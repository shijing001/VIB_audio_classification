{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revised Linear Layer Architecture without VIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tensorboardX import SummaryWriter\n",
    "#from utils import cuda\n",
    "import pdb\n",
    "import time\n",
    "from numbers import Number\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics\n",
    "import argparse\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### neural networks architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyNet(nn.Module):\n",
    "    '''\n",
    "    Construct a MLP that is used to train the model \n",
    "    param[in]: X_train, output_features\n",
    "    param[out]: output \n",
    "    \n",
    "    Note: initialize the weight with a self-defined method\n",
    "    '''\n",
    "\n",
    "    def __init__(self, output_features=8):\n",
    "        super(ToyNet, self).__init__()\n",
    "        self.encode = nn.Sequential(\n",
    "            nn.Linear(40, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, output_features))\n",
    "        #self.optim = optim.Adam(self.toynet.parameters(),lr=self.lr,betas=(0.5,0.999))\n",
    "        #self.scheduler = lr_scheduler.ExponentialLR(self.optim,gamma=0.97\n",
    "    def forward(self, X_train):\n",
    "        output=self.encode(X_train)\n",
    "        #prediction = F.softmax(output,dim=1).max(1)[1]\n",
    "        \n",
    "        #print(prediction)\n",
    "        return output\n",
    "    def weight_init(self):\n",
    "        for m in self._modules:\n",
    "            xavier_init(self._modules[m])\n",
    "            \n",
    "def xavier_init(ms):\n",
    "    \"\"\"\n",
    "    Xavier initialization\n",
    "    \"\"\"\n",
    "    for m in ms :\n",
    "        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "            nn.init.xavier_uniform(m.weight,gain=nn.init.calculate_gain('relu'))\n",
    "            m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda(tensor, is_cuda):\n",
    "    if is_cuda : return tensor.cuda()\n",
    "    else : return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    'epoch':100,\n",
    "    'batch_size':32,\n",
    "    'lr':0.009,\n",
    "    'train_dataset_percentage':0.05\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train inuse,train, percentage of whole ,valid,test\n",
      "262 3151 0.049885757806549885 1050 1051\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"\n",
    "    construct dataset from numpy and split it \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, data, target, transform=None):\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "        self.target = torch.from_numpy(target).long()\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "X = joblib.load('./joblib_features/X.joblib')\n",
    "y = joblib.load('./joblib_features/y.joblib')\n",
    "full_dataset = CustomDataset(X, y)\n",
    "train_size = int(0.6 * len(full_dataset))\n",
    "valid_size = int(0.2 * len(full_dataset))\n",
    "test_size = len(full_dataset) - valid_size-train_size\n",
    "batch_size = params['batch_size']\n",
    "#train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, \n",
    "                                                            #[train_size, test_size])\n",
    "### split dataset into training, validation and test                     \n",
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    full_dataset, (train_size, valid_size, test_size), generator=torch.Generator().manual_seed(42))\n",
    "train_dataset_inuse_size=int(params['train_dataset_percentage']* len(full_dataset))\n",
    "train_dataset_unused_size=len(train_dataset)- train_dataset_inuse_size\n",
    "train_dataset_inuse,train_dataset_unused=torch.utils.data.random_split(\n",
    "    train_dataset, (train_dataset_inuse_size,train_dataset_unused_size), generator=torch.Generator().manual_seed(42))\n",
    "train_dataloader = DataLoader(train_dataset_inuse, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "my_dataloader = {'train': train_dataloader , 'validate':valid_dataloader, 'test': test_dataloader}\n",
    "print('train inuse,train, percentage of whole ,valid,test')\n",
    "print(train_dataset_inuse_size,train_size, train_dataset_inuse_size/len(full_dataset),valid_size,test_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver(object):\n",
    "#train the model\n",
    "\n",
    "    def __init__(self, params):\n",
    "        \"\"\"\n",
    "        initialization of a Solver object\n",
    "        \n",
    "        \"\"\"\n",
    "        self.cuda =torch.cuda.is_available ()\n",
    "        self.epoch = params['epoch']\n",
    "        self.batch_size = params['batch_size']\n",
    "        self.lr = params['lr']\n",
    "        self.toynet = cuda(ToyNet(), self.cuda)\n",
    "        self.toynet.weight_init()\n",
    "        self.optim = optim.Adam(self.toynet.parameters(),\n",
    "                                lr=self.lr,\n",
    "                                betas=(0.5,0.999))\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def train(self):\n",
    "        baseline_train = {\"Accuracy\":[],\"F1_Score\":[]}\n",
    "        baseline_valid = {\"Accuracy\":[],\"F1_Score\":[]}\n",
    "        for epc in range(self.epoch):  # loop over the dataset multiple times\n",
    "            self.toynet.train('True')  # training neural networks mode\n",
    "            running_loss = 0.0\n",
    "            y_real=torch.randn([0])\n",
    "            y_hat=torch.randn([0])\n",
    "            for i, data in enumerate(train_dataloader):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs, labels = data\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                self.optim.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = self.toynet.forward(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optim.step()\n",
    "                \n",
    "                prediction = F.softmax(outputs,dim=1).max(1)[1]\n",
    "                y_real=torch.cat([y_real,labels],dim=0)\n",
    "                y_hat=torch.cat([y_hat,prediction],dim=0)\n",
    "                accuracy = torch.eq(prediction,labels).float().mean()\n",
    "                avg_accuracy = Variable(cuda(torch.zeros(accuracy.size()), self.cuda))\n",
    "\n",
    "                # print statistics\n",
    "                running_loss += loss.item()\n",
    "                if i % self.batch_size == 0:    # print every 30 mini-batches\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                            (epc + 1, i + 1, running_loss / self.batch_size))\n",
    "                    print('acc:{:.4f} '\n",
    "                            .format(accuracy.item(), end=' '))\n",
    "                    print('err:{:.4f} '\n",
    "                            .format(1-accuracy.item()))\n",
    "                    running_loss = 0.0\n",
    "            baseline_train[\"Accuracy\"].append(float(\"{:.2f}\".format(accuracy.item())))\n",
    "            f1score = sklearn.metrics.f1_score(y_real, y_hat,labels=None,pos_label=1, average='weighted',sample_weight=None)\n",
    "            baseline_train[\"F1_Score\"].append(float(\"{:.2f}\".format(f1score.item())))\n",
    "            ## validation set at each epoch\n",
    "            temp_accuracy,temp_f1score = self.test()\n",
    "            ##input accuracy and f1-score of validation dataset into ano\n",
    "            baseline_valid[\"F1_Score\"].append(float(\"{:.2f}\".format(temp_f1score)))\n",
    "            baseline_valid[\"Accuracy\"].append(float(\"{:.2f}\".format(temp_accuracy)))\n",
    "        print(baseline_train)\n",
    "        print(baseline_valid)\n",
    "        print('Finished Training',(epc+1))\n",
    "        return baseline_train, baseline_valid\n",
    "    \n",
    "    def test(self):\n",
    "        \"\"\"\n",
    "        Testing over a dataset\n",
    "        \"\"\"\n",
    "        self.toynet.train('False')  # evaluation mode      \n",
    "        loss, correct, total_num = 0,0,0\n",
    "        \n",
    "        y_real=torch.randn([0])\n",
    "        y_hat=torch.randn([0])\n",
    "        \n",
    "        for i, data in enumerate(valid_dataloader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            outputs = self.toynet.forward(inputs)\n",
    "            #loss\n",
    "            total_num += labels.shape[0]\n",
    "            loss += self.criterion(outputs,labels)\n",
    "            prediction = F.softmax(outputs,dim=1).max(1)[1]\n",
    "            y_real=torch.cat([y_real,labels],dim=0)\n",
    "            y_hat=torch.cat([y_hat,prediction],dim=0)\n",
    "            correct += torch.eq(prediction,labels).float().sum()\n",
    "            avg_correct = Variable(cuda(torch.zeros(correct.size()), self.cuda))\n",
    "        accuracy = correct/total_num\n",
    "        f1score = sklearn.metrics.f1_score(y_real, y_hat,labels=None,pos_label=1, average='weighted',sample_weight=None)\n",
    "        avg_accuracy = avg_correct/total_num\n",
    "            \n",
    "        print('[TEST RESULT]')\n",
    "        print('acc:{:.4f} '\n",
    "                .format(accuracy.item(),end=' '))\n",
    "        print('err:{:.4f}'\n",
    "                .format(1-accuracy.item()))\n",
    "        print(classification_report(y_real,y_hat))\n",
    "        self.toynet.train('True')\n",
    "        return accuracy.item(),f1score.item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:36: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.867\n",
      "acc:0.0625 \n",
      "err:0.9375 \n",
      "[TEST RESULT]\n",
      "acc:0.1762 \n",
      "err:0.8238\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       115\n",
      "         1.0       0.16      0.84      0.27        63\n",
      "         2.0       0.00      0.00      0.00       149\n",
      "         3.0       0.00      0.00      0.00       159\n",
      "         4.0       0.19      0.73      0.30       180\n",
      "         5.0       0.00      0.00      0.00       157\n",
      "         6.0       0.00      0.00      0.00       109\n",
      "         7.0       0.00      0.00      0.00       118\n",
      "\n",
      "    accuracy                           0.18      1050\n",
      "   macro avg       0.04      0.20      0.07      1050\n",
      "weighted avg       0.04      0.18      0.07      1050\n",
      "\n",
      "[2,     1] loss: 0.626\n",
      "acc:0.2500 \n",
      "err:0.7500 \n",
      "[TEST RESULT]\n",
      "acc:0.3733 \n",
      "err:0.6267\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.31      0.82      0.45       115\n",
      "         1.0       0.00      0.00      0.00        63\n",
      "         2.0       0.22      0.31      0.26       149\n",
      "         3.0       1.00      0.13      0.23       159\n",
      "         4.0       0.43      0.51      0.47       180\n",
      "         5.0       0.92      0.41      0.57       157\n",
      "         6.0       0.31      0.54      0.40       109\n",
      "         7.0       0.28      0.13      0.18       118\n",
      "\n",
      "    accuracy                           0.37      1050\n",
      "   macro avg       0.44      0.36      0.32      1050\n",
      "weighted avg       0.49      0.37      0.35      1050\n",
      "\n",
      "[3,     1] loss: 0.091\n",
      "acc:0.4062 \n",
      "err:0.5938 \n",
      "[TEST RESULT]\n",
      "acc:0.4571 \n",
      "err:0.5429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.73      0.84       115\n",
      "         1.0       0.00      0.00      0.00        63\n",
      "         2.0       0.35      0.47      0.40       149\n",
      "         3.0       0.76      0.58      0.66       159\n",
      "         4.0       0.72      0.51      0.59       180\n",
      "         5.0       0.40      0.62      0.49       157\n",
      "         6.0       0.17      0.41      0.24       109\n",
      "         7.0       0.00      0.00      0.00       118\n",
      "\n",
      "    accuracy                           0.46      1050\n",
      "   macro avg       0.42      0.42      0.40      1050\n",
      "weighted avg       0.47      0.46      0.45      1050\n",
      "\n",
      "[4,     1] loss: 0.071\n",
      "acc:0.5000 \n",
      "err:0.5000 \n",
      "[TEST RESULT]\n",
      "acc:0.4886 \n",
      "err:0.5114\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.74      0.81       115\n",
      "         1.0       0.21      0.73      0.32        63\n",
      "         2.0       0.51      0.28      0.36       149\n",
      "         3.0       0.79      0.55      0.65       159\n",
      "         4.0       0.35      0.59      0.44       180\n",
      "         5.0       0.75      0.27      0.39       157\n",
      "         6.0       0.76      0.28      0.41       109\n",
      "         7.0       0.53      0.62      0.57       118\n",
      "\n",
      "    accuracy                           0.49      1050\n",
      "   macro avg       0.60      0.51      0.50      1050\n",
      "weighted avg       0.61      0.49      0.50      1050\n",
      "\n",
      "[5,     1] loss: 0.047\n",
      "acc:0.5000 \n",
      "err:0.5000 \n",
      "[TEST RESULT]\n",
      "acc:0.4543 \n",
      "err:0.5457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.76      0.80       115\n",
      "         1.0       0.24      0.49      0.32        63\n",
      "         2.0       0.37      0.64      0.47       149\n",
      "         3.0       0.98      0.31      0.48       159\n",
      "         4.0       0.89      0.31      0.46       180\n",
      "         5.0       0.51      0.50      0.50       157\n",
      "         6.0       0.18      0.32      0.23       109\n",
      "         7.0       0.46      0.37      0.41       118\n",
      "\n",
      "    accuracy                           0.45      1050\n",
      "   macro avg       0.56      0.46      0.46      1050\n",
      "weighted avg       0.61      0.45      0.47      1050\n",
      "\n",
      "[6,     1] loss: 0.033\n",
      "acc:0.5625 \n",
      "err:0.4375 \n",
      "[TEST RESULT]\n",
      "acc:0.4114 \n",
      "err:0.5886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.15      0.26       115\n",
      "         1.0       0.62      0.08      0.14        63\n",
      "         2.0       0.90      0.25      0.39       149\n",
      "         3.0       0.67      0.57      0.61       159\n",
      "         4.0       0.74      0.47      0.58       180\n",
      "         5.0       0.26      0.84      0.40       157\n",
      "         6.0       0.25      0.24      0.24       109\n",
      "         7.0       0.31      0.34      0.32       118\n",
      "\n",
      "    accuracy                           0.41      1050\n",
      "   macro avg       0.59      0.37      0.37      1050\n",
      "weighted avg       0.60      0.41      0.41      1050\n",
      "\n",
      "[7,     1] loss: 0.061\n",
      "acc:0.5000 \n",
      "err:0.5000 \n",
      "[TEST RESULT]\n",
      "acc:0.5038 \n",
      "err:0.4962\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.46      0.84      0.60       115\n",
      "         1.0       0.36      0.19      0.25        63\n",
      "         2.0       0.53      0.42      0.47       149\n",
      "         3.0       0.94      0.55      0.69       159\n",
      "         4.0       0.86      0.43      0.58       180\n",
      "         5.0       0.83      0.45      0.58       157\n",
      "         6.0       0.25      0.83      0.38       109\n",
      "         7.0       0.60      0.27      0.37       118\n",
      "\n",
      "    accuracy                           0.50      1050\n",
      "   macro avg       0.60      0.50      0.49      1050\n",
      "weighted avg       0.65      0.50      0.52      1050\n",
      "\n",
      "[8,     1] loss: 0.029\n",
      "acc:0.6250 \n",
      "err:0.3750 \n",
      "[TEST RESULT]\n",
      "acc:0.5114 \n",
      "err:0.4886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.73      0.82       115\n",
      "         1.0       0.30      0.22      0.25        63\n",
      "         2.0       0.30      0.83      0.44       149\n",
      "         3.0       0.67      0.58      0.62       159\n",
      "         4.0       0.93      0.46      0.62       180\n",
      "         5.0       0.47      0.48      0.48       157\n",
      "         6.0       0.44      0.31      0.37       109\n",
      "         7.0       0.82      0.26      0.40       118\n",
      "\n",
      "    accuracy                           0.51      1050\n",
      "   macro avg       0.61      0.48      0.50      1050\n",
      "weighted avg       0.63      0.51      0.52      1050\n",
      "\n",
      "[9,     1] loss: 0.041\n",
      "acc:0.5625 \n",
      "err:0.4375 \n",
      "[TEST RESULT]\n",
      "acc:0.4790 \n",
      "err:0.5210\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.71      0.82       115\n",
      "         1.0       0.14      0.65      0.23        63\n",
      "         2.0       0.60      0.39      0.47       149\n",
      "         3.0       0.42      0.62      0.50       159\n",
      "         4.0       0.93      0.50      0.65       180\n",
      "         5.0       0.87      0.46      0.60       157\n",
      "         6.0       0.22      0.24      0.23       109\n",
      "         7.0       0.90      0.31      0.46       118\n",
      "\n",
      "    accuracy                           0.48      1050\n",
      "   macro avg       0.63      0.48      0.49      1050\n",
      "weighted avg       0.68      0.48      0.52      1050\n",
      "\n",
      "[10,     1] loss: 0.046\n",
      "acc:0.5312 \n",
      "err:0.4688 \n",
      "[TEST RESULT]\n",
      "acc:0.4590 \n",
      "err:0.5410\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.76      0.82       115\n",
      "         1.0       0.15      0.78      0.26        63\n",
      "         2.0       0.72      0.22      0.34       149\n",
      "         3.0       1.00      0.03      0.05       159\n",
      "         4.0       0.86      0.49      0.62       180\n",
      "         5.0       0.69      0.54      0.60       157\n",
      "         6.0       0.30      0.56      0.39       109\n",
      "         7.0       0.49      0.64      0.55       118\n",
      "\n",
      "    accuracy                           0.46      1050\n",
      "   macro avg       0.64      0.50      0.45      1050\n",
      "weighted avg       0.70      0.46      0.46      1050\n",
      "\n",
      "[11,     1] loss: 0.035\n",
      "acc:0.5938 \n",
      "err:0.4062 \n",
      "[TEST RESULT]\n",
      "acc:0.5076 \n",
      "err:0.4924\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.76      0.83       115\n",
      "         1.0       0.14      0.43      0.21        63\n",
      "         2.0       0.38      0.40      0.39       149\n",
      "         3.0       0.44      0.65      0.52       159\n",
      "         4.0       0.98      0.45      0.62       180\n",
      "         5.0       0.76      0.54      0.63       157\n",
      "         6.0       0.31      0.18      0.23       109\n",
      "         7.0       0.61      0.60      0.61       118\n",
      "\n",
      "    accuracy                           0.51      1050\n",
      "   macro avg       0.57      0.50      0.51      1050\n",
      "weighted avg       0.61      0.51      0.53      1050\n",
      "\n",
      "[12,     1] loss: 0.053\n",
      "acc:0.4688 \n",
      "err:0.5312 \n",
      "[TEST RESULT]\n",
      "acc:0.4076 \n",
      "err:0.5924\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.77      0.74       115\n",
      "         1.0       0.00      0.00      0.00        63\n",
      "         2.0       0.28      0.81      0.41       149\n",
      "         3.0       0.75      0.02      0.04       159\n",
      "         4.0       0.86      0.48      0.62       180\n",
      "         5.0       0.59      0.51      0.55       157\n",
      "         6.0       0.23      0.19      0.21       109\n",
      "         7.0       0.19      0.24      0.21       118\n",
      "\n",
      "    accuracy                           0.41      1050\n",
      "   macro avg       0.45      0.38      0.35      1050\n",
      "weighted avg       0.51      0.41      0.38      1050\n",
      "\n",
      "[13,     1] loss: 0.044\n",
      "acc:0.5938 \n",
      "err:0.4062 \n",
      "[TEST RESULT]\n",
      "acc:0.4629 \n",
      "err:0.5371\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.44      0.81      0.57       115\n",
      "         1.0       0.00      0.00      0.00        63\n",
      "         2.0       0.53      0.52      0.53       149\n",
      "         3.0       0.66      0.42      0.51       159\n",
      "         4.0       0.76      0.51      0.61       180\n",
      "         5.0       0.32      0.66      0.43       157\n",
      "         6.0       0.17      0.18      0.18       109\n",
      "         7.0       0.88      0.30      0.44       118\n",
      "\n",
      "    accuracy                           0.46      1050\n",
      "   macro avg       0.47      0.42      0.41      1050\n",
      "weighted avg       0.52      0.46      0.45      1050\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14,     1] loss: 0.095\n",
      "acc:0.5000 \n",
      "err:0.5000 \n",
      "[TEST RESULT]\n",
      "acc:0.2952 \n",
      "err:0.7048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.23      0.80      0.36       115\n",
      "         1.0       0.14      0.84      0.24        63\n",
      "         2.0       0.47      0.32      0.38       149\n",
      "         3.0       0.88      0.14      0.24       159\n",
      "         4.0       0.65      0.26      0.37       180\n",
      "         5.0       0.81      0.11      0.19       157\n",
      "         6.0       0.00      0.00      0.00       109\n",
      "         7.0       0.60      0.27      0.37       118\n",
      "\n",
      "    accuracy                           0.30      1050\n",
      "   macro avg       0.47      0.34      0.27      1050\n",
      "weighted avg       0.53      0.30      0.28      1050\n",
      "\n",
      "[15,     1] loss: 0.098\n",
      "acc:0.4375 \n",
      "err:0.5625 \n",
      "[TEST RESULT]\n",
      "acc:0.4524 \n",
      "err:0.5476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.75      0.86       115\n",
      "         1.0       0.16      0.21      0.18        63\n",
      "         2.0       0.45      0.52      0.48       149\n",
      "         3.0       0.49      0.67      0.57       159\n",
      "         4.0       0.53      0.61      0.56       180\n",
      "         5.0       1.00      0.02      0.04       157\n",
      "         6.0       0.21      0.44      0.28       109\n",
      "         7.0       0.62      0.27      0.38       118\n",
      "\n",
      "    accuracy                           0.45      1050\n",
      "   macro avg       0.56      0.44      0.42      1050\n",
      "weighted avg       0.59      0.45      0.43      1050\n",
      "\n",
      "[16,     1] loss: 0.061\n",
      "acc:0.5000 \n",
      "err:0.5000 \n",
      "[TEST RESULT]\n",
      "acc:0.5390 \n",
      "err:0.4610\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.44      0.86      0.59       115\n",
      "         1.0       0.43      0.10      0.16        63\n",
      "         2.0       0.38      0.54      0.45       149\n",
      "         3.0       0.49      0.68      0.57       159\n",
      "         4.0       0.95      0.44      0.61       180\n",
      "         5.0       0.86      0.43      0.57       157\n",
      "         6.0       0.55      0.56      0.56       109\n",
      "         7.0       0.60      0.54      0.57       118\n",
      "\n",
      "    accuracy                           0.54      1050\n",
      "   macro avg       0.59      0.52      0.51      1050\n",
      "weighted avg       0.62      0.54      0.53      1050\n",
      "\n",
      "[17,     1] loss: 0.029\n",
      "acc:0.6250 \n",
      "err:0.3750 \n",
      "[TEST RESULT]\n",
      "acc:0.4200 \n",
      "err:0.5800\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.74      0.85       115\n",
      "         1.0       0.14      0.97      0.24        63\n",
      "         2.0       0.64      0.21      0.32       149\n",
      "         3.0       0.74      0.45      0.56       159\n",
      "         4.0       0.61      0.48      0.54       180\n",
      "         5.0       0.40      0.45      0.43       157\n",
      "         6.0       0.54      0.13      0.21       109\n",
      "         7.0       0.58      0.18      0.27       118\n",
      "\n",
      "    accuracy                           0.42      1050\n",
      "   macro avg       0.58      0.45      0.43      1050\n",
      "weighted avg       0.61      0.42      0.45      1050\n",
      "\n",
      "[18,     1] loss: 0.081\n",
      "acc:0.4688 \n",
      "err:0.5312 \n",
      "[TEST RESULT]\n",
      "acc:0.5143 \n",
      "err:0.4857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.82      0.70       115\n",
      "         1.0       0.25      0.21      0.22        63\n",
      "         2.0       0.40      0.51      0.45       149\n",
      "         3.0       0.69      0.56      0.62       159\n",
      "         4.0       0.96      0.48      0.64       180\n",
      "         5.0       0.97      0.36      0.53       157\n",
      "         6.0       0.22      0.60      0.32       109\n",
      "         7.0       0.82      0.51      0.63       118\n",
      "\n",
      "    accuracy                           0.51      1050\n",
      "   macro avg       0.61      0.50      0.51      1050\n",
      "weighted avg       0.67      0.51      0.54      1050\n",
      "\n",
      "[19,     1] loss: 0.030\n",
      "acc:0.6562 \n",
      "err:0.3438 \n",
      "[TEST RESULT]\n",
      "acc:0.5467 \n",
      "err:0.4533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.89      0.53       115\n",
      "         1.0       0.35      0.13      0.19        63\n",
      "         2.0       0.51      0.48      0.50       149\n",
      "         3.0       0.90      0.55      0.68       159\n",
      "         4.0       0.90      0.54      0.67       180\n",
      "         5.0       0.82      0.43      0.57       157\n",
      "         6.0       0.29      0.58      0.39       109\n",
      "         7.0       0.65      0.65      0.65       118\n",
      "\n",
      "    accuracy                           0.55      1050\n",
      "   macro avg       0.60      0.53      0.52      1050\n",
      "weighted avg       0.65      0.55      0.56      1050\n",
      "\n",
      "[20,     1] loss: 0.026\n",
      "acc:0.6562 \n",
      "err:0.3438 \n",
      "[TEST RESULT]\n",
      "acc:0.4743 \n",
      "err:0.5257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.74      0.85       115\n",
      "         1.0       0.26      0.22      0.24        63\n",
      "         2.0       0.44      0.35      0.39       149\n",
      "         3.0       0.12      0.04      0.06       159\n",
      "         4.0       0.54      0.74      0.63       180\n",
      "         5.0       0.36      0.66      0.47       157\n",
      "         6.0       0.35      0.48      0.40       109\n",
      "         7.0       0.81      0.43      0.56       118\n",
      "\n",
      "    accuracy                           0.47      1050\n",
      "   macro avg       0.49      0.46      0.45      1050\n",
      "weighted avg       0.48      0.47      0.45      1050\n",
      "\n",
      "[21,     1] loss: 0.050\n",
      "acc:0.5312 \n",
      "err:0.4688 \n",
      "[TEST RESULT]\n",
      "acc:0.5867 \n",
      "err:0.4133\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.80      0.78       115\n",
      "         1.0       0.23      0.76      0.35        63\n",
      "         2.0       0.89      0.40      0.55       149\n",
      "         3.0       0.90      0.55      0.68       159\n",
      "         4.0       0.93      0.48      0.64       180\n",
      "         5.0       0.40      0.71      0.51       157\n",
      "         6.0       0.84      0.54      0.66       109\n",
      "         7.0       0.66      0.60      0.63       118\n",
      "\n",
      "    accuracy                           0.59      1050\n",
      "   macro avg       0.70      0.61      0.60      1050\n",
      "weighted avg       0.74      0.59      0.61      1050\n",
      "\n",
      "[22,     1] loss: 0.019\n",
      "acc:0.7812 \n",
      "err:0.2188 \n",
      "[TEST RESULT]\n",
      "acc:0.5714 \n",
      "err:0.4286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      0.90      0.56       115\n",
      "         1.0       0.64      0.11      0.19        63\n",
      "         2.0       0.67      0.50      0.57       149\n",
      "         3.0       0.92      0.55      0.69       159\n",
      "         4.0       0.95      0.46      0.62       180\n",
      "         5.0       0.35      0.75      0.48       157\n",
      "         6.0       0.81      0.59      0.68       109\n",
      "         7.0       0.82      0.55      0.66       118\n",
      "\n",
      "    accuracy                           0.57      1050\n",
      "   macro avg       0.70      0.55      0.55      1050\n",
      "weighted avg       0.71      0.57      0.58      1050\n",
      "\n",
      "[23,     1] loss: 0.020\n",
      "acc:0.7500 \n",
      "err:0.2500 \n",
      "[TEST RESULT]\n",
      "acc:0.5886 \n",
      "err:0.4114\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.74      0.85       115\n",
      "         1.0       1.00      0.03      0.06        63\n",
      "         2.0       0.71      0.44      0.54       149\n",
      "         3.0       0.53      0.68      0.60       159\n",
      "         4.0       0.78      0.64      0.70       180\n",
      "         5.0       0.44      0.66      0.53       157\n",
      "         6.0       0.37      0.76      0.50       109\n",
      "         7.0       0.89      0.48      0.63       118\n",
      "\n",
      "    accuracy                           0.59      1050\n",
      "   macro avg       0.72      0.55      0.55      1050\n",
      "weighted avg       0.69      0.59      0.59      1050\n",
      "\n",
      "[24,     1] loss: 0.076\n",
      "acc:0.6250 \n",
      "err:0.3750 \n",
      "[TEST RESULT]\n",
      "acc:0.5590 \n",
      "err:0.4410\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.73      0.77       115\n",
      "         1.0       0.31      0.33      0.32        63\n",
      "         2.0       0.79      0.25      0.38       149\n",
      "         3.0       0.61      0.58      0.60       159\n",
      "         4.0       0.83      0.58      0.68       180\n",
      "         5.0       0.49      0.66      0.56       157\n",
      "         6.0       0.32      0.72      0.45       109\n",
      "         7.0       0.65      0.56      0.60       118\n",
      "\n",
      "    accuracy                           0.56      1050\n",
      "   macro avg       0.60      0.55      0.54      1050\n",
      "weighted avg       0.63      0.56      0.56      1050\n",
      "\n",
      "[25,     1] loss: 0.025\n",
      "acc:0.6875 \n",
      "err:0.3125 \n",
      "[TEST RESULT]\n",
      "acc:0.5962 \n",
      "err:0.4038\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.75      0.85       115\n",
      "         1.0       0.18      0.52      0.27        63\n",
      "         2.0       0.75      0.44      0.55       149\n",
      "         3.0       0.99      0.55      0.70       159\n",
      "         4.0       0.71      0.69      0.70       180\n",
      "         5.0       0.47      0.74      0.58       157\n",
      "         6.0       0.74      0.49      0.59       109\n",
      "         7.0       0.56      0.52      0.54       118\n",
      "\n",
      "    accuracy                           0.60      1050\n",
      "   macro avg       0.67      0.59      0.60      1050\n",
      "weighted avg       0.71      0.60      0.62      1050\n",
      "\n",
      "[26,     1] loss: 0.012\n",
      "acc:0.8750 \n",
      "err:0.1250 \n",
      "[TEST RESULT]\n",
      "acc:0.6229 \n",
      "err:0.3771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.75      0.84       115\n",
      "         1.0       0.24      0.60      0.34        63\n",
      "         2.0       0.47      0.62      0.54       149\n",
      "         3.0       0.73      0.57      0.64       159\n",
      "         4.0       0.68      0.67      0.67       180\n",
      "         5.0       0.66      0.61      0.63       157\n",
      "         6.0       0.83      0.60      0.70       109\n",
      "         7.0       0.80      0.55      0.65       118\n",
      "\n",
      "    accuracy                           0.62      1050\n",
      "   macro avg       0.67      0.62      0.63      1050\n",
      "weighted avg       0.69      0.62      0.64      1050\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27,     1] loss: 0.017\n",
      "acc:0.8438 \n",
      "err:0.1562 \n",
      "[TEST RESULT]\n",
      "acc:0.2400 \n",
      "err:0.7600\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.15      0.98      0.26       115\n",
      "         1.0       0.62      0.13      0.21        63\n",
      "         2.0       0.36      0.23      0.29       149\n",
      "         3.0       1.00      0.01      0.01       159\n",
      "         4.0       1.00      0.11      0.20       180\n",
      "         5.0       0.48      0.39      0.43       157\n",
      "         6.0       0.00      0.00      0.00       109\n",
      "         7.0       0.32      0.11      0.16       118\n",
      "\n",
      "    accuracy                           0.24      1050\n",
      "   macro avg       0.49      0.25      0.20      1050\n",
      "weighted avg       0.53      0.24      0.20      1050\n",
      "\n",
      "[28,     1] loss: 0.351\n",
      "acc:0.3750 \n",
      "err:0.6250 \n",
      "[TEST RESULT]\n",
      "acc:0.4019 \n",
      "err:0.5981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.70      0.82       115\n",
      "         1.0       0.25      0.63      0.36        63\n",
      "         2.0       0.35      0.62      0.45       149\n",
      "         3.0       0.00      0.00      0.00       159\n",
      "         4.0       0.67      0.30      0.41       180\n",
      "         5.0       0.62      0.46      0.53       157\n",
      "         6.0       0.20      0.60      0.30       109\n",
      "         7.0       0.95      0.15      0.26       118\n",
      "\n",
      "    accuracy                           0.40      1050\n",
      "   macro avg       0.50      0.43      0.39      1050\n",
      "weighted avg       0.51      0.40      0.38      1050\n",
      "\n",
      "[29,     1] loss: 0.039\n",
      "acc:0.5625 \n",
      "err:0.4375 \n",
      "[TEST RESULT]\n",
      "acc:0.4695 \n",
      "err:0.5305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.74      0.85       115\n",
      "         1.0       1.00      0.03      0.06        63\n",
      "         2.0       0.70      0.41      0.52       149\n",
      "         3.0       0.00      0.00      0.00       159\n",
      "         4.0       0.94      0.46      0.62       180\n",
      "         5.0       0.25      0.91      0.39       157\n",
      "         6.0       0.42      0.58      0.49       109\n",
      "         7.0       0.80      0.47      0.60       118\n",
      "\n",
      "    accuracy                           0.47      1050\n",
      "   macro avg       0.64      0.45      0.44      1050\n",
      "weighted avg       0.60      0.47      0.45      1050\n",
      "\n",
      "[30,     1] loss: 0.082\n",
      "acc:0.4375 \n",
      "err:0.5625 \n",
      "[TEST RESULT]\n",
      "acc:0.4771 \n",
      "err:0.5229\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.80      0.81       115\n",
      "         1.0       0.36      0.06      0.11        63\n",
      "         2.0       0.49      0.36      0.42       149\n",
      "         3.0       0.48      0.62      0.54       159\n",
      "         4.0       0.84      0.48      0.61       180\n",
      "         5.0       0.52      0.53      0.53       157\n",
      "         6.0       0.16      0.45      0.23       109\n",
      "         7.0       0.87      0.28      0.42       118\n",
      "\n",
      "    accuracy                           0.48      1050\n",
      "   macro avg       0.57      0.45      0.46      1050\n",
      "weighted avg       0.59      0.48      0.49      1050\n",
      "\n",
      "[31,     1] loss: 0.048\n",
      "acc:0.4688 \n",
      "err:0.5312 \n",
      "[TEST RESULT]\n",
      "acc:0.4971 \n",
      "err:0.5029\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.79      0.84       115\n",
      "         1.0       0.13      0.35      0.19        63\n",
      "         2.0       0.44      0.66      0.53       149\n",
      "         3.0       0.70      0.09      0.16       159\n",
      "         4.0       0.94      0.44      0.60       180\n",
      "         5.0       0.86      0.48      0.61       157\n",
      "         6.0       0.27      0.69      0.39       109\n",
      "         7.0       0.74      0.58      0.65       118\n",
      "\n",
      "    accuracy                           0.50      1050\n",
      "   macro avg       0.62      0.51      0.50      1050\n",
      "weighted avg       0.68      0.50      0.51      1050\n",
      "\n",
      "[32,     1] loss: 0.028\n",
      "acc:0.6562 \n",
      "err:0.3438 \n",
      "[TEST RESULT]\n",
      "acc:0.5448 \n",
      "err:0.4552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.78      0.84       115\n",
      "         1.0       0.60      0.05      0.09        63\n",
      "         2.0       0.56      0.61      0.59       149\n",
      "         3.0       0.60      0.55      0.58       159\n",
      "         4.0       0.58      0.69      0.63       180\n",
      "         5.0       0.44      0.61      0.51       157\n",
      "         6.0       0.19      0.26      0.22       109\n",
      "         7.0       0.90      0.44      0.59       118\n",
      "\n",
      "    accuracy                           0.54      1050\n",
      "   macro avg       0.60      0.50      0.50      1050\n",
      "weighted avg       0.59      0.54      0.54      1050\n",
      "\n",
      "[33,     1] loss: 0.040\n",
      "acc:0.5625 \n",
      "err:0.4375 \n",
      "[TEST RESULT]\n",
      "acc:0.5638 \n",
      "err:0.4362\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.78      0.79       115\n",
      "         1.0       0.17      0.51      0.26        63\n",
      "         2.0       0.45      0.68      0.54       149\n",
      "         3.0       0.50      0.55      0.52       159\n",
      "         4.0       0.88      0.56      0.68       180\n",
      "         5.0       0.92      0.43      0.59       157\n",
      "         6.0       0.66      0.40      0.50       109\n",
      "         7.0       0.72      0.58      0.64       118\n",
      "\n",
      "    accuracy                           0.56      1050\n",
      "   macro avg       0.64      0.56      0.57      1050\n",
      "weighted avg       0.67      0.56      0.59      1050\n",
      "\n",
      "[34,     1] loss: 0.024\n",
      "acc:0.7812 \n",
      "err:0.2188 \n",
      "[TEST RESULT]\n",
      "acc:0.5610 \n",
      "err:0.4390\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.77      0.85       115\n",
      "         1.0       0.25      0.24      0.24        63\n",
      "         2.0       0.68      0.60      0.64       149\n",
      "         3.0       0.96      0.42      0.58       159\n",
      "         4.0       0.91      0.52      0.66       180\n",
      "         5.0       0.60      0.55      0.57       157\n",
      "         6.0       0.68      0.57      0.62       109\n",
      "         7.0       0.24      0.74      0.37       118\n",
      "\n",
      "    accuracy                           0.56      1050\n",
      "   macro avg       0.66      0.55      0.57      1050\n",
      "weighted avg       0.71      0.56      0.59      1050\n",
      "\n",
      "[35,     1] loss: 0.042\n",
      "acc:0.6250 \n",
      "err:0.3750 \n",
      "[TEST RESULT]\n",
      "acc:0.5267 \n",
      "err:0.4733\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.76      0.86       115\n",
      "         1.0       0.28      0.22      0.25        63\n",
      "         2.0       0.42      0.70      0.53       149\n",
      "         3.0       0.00      0.00      0.00       159\n",
      "         4.0       0.83      0.59      0.69       180\n",
      "         5.0       0.60      0.57      0.58       157\n",
      "         6.0       0.29      0.77      0.42       109\n",
      "         7.0       0.77      0.57      0.65       118\n",
      "\n",
      "    accuracy                           0.53      1050\n",
      "   macro avg       0.52      0.52      0.50      1050\n",
      "weighted avg       0.53      0.53      0.51      1050\n",
      "\n",
      "[36,     1] loss: 0.032\n",
      "acc:0.6875 \n",
      "err:0.3125 \n",
      "[TEST RESULT]\n",
      "acc:0.4514 \n",
      "err:0.5486\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.77      0.83       115\n",
      "         1.0       0.10      0.19      0.13        63\n",
      "         2.0       0.32      0.72      0.44       149\n",
      "         3.0       0.43      0.08      0.13       159\n",
      "         4.0       0.84      0.51      0.64       180\n",
      "         5.0       0.81      0.30      0.44       157\n",
      "         6.0       0.31      0.62      0.41       109\n",
      "         7.0       0.61      0.40      0.48       118\n",
      "\n",
      "    accuracy                           0.45      1050\n",
      "   macro avg       0.54      0.45      0.44      1050\n",
      "weighted avg       0.58      0.45      0.45      1050\n",
      "\n",
      "[37,     1] loss: 0.045\n",
      "acc:0.5000 \n",
      "err:0.5000 \n",
      "[TEST RESULT]\n",
      "acc:0.5267 \n",
      "err:0.4733\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.79      0.76       115\n",
      "         1.0       0.25      0.21      0.23        63\n",
      "         2.0       0.46      0.68      0.55       149\n",
      "         3.0       0.37      0.77      0.50       159\n",
      "         4.0       0.82      0.47      0.60       180\n",
      "         5.0       0.91      0.38      0.53       157\n",
      "         6.0       0.37      0.22      0.28       109\n",
      "         7.0       0.65      0.49      0.56       118\n",
      "\n",
      "    accuracy                           0.53      1050\n",
      "   macro avg       0.57      0.50      0.50      1050\n",
      "weighted avg       0.60      0.53      0.52      1050\n",
      "\n",
      "[38,     1] loss: 0.026\n",
      "acc:0.7812 \n",
      "err:0.2188 \n",
      "[TEST RESULT]\n",
      "acc:0.5695 \n",
      "err:0.4305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.77      0.82       115\n",
      "         1.0       0.36      0.21      0.26        63\n",
      "         2.0       0.62      0.58      0.60       149\n",
      "         3.0       0.44      0.69      0.54       159\n",
      "         4.0       0.74      0.57      0.64       180\n",
      "         5.0       0.41      0.68      0.51       157\n",
      "         6.0       0.58      0.28      0.37       109\n",
      "         7.0       0.81      0.53      0.64       118\n",
      "\n",
      "    accuracy                           0.57      1050\n",
      "   macro avg       0.60      0.54      0.55      1050\n",
      "weighted avg       0.61      0.57      0.57      1050\n",
      "\n",
      "[39,     1] loss: 0.018\n",
      "acc:0.7500 \n",
      "err:0.2500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST RESULT]\n",
      "acc:0.5695 \n",
      "err:0.4305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.84      0.66       115\n",
      "         1.0       0.23      0.97      0.38        63\n",
      "         2.0       0.80      0.44      0.57       149\n",
      "         3.0       0.88      0.43      0.58       159\n",
      "         4.0       0.81      0.54      0.65       180\n",
      "         5.0       0.59      0.56      0.58       157\n",
      "         6.0       0.54      0.54      0.54       109\n",
      "         7.0       0.87      0.51      0.64       118\n",
      "\n",
      "    accuracy                           0.57      1050\n",
      "   macro avg       0.66      0.61      0.57      1050\n",
      "weighted avg       0.70      0.57      0.59      1050\n",
      "\n",
      "[40,     1] loss: 0.039\n",
      "acc:0.5938 \n",
      "err:0.4062 \n",
      "[TEST RESULT]\n",
      "acc:0.5714 \n",
      "err:0.4286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.76      0.83       115\n",
      "         1.0       0.41      0.14      0.21        63\n",
      "         2.0       0.71      0.51      0.59       149\n",
      "         3.0       0.74      0.51      0.60       159\n",
      "         4.0       0.84      0.57      0.68       180\n",
      "         5.0       0.35      0.82      0.49       157\n",
      "         6.0       0.46      0.63      0.53       109\n",
      "         7.0       0.61      0.41      0.49       118\n",
      "\n",
      "    accuracy                           0.57      1050\n",
      "   macro avg       0.63      0.54      0.55      1050\n",
      "weighted avg       0.65      0.57      0.58      1050\n",
      "\n",
      "[41,     1] loss: 0.029\n",
      "acc:0.7188 \n",
      "err:0.2812 \n",
      "[TEST RESULT]\n",
      "acc:0.5790 \n",
      "err:0.4210\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.83      0.76       115\n",
      "         1.0       0.21      0.71      0.32        63\n",
      "         2.0       0.61      0.44      0.51       149\n",
      "         3.0       0.73      0.51      0.60       159\n",
      "         4.0       0.81      0.56      0.66       180\n",
      "         5.0       0.59      0.58      0.59       157\n",
      "         6.0       0.55      0.61      0.58       109\n",
      "         7.0       0.78      0.53      0.63       118\n",
      "\n",
      "    accuracy                           0.58      1050\n",
      "   macro avg       0.62      0.60      0.58      1050\n",
      "weighted avg       0.66      0.58      0.60      1050\n",
      "\n",
      "[42,     1] loss: 0.018\n",
      "acc:0.7500 \n",
      "err:0.2500 \n",
      "[TEST RESULT]\n",
      "acc:0.5657 \n",
      "err:0.4343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.77      0.81       115\n",
      "         1.0       0.50      0.06      0.11        63\n",
      "         2.0       0.83      0.43      0.57       149\n",
      "         3.0       0.65      0.58      0.62       159\n",
      "         4.0       0.90      0.50      0.64       180\n",
      "         5.0       0.44      0.61      0.51       157\n",
      "         6.0       0.75      0.50      0.60       109\n",
      "         7.0       0.32      0.89      0.47       118\n",
      "\n",
      "    accuracy                           0.57      1050\n",
      "   macro avg       0.66      0.54      0.54      1050\n",
      "weighted avg       0.68      0.57      0.57      1050\n",
      "\n",
      "[43,     1] loss: 0.030\n",
      "acc:0.6875 \n",
      "err:0.3125 \n",
      "[TEST RESULT]\n",
      "acc:0.6019 \n",
      "err:0.3981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.82      0.78       115\n",
      "         1.0       0.33      0.54      0.41        63\n",
      "         2.0       0.61      0.58      0.59       149\n",
      "         3.0       0.93      0.52      0.66       159\n",
      "         4.0       0.88      0.48      0.62       180\n",
      "         5.0       0.57      0.61      0.59       157\n",
      "         6.0       0.71      0.58      0.64       109\n",
      "         7.0       0.38      0.78      0.52       118\n",
      "\n",
      "    accuracy                           0.60      1050\n",
      "   macro avg       0.64      0.61      0.60      1050\n",
      "weighted avg       0.68      0.60      0.61      1050\n",
      "\n",
      "[44,     1] loss: 0.015\n",
      "acc:0.8438 \n",
      "err:0.1562 \n",
      "[TEST RESULT]\n",
      "acc:0.5848 \n",
      "err:0.4152\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.85      0.65       115\n",
      "         1.0       0.35      0.54      0.42        63\n",
      "         2.0       0.61      0.52      0.57       149\n",
      "         3.0       0.84      0.48      0.61       159\n",
      "         4.0       0.75      0.53      0.62       180\n",
      "         5.0       0.51      0.59      0.54       157\n",
      "         6.0       0.46      0.60      0.52       109\n",
      "         7.0       0.77      0.64      0.70       118\n",
      "\n",
      "    accuracy                           0.58      1050\n",
      "   macro avg       0.60      0.59      0.58      1050\n",
      "weighted avg       0.63      0.58      0.59      1050\n",
      "\n",
      "[45,     1] loss: 0.016\n",
      "acc:0.7812 \n",
      "err:0.2188 \n",
      "[TEST RESULT]\n",
      "acc:0.6076 \n",
      "err:0.3924\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.79      0.76       115\n",
      "         1.0       0.22      0.75      0.34        63\n",
      "         2.0       0.58      0.60      0.59       149\n",
      "         3.0       0.88      0.54      0.67       159\n",
      "         4.0       0.90      0.52      0.66       180\n",
      "         5.0       0.68      0.58      0.63       157\n",
      "         6.0       0.54      0.64      0.59       109\n",
      "         7.0       0.78      0.58      0.67       118\n",
      "\n",
      "    accuracy                           0.61      1050\n",
      "   macro avg       0.66      0.63      0.61      1050\n",
      "weighted avg       0.71      0.61      0.63      1050\n",
      "\n",
      "[46,     1] loss: 0.016\n",
      "acc:0.8125 \n",
      "err:0.1875 \n",
      "[TEST RESULT]\n",
      "acc:0.6133 \n",
      "err:0.3867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.77      0.83       115\n",
      "         1.0       0.50      0.24      0.32        63\n",
      "         2.0       0.59      0.62      0.60       149\n",
      "         3.0       0.90      0.52      0.66       159\n",
      "         4.0       0.76      0.62      0.69       180\n",
      "         5.0       0.48      0.71      0.58       157\n",
      "         6.0       0.36      0.74      0.49       109\n",
      "         7.0       0.84      0.53      0.65       118\n",
      "\n",
      "    accuracy                           0.61      1050\n",
      "   macro avg       0.67      0.59      0.60      1050\n",
      "weighted avg       0.68      0.61      0.62      1050\n",
      "\n",
      "[47,     1] loss: 0.017\n",
      "acc:0.8438 \n",
      "err:0.1562 \n",
      "[TEST RESULT]\n",
      "acc:0.5962 \n",
      "err:0.4038\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.83      0.73       115\n",
      "         1.0       0.52      0.19      0.28        63\n",
      "         2.0       0.57      0.62      0.59       149\n",
      "         3.0       0.61      0.59      0.60       159\n",
      "         4.0       0.86      0.50      0.63       180\n",
      "         5.0       0.45      0.72      0.55       157\n",
      "         6.0       0.87      0.41      0.56       109\n",
      "         7.0       0.53      0.72      0.61       118\n",
      "\n",
      "    accuracy                           0.60      1050\n",
      "   macro avg       0.63      0.57      0.57      1050\n",
      "weighted avg       0.64      0.60      0.59      1050\n",
      "\n",
      "[48,     1] loss: 0.024\n",
      "acc:0.7188 \n",
      "err:0.2812 \n",
      "[TEST RESULT]\n",
      "acc:0.5876 \n",
      "err:0.4124\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.83      0.74       115\n",
      "         1.0       0.24      0.92      0.39        63\n",
      "         2.0       0.68      0.46      0.55       149\n",
      "         3.0       0.74      0.55      0.63       159\n",
      "         4.0       0.86      0.51      0.64       180\n",
      "         5.0       0.62      0.57      0.60       157\n",
      "         6.0       0.55      0.61      0.58       109\n",
      "         7.0       0.74      0.52      0.61       118\n",
      "\n",
      "    accuracy                           0.59      1050\n",
      "   macro avg       0.64      0.62      0.59      1050\n",
      "weighted avg       0.68      0.59      0.60      1050\n",
      "\n",
      "[49,     1] loss: 0.022\n",
      "acc:0.7188 \n",
      "err:0.2812 \n",
      "[TEST RESULT]\n",
      "acc:0.5971 \n",
      "err:0.4029\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.81      0.72       115\n",
      "         1.0       0.44      0.11      0.18        63\n",
      "         2.0       0.62      0.66      0.64       149\n",
      "         3.0       0.39      0.84      0.53       159\n",
      "         4.0       0.69      0.67      0.68       180\n",
      "         5.0       0.71      0.50      0.58       157\n",
      "         6.0       0.92      0.41      0.57       109\n",
      "         7.0       0.98      0.43      0.60       118\n",
      "\n",
      "    accuracy                           0.60      1050\n",
      "   macro avg       0.67      0.55      0.56      1050\n",
      "weighted avg       0.67      0.60      0.59      1050\n",
      "\n",
      "[50,     1] loss: 0.021\n",
      "acc:0.9062 \n",
      "err:0.0938 \n",
      "[TEST RESULT]\n",
      "acc:0.6210 \n",
      "err:0.3790\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.78      0.83       115\n",
      "         1.0       0.25      0.70      0.36        63\n",
      "         2.0       0.66      0.61      0.63       149\n",
      "         3.0       0.67      0.57      0.62       159\n",
      "         4.0       0.72      0.63      0.67       180\n",
      "         5.0       0.50      0.65      0.57       157\n",
      "         6.0       0.85      0.50      0.63       109\n",
      "         7.0       0.93      0.56      0.70       118\n",
      "\n",
      "    accuracy                           0.62      1050\n",
      "   macro avg       0.68      0.63      0.63      1050\n",
      "weighted avg       0.70      0.62      0.64      1050\n",
      "\n",
      "[51,     1] loss: 0.018\n",
      "acc:0.8125 \n",
      "err:0.1875 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST RESULT]\n",
      "acc:0.5857 \n",
      "err:0.4143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.77      0.83       115\n",
      "         1.0       0.27      0.78      0.40        63\n",
      "         2.0       0.73      0.43      0.54       149\n",
      "         3.0       0.79      0.55      0.65       159\n",
      "         4.0       0.79      0.59      0.68       180\n",
      "         5.0       0.46      0.72      0.56       157\n",
      "         6.0       0.51      0.50      0.50       109\n",
      "         7.0       0.60      0.44      0.51       118\n",
      "\n",
      "    accuracy                           0.59      1050\n",
      "   macro avg       0.63      0.60      0.58      1050\n",
      "weighted avg       0.66      0.59      0.60      1050\n",
      "\n",
      "[52,     1] loss: 0.017\n",
      "acc:0.7812 \n",
      "err:0.2188 \n",
      "[TEST RESULT]\n",
      "acc:0.5552 \n",
      "err:0.4448\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.81      0.79       115\n",
      "         1.0       0.74      0.22      0.34        63\n",
      "         2.0       0.79      0.44      0.57       149\n",
      "         3.0       0.45      0.64      0.53       159\n",
      "         4.0       0.87      0.38      0.53       180\n",
      "         5.0       0.39      0.69      0.50       157\n",
      "         6.0       0.69      0.42      0.52       109\n",
      "         7.0       0.50      0.71      0.59       118\n",
      "\n",
      "    accuracy                           0.56      1050\n",
      "   macro avg       0.65      0.54      0.55      1050\n",
      "weighted avg       0.64      0.56      0.55      1050\n",
      "\n",
      "[53,     1] loss: 0.036\n",
      "acc:0.5312 \n",
      "err:0.4688 \n",
      "[TEST RESULT]\n",
      "acc:0.5752 \n",
      "err:0.4248\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.83      0.77       115\n",
      "         1.0       0.42      0.32      0.36        63\n",
      "         2.0       0.81      0.48      0.60       149\n",
      "         3.0       0.88      0.45      0.60       159\n",
      "         4.0       0.73      0.59      0.65       180\n",
      "         5.0       0.62      0.53      0.57       157\n",
      "         6.0       0.28      0.92      0.43       109\n",
      "         7.0       0.87      0.47      0.61       118\n",
      "\n",
      "    accuracy                           0.58      1050\n",
      "   macro avg       0.66      0.57      0.57      1050\n",
      "weighted avg       0.70      0.58      0.59      1050\n",
      "\n",
      "[54,     1] loss: 0.022\n",
      "acc:0.6875 \n",
      "err:0.3125 \n",
      "[TEST RESULT]\n",
      "acc:0.5971 \n",
      "err:0.4029\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.81      0.77       115\n",
      "         1.0       0.44      0.06      0.11        63\n",
      "         2.0       0.40      0.74      0.52       149\n",
      "         3.0       0.62      0.58      0.60       159\n",
      "         4.0       0.81      0.58      0.67       180\n",
      "         5.0       0.59      0.59      0.59       157\n",
      "         6.0       0.76      0.48      0.59       109\n",
      "         7.0       0.58      0.67      0.62       118\n",
      "\n",
      "    accuracy                           0.60      1050\n",
      "   macro avg       0.62      0.56      0.56      1050\n",
      "weighted avg       0.63      0.60      0.59      1050\n",
      "\n",
      "[55,     1] loss: 0.035\n",
      "acc:0.7188 \n",
      "err:0.2812 \n",
      "[TEST RESULT]\n",
      "acc:0.6143 \n",
      "err:0.3857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.80      0.78       115\n",
      "         1.0       0.53      0.30      0.38        63\n",
      "         2.0       0.64      0.56      0.60       149\n",
      "         3.0       0.47      0.68      0.55       159\n",
      "         4.0       0.67      0.66      0.66       180\n",
      "         5.0       0.55      0.64      0.59       157\n",
      "         6.0       0.61      0.55      0.58       109\n",
      "         7.0       0.86      0.54      0.67       118\n",
      "\n",
      "    accuracy                           0.61      1050\n",
      "   macro avg       0.64      0.59      0.60      1050\n",
      "weighted avg       0.63      0.61      0.61      1050\n",
      "\n",
      "[56,     1] loss: 0.019\n",
      "acc:0.7188 \n",
      "err:0.2812 \n",
      "[TEST RESULT]\n",
      "acc:0.6057 \n",
      "err:0.3943\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.81      0.78       115\n",
      "         1.0       0.38      0.25      0.30        63\n",
      "         2.0       0.73      0.46      0.57       149\n",
      "         3.0       0.89      0.55      0.68       159\n",
      "         4.0       0.60      0.74      0.67       180\n",
      "         5.0       0.35      0.75      0.48       157\n",
      "         6.0       0.84      0.51      0.64       109\n",
      "         7.0       0.90      0.53      0.67       118\n",
      "\n",
      "    accuracy                           0.61      1050\n",
      "   macro avg       0.68      0.58      0.60      1050\n",
      "weighted avg       0.69      0.61      0.61      1050\n",
      "\n",
      "[57,     1] loss: 0.020\n",
      "acc:0.8125 \n",
      "err:0.1875 \n",
      "[TEST RESULT]\n",
      "acc:0.6152 \n",
      "err:0.3848\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.84      0.70       115\n",
      "         1.0       0.40      0.35      0.37        63\n",
      "         2.0       0.57      0.62      0.59       149\n",
      "         3.0       0.86      0.51      0.64       159\n",
      "         4.0       0.71      0.64      0.67       180\n",
      "         5.0       0.72      0.52      0.60       157\n",
      "         6.0       0.42      0.83      0.56       109\n",
      "         7.0       0.77      0.57      0.65       118\n",
      "\n",
      "    accuracy                           0.62      1050\n",
      "   macro avg       0.63      0.61      0.60      1050\n",
      "weighted avg       0.66      0.62      0.62      1050\n",
      "\n",
      "[58,     1] loss: 0.010\n",
      "acc:0.8750 \n",
      "err:0.1250 \n",
      "[TEST RESULT]\n",
      "acc:0.6181 \n",
      "err:0.3819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.82      0.71       115\n",
      "         1.0       0.34      0.65      0.44        63\n",
      "         2.0       0.75      0.52      0.62       149\n",
      "         3.0       0.86      0.55      0.67       159\n",
      "         4.0       0.84      0.55      0.66       180\n",
      "         5.0       0.51      0.68      0.58       157\n",
      "         6.0       0.51      0.73      0.60       109\n",
      "         7.0       0.70      0.54      0.61       118\n",
      "\n",
      "    accuracy                           0.62      1050\n",
      "   macro avg       0.64      0.63      0.61      1050\n",
      "weighted avg       0.68      0.62      0.63      1050\n",
      "\n",
      "[59,     1] loss: 0.010\n",
      "acc:0.8125 \n",
      "err:0.1875 \n",
      "[TEST RESULT]\n",
      "acc:0.6238 \n",
      "err:0.3762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.83      0.76       115\n",
      "         1.0       0.32      0.51      0.40        63\n",
      "         2.0       0.52      0.69      0.60       149\n",
      "         3.0       0.57      0.65      0.60       159\n",
      "         4.0       0.80      0.55      0.65       180\n",
      "         5.0       0.59      0.58      0.58       157\n",
      "         6.0       0.77      0.64      0.70       109\n",
      "         7.0       0.90      0.53      0.66       118\n",
      "\n",
      "    accuracy                           0.62      1050\n",
      "   macro avg       0.65      0.62      0.62      1050\n",
      "weighted avg       0.66      0.62      0.63      1050\n",
      "\n",
      "[60,     1] loss: 0.011\n",
      "acc:0.8750 \n",
      "err:0.1250 \n",
      "[TEST RESULT]\n",
      "acc:0.6438 \n",
      "err:0.3562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.83      0.81       115\n",
      "         1.0       0.54      0.44      0.49        63\n",
      "         2.0       0.61      0.60      0.61       149\n",
      "         3.0       0.64      0.62      0.63       159\n",
      "         4.0       0.72      0.66      0.69       180\n",
      "         5.0       0.48      0.71      0.57       157\n",
      "         6.0       0.77      0.61      0.68       109\n",
      "         7.0       0.73      0.58      0.65       118\n",
      "\n",
      "    accuracy                           0.64      1050\n",
      "   macro avg       0.66      0.63      0.64      1050\n",
      "weighted avg       0.66      0.64      0.65      1050\n",
      "\n",
      "[61,     1] loss: 0.008\n",
      "acc:0.9375 \n",
      "err:0.0625 \n",
      "[TEST RESULT]\n",
      "acc:0.5914 \n",
      "err:0.4086\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.88      0.63       115\n",
      "         1.0       0.42      0.41      0.42        63\n",
      "         2.0       0.75      0.47      0.58       149\n",
      "         3.0       0.57      0.55      0.56       159\n",
      "         4.0       0.91      0.49      0.64       180\n",
      "         5.0       0.82      0.48      0.60       157\n",
      "         6.0       0.38      0.85      0.53       109\n",
      "         7.0       0.75      0.68      0.71       118\n",
      "\n",
      "    accuracy                           0.59      1050\n",
      "   macro avg       0.64      0.60      0.58      1050\n",
      "weighted avg       0.68      0.59      0.60      1050\n",
      "\n",
      "[62,     1] loss: 0.016\n",
      "acc:0.7812 \n",
      "err:0.2188 \n",
      "[TEST RESULT]\n",
      "acc:0.5914 \n",
      "err:0.4086\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.76      0.85       115\n",
      "         1.0       0.40      0.06      0.11        63\n",
      "         2.0       0.62      0.56      0.59       149\n",
      "         3.0       0.39      0.84      0.53       159\n",
      "         4.0       0.68      0.65      0.67       180\n",
      "         5.0       0.52      0.66      0.58       157\n",
      "         6.0       0.86      0.46      0.60       109\n",
      "         7.0       1.00      0.36      0.53       118\n",
      "\n",
      "    accuracy                           0.59      1050\n",
      "   macro avg       0.68      0.54      0.56      1050\n",
      "weighted avg       0.67      0.59      0.59      1050\n",
      "\n",
      "[63,     1] loss: 0.028\n",
      "acc:0.7500 \n",
      "err:0.2500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST RESULT]\n",
      "acc:0.5924 \n",
      "err:0.4076\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.85      0.72       115\n",
      "         1.0       0.44      0.29      0.35        63\n",
      "         2.0       0.57      0.51      0.54       149\n",
      "         3.0       0.45      0.72      0.55       159\n",
      "         4.0       0.81      0.53      0.64       180\n",
      "         5.0       0.64      0.52      0.58       157\n",
      "         6.0       0.66      0.60      0.63       109\n",
      "         7.0       0.61      0.62      0.61       118\n",
      "\n",
      "    accuracy                           0.59      1050\n",
      "   macro avg       0.60      0.58      0.58      1050\n",
      "weighted avg       0.62      0.59      0.59      1050\n",
      "\n",
      "[64,     1] loss: 0.013\n",
      "acc:0.8125 \n",
      "err:0.1875 \n",
      "[TEST RESULT]\n",
      "acc:0.6067 \n",
      "err:0.3933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.78      0.80       115\n",
      "         1.0       0.58      0.29      0.38        63\n",
      "         2.0       0.62      0.56      0.59       149\n",
      "         3.0       0.58      0.63      0.60       159\n",
      "         4.0       0.82      0.53      0.64       180\n",
      "         5.0       0.54      0.61      0.57       157\n",
      "         6.0       0.67      0.58      0.62       109\n",
      "         7.0       0.43      0.77      0.55       118\n",
      "\n",
      "    accuracy                           0.61      1050\n",
      "   macro avg       0.63      0.59      0.60      1050\n",
      "weighted avg       0.64      0.61      0.61      1050\n",
      "\n",
      "[65,     1] loss: 0.014\n",
      "acc:0.8125 \n",
      "err:0.1875 \n",
      "[TEST RESULT]\n",
      "acc:0.6133 \n",
      "err:0.3867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.78      0.83       115\n",
      "         1.0       0.33      0.11      0.17        63\n",
      "         2.0       0.50      0.61      0.55       149\n",
      "         3.0       0.65      0.58      0.62       159\n",
      "         4.0       0.48      0.85      0.61       180\n",
      "         5.0       0.61      0.56      0.58       157\n",
      "         6.0       0.89      0.50      0.64       109\n",
      "         7.0       0.86      0.58      0.69       118\n",
      "\n",
      "    accuracy                           0.61      1050\n",
      "   macro avg       0.65      0.57      0.59      1050\n",
      "weighted avg       0.65      0.61      0.61      1050\n",
      "\n",
      "[66,     1] loss: 0.022\n",
      "acc:0.8438 \n",
      "err:0.1562 \n",
      "[TEST RESULT]\n",
      "acc:0.6029 \n",
      "err:0.3971\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.80      0.76       115\n",
      "         1.0       0.25      0.60      0.35        63\n",
      "         2.0       0.72      0.48      0.57       149\n",
      "         3.0       0.70      0.58      0.63       159\n",
      "         4.0       0.78      0.57      0.66       180\n",
      "         5.0       0.52      0.60      0.56       157\n",
      "         6.0       0.55      0.69      0.61       109\n",
      "         7.0       0.75      0.58      0.65       118\n",
      "\n",
      "    accuracy                           0.60      1050\n",
      "   macro avg       0.62      0.61      0.60      1050\n",
      "weighted avg       0.65      0.60      0.61      1050\n",
      "\n",
      "[67,     1] loss: 0.014\n",
      "acc:0.9062 \n",
      "err:0.0938 \n",
      "[TEST RESULT]\n",
      "acc:0.6276 \n",
      "err:0.3724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.78      0.76       115\n",
      "         1.0       0.67      0.13      0.21        63\n",
      "         2.0       0.47      0.67      0.55       149\n",
      "         3.0       0.82      0.57      0.67       159\n",
      "         4.0       0.60      0.73      0.66       180\n",
      "         5.0       0.70      0.53      0.60       157\n",
      "         6.0       0.50      0.76      0.60       109\n",
      "         7.0       0.82      0.62      0.71       118\n",
      "\n",
      "    accuracy                           0.63      1050\n",
      "   macro avg       0.66      0.60      0.60      1050\n",
      "weighted avg       0.66      0.63      0.62      1050\n",
      "\n",
      "[68,     1] loss: 0.022\n",
      "acc:0.7812 \n",
      "err:0.2188 \n",
      "[TEST RESULT]\n",
      "acc:0.6152 \n",
      "err:0.3848\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.80      0.81       115\n",
      "         1.0       0.29      0.52      0.37        63\n",
      "         2.0       0.58      0.57      0.58       149\n",
      "         3.0       0.46      0.72      0.56       159\n",
      "         4.0       0.76      0.58      0.66       180\n",
      "         5.0       0.65      0.56      0.60       157\n",
      "         6.0       0.79      0.59      0.67       109\n",
      "         7.0       0.92      0.55      0.69       118\n",
      "\n",
      "    accuracy                           0.62      1050\n",
      "   macro avg       0.66      0.61      0.62      1050\n",
      "weighted avg       0.67      0.62      0.63      1050\n",
      "\n",
      "[69,     1] loss: 0.008\n",
      "acc:0.9062 \n",
      "err:0.0938 \n",
      "[TEST RESULT]\n",
      "acc:0.6267 \n",
      "err:0.3733\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.83      0.74       115\n",
      "         1.0       0.37      0.56      0.45        63\n",
      "         2.0       0.56      0.62      0.59       149\n",
      "         3.0       0.86      0.55      0.67       159\n",
      "         4.0       0.78      0.56      0.65       180\n",
      "         5.0       0.73      0.52      0.60       157\n",
      "         6.0       0.51      0.74      0.60       109\n",
      "         7.0       0.58      0.71      0.64       118\n",
      "\n",
      "    accuracy                           0.63      1050\n",
      "   macro avg       0.63      0.64      0.62      1050\n",
      "weighted avg       0.67      0.63      0.63      1050\n",
      "\n",
      "[70,     1] loss: 0.010\n",
      "acc:0.8750 \n",
      "err:0.1250 \n",
      "[TEST RESULT]\n",
      "acc:0.6305 \n",
      "err:0.3695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.79      0.81       115\n",
      "         1.0       0.36      0.51      0.42        63\n",
      "         2.0       0.51      0.60      0.55       149\n",
      "         3.0       0.59      0.60      0.59       159\n",
      "         4.0       0.72      0.67      0.69       180\n",
      "         5.0       0.61      0.62      0.62       157\n",
      "         6.0       0.65      0.68      0.66       109\n",
      "         7.0       0.88      0.53      0.66       118\n",
      "\n",
      "    accuracy                           0.63      1050\n",
      "   macro avg       0.64      0.62      0.63      1050\n",
      "weighted avg       0.65      0.63      0.64      1050\n",
      "\n",
      "[71,     1] loss: 0.003\n",
      "acc:1.0000 \n",
      "err:0.0000 \n",
      "[TEST RESULT]\n",
      "acc:0.6019 \n",
      "err:0.3981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.83      0.71       115\n",
      "         1.0       0.38      0.40      0.39        63\n",
      "         2.0       0.50      0.61      0.55       149\n",
      "         3.0       0.93      0.48      0.63       159\n",
      "         4.0       0.86      0.53      0.66       180\n",
      "         5.0       0.47      0.71      0.57       157\n",
      "         6.0       0.54      0.72      0.62       109\n",
      "         7.0       0.76      0.51      0.61       118\n",
      "\n",
      "    accuracy                           0.60      1050\n",
      "   macro avg       0.63      0.60      0.59      1050\n",
      "weighted avg       0.66      0.60      0.61      1050\n",
      "\n",
      "[72,     1] loss: 0.034\n",
      "acc:0.7188 \n",
      "err:0.2812 \n",
      "[TEST RESULT]\n",
      "acc:0.5381 \n",
      "err:0.4619\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.76      0.83       115\n",
      "         1.0       0.63      0.19      0.29        63\n",
      "         2.0       0.68      0.52      0.59       149\n",
      "         3.0       0.49      0.30      0.37       159\n",
      "         4.0       0.87      0.54      0.67       180\n",
      "         5.0       0.54      0.66      0.60       157\n",
      "         6.0       0.36      0.41      0.38       109\n",
      "         7.0       0.32      0.81      0.46       118\n",
      "\n",
      "    accuracy                           0.54      1050\n",
      "   macro avg       0.60      0.52      0.52      1050\n",
      "weighted avg       0.61      0.54      0.54      1050\n",
      "\n",
      "[73,     1] loss: 0.027\n",
      "acc:0.8125 \n",
      "err:0.1875 \n",
      "[TEST RESULT]\n",
      "acc:0.5581 \n",
      "err:0.4419\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.90      0.54       115\n",
      "         1.0       0.25      0.78      0.38        63\n",
      "         2.0       0.85      0.38      0.53       149\n",
      "         3.0       0.71      0.48      0.57       159\n",
      "         4.0       0.85      0.47      0.61       180\n",
      "         5.0       0.61      0.58      0.60       157\n",
      "         6.0       0.65      0.56      0.60       109\n",
      "         7.0       0.89      0.53      0.67       118\n",
      "\n",
      "    accuracy                           0.56      1050\n",
      "   macro avg       0.65      0.59      0.56      1050\n",
      "weighted avg       0.69      0.56      0.57      1050\n",
      "\n",
      "[74,     1] loss: 0.071\n",
      "acc:0.5938 \n",
      "err:0.4062 \n",
      "[TEST RESULT]\n",
      "acc:0.5048 \n",
      "err:0.4952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.57      0.72       115\n",
      "         1.0       0.23      0.22      0.23        63\n",
      "         2.0       0.43      0.59      0.50       149\n",
      "         3.0       0.47      0.64      0.54       159\n",
      "         4.0       0.89      0.45      0.60       180\n",
      "         5.0       0.41      0.71      0.52       157\n",
      "         6.0       0.58      0.34      0.43       109\n",
      "         7.0       0.43      0.28      0.34       118\n",
      "\n",
      "    accuracy                           0.50      1050\n",
      "   macro avg       0.55      0.47      0.48      1050\n",
      "weighted avg       0.58      0.50      0.51      1050\n",
      "\n",
      "[75,     1] loss: 0.031\n",
      "acc:0.7500 \n",
      "err:0.2500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST RESULT]\n",
      "acc:0.6105 \n",
      "err:0.3895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.85      0.64       115\n",
      "         1.0       0.51      0.35      0.42        63\n",
      "         2.0       0.58      0.56      0.57       149\n",
      "         3.0       0.68      0.53      0.60       159\n",
      "         4.0       0.74      0.64      0.68       180\n",
      "         5.0       0.57      0.62      0.59       157\n",
      "         6.0       0.54      0.72      0.62       109\n",
      "         7.0       0.81      0.53      0.64       118\n",
      "\n",
      "    accuracy                           0.61      1050\n",
      "   macro avg       0.62      0.60      0.59      1050\n",
      "weighted avg       0.63      0.61      0.61      1050\n",
      "\n",
      "[76,     1] loss: 0.021\n",
      "acc:0.7188 \n",
      "err:0.2812 \n",
      "[TEST RESULT]\n",
      "acc:0.5190 \n",
      "err:0.4810\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.83      0.63       115\n",
      "         1.0       0.28      0.43      0.34        63\n",
      "         2.0       0.67      0.50      0.57       149\n",
      "         3.0       0.50      0.36      0.42       159\n",
      "         4.0       0.57      0.69      0.63       180\n",
      "         5.0       0.42      0.64      0.51       157\n",
      "         6.0       0.76      0.26      0.38       109\n",
      "         7.0       0.82      0.31      0.45       118\n",
      "\n",
      "    accuracy                           0.52      1050\n",
      "   macro avg       0.57      0.50      0.49      1050\n",
      "weighted avg       0.58      0.52      0.51      1050\n",
      "\n",
      "[77,     1] loss: 0.028\n",
      "acc:0.7188 \n",
      "err:0.2812 \n",
      "[TEST RESULT]\n",
      "acc:0.6019 \n",
      "err:0.3981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.83      0.67       115\n",
      "         1.0       0.36      0.67      0.47        63\n",
      "         2.0       0.69      0.46      0.55       149\n",
      "         3.0       0.60      0.55      0.57       159\n",
      "         4.0       0.88      0.53      0.66       180\n",
      "         5.0       0.65      0.59      0.62       157\n",
      "         6.0       0.58      0.62      0.60       109\n",
      "         7.0       0.56      0.70      0.62       118\n",
      "\n",
      "    accuracy                           0.60      1050\n",
      "   macro avg       0.61      0.62      0.60      1050\n",
      "weighted avg       0.64      0.60      0.60      1050\n",
      "\n",
      "[78,     1] loss: 0.012\n",
      "acc:0.8438 \n",
      "err:0.1562 \n",
      "[TEST RESULT]\n",
      "acc:0.6000 \n",
      "err:0.4000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.82      0.69       115\n",
      "         1.0       0.29      0.48      0.36        63\n",
      "         2.0       0.70      0.54      0.61       149\n",
      "         3.0       0.90      0.55      0.68       159\n",
      "         4.0       0.81      0.53      0.64       180\n",
      "         5.0       0.39      0.71      0.51       157\n",
      "         6.0       0.65      0.62      0.64       109\n",
      "         7.0       0.90      0.53      0.67       118\n",
      "\n",
      "    accuracy                           0.60      1050\n",
      "   macro avg       0.65      0.60      0.60      1050\n",
      "weighted avg       0.68      0.60      0.61      1050\n",
      "\n",
      "[79,     1] loss: 0.011\n",
      "acc:0.8438 \n",
      "err:0.1562 \n",
      "[TEST RESULT]\n",
      "acc:0.6010 \n",
      "err:0.3990\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.79      0.79       115\n",
      "         1.0       0.26      0.38      0.31        63\n",
      "         2.0       0.45      0.60      0.51       149\n",
      "         3.0       0.60      0.60      0.60       159\n",
      "         4.0       0.57      0.73      0.64       180\n",
      "         5.0       0.71      0.48      0.58       157\n",
      "         6.0       0.81      0.56      0.66       109\n",
      "         7.0       0.88      0.53      0.66       118\n",
      "\n",
      "    accuracy                           0.60      1050\n",
      "   macro avg       0.63      0.58      0.59      1050\n",
      "weighted avg       0.64      0.60      0.61      1050\n",
      "\n",
      "[80,     1] loss: 0.015\n",
      "acc:0.8438 \n",
      "err:0.1562 \n",
      "[TEST RESULT]\n",
      "acc:0.6133 \n",
      "err:0.3867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.82      0.73       115\n",
      "         1.0       0.51      0.40      0.45        63\n",
      "         2.0       0.53      0.66      0.59       149\n",
      "         3.0       0.68      0.57      0.62       159\n",
      "         4.0       0.84      0.54      0.66       180\n",
      "         5.0       0.73      0.48      0.58       157\n",
      "         6.0       0.68      0.67      0.67       109\n",
      "         7.0       0.43      0.77      0.55       118\n",
      "\n",
      "    accuracy                           0.61      1050\n",
      "   macro avg       0.63      0.61      0.61      1050\n",
      "weighted avg       0.65      0.61      0.61      1050\n",
      "\n",
      "[81,     1] loss: 0.008\n",
      "acc:0.9375 \n",
      "err:0.0625 \n",
      "[TEST RESULT]\n",
      "acc:0.5895 \n",
      "err:0.4105\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.54      0.67       115\n",
      "         1.0       0.29      0.44      0.35        63\n",
      "         2.0       0.68      0.50      0.58       149\n",
      "         3.0       0.61      0.55      0.58       159\n",
      "         4.0       0.83      0.58      0.68       180\n",
      "         5.0       0.43      0.74      0.54       157\n",
      "         6.0       0.64      0.54      0.59       109\n",
      "         7.0       0.61      0.74      0.67       118\n",
      "\n",
      "    accuracy                           0.59      1050\n",
      "   macro avg       0.62      0.58      0.58      1050\n",
      "weighted avg       0.64      0.59      0.60      1050\n",
      "\n",
      "[82,     1] loss: 0.013\n",
      "acc:0.8438 \n",
      "err:0.1562 \n",
      "[TEST RESULT]\n",
      "acc:0.6067 \n",
      "err:0.3933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.79      0.77       115\n",
      "         1.0       0.37      0.40      0.38        63\n",
      "         2.0       0.66      0.54      0.59       149\n",
      "         3.0       0.57      0.65      0.60       159\n",
      "         4.0       0.81      0.51      0.63       180\n",
      "         5.0       0.42      0.78      0.55       157\n",
      "         6.0       0.85      0.49      0.62       109\n",
      "         7.0       0.76      0.60      0.67       118\n",
      "\n",
      "    accuracy                           0.61      1050\n",
      "   macro avg       0.65      0.59      0.60      1050\n",
      "weighted avg       0.66      0.61      0.61      1050\n",
      "\n",
      "[83,     1] loss: 0.014\n",
      "acc:0.7500 \n",
      "err:0.2500 \n",
      "[TEST RESULT]\n",
      "acc:0.6324 \n",
      "err:0.3676\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.81      0.77       115\n",
      "         1.0       0.35      0.48      0.40        63\n",
      "         2.0       0.64      0.60      0.62       149\n",
      "         3.0       0.72      0.60      0.66       159\n",
      "         4.0       0.75      0.63      0.68       180\n",
      "         5.0       0.49      0.62      0.55       157\n",
      "         6.0       0.62      0.68      0.65       109\n",
      "         7.0       0.77      0.59      0.67       118\n",
      "\n",
      "    accuracy                           0.63      1050\n",
      "   macro avg       0.63      0.63      0.62      1050\n",
      "weighted avg       0.65      0.63      0.64      1050\n",
      "\n",
      "[84,     1] loss: 0.005\n",
      "acc:0.9062 \n",
      "err:0.0938 \n",
      "[TEST RESULT]\n",
      "acc:0.5914 \n",
      "err:0.4086\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.41      0.88      0.56       115\n",
      "         1.0       0.30      0.56      0.39        63\n",
      "         2.0       0.60      0.58      0.59       149\n",
      "         3.0       0.84      0.55      0.67       159\n",
      "         4.0       0.84      0.54      0.66       180\n",
      "         5.0       0.66      0.48      0.56       157\n",
      "         6.0       0.66      0.60      0.62       109\n",
      "         7.0       0.67      0.61      0.64       118\n",
      "\n",
      "    accuracy                           0.59      1050\n",
      "   macro avg       0.62      0.60      0.59      1050\n",
      "weighted avg       0.66      0.59      0.60      1050\n",
      "\n",
      "[85,     1] loss: 0.016\n",
      "acc:0.8125 \n",
      "err:0.1875 \n",
      "[TEST RESULT]\n",
      "acc:0.5743 \n",
      "err:0.4257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      0.97      0.49       115\n",
      "         1.0       0.39      0.38      0.38        63\n",
      "         2.0       0.83      0.42      0.56       149\n",
      "         3.0       0.86      0.45      0.59       159\n",
      "         4.0       0.87      0.52      0.65       180\n",
      "         5.0       0.62      0.62      0.62       157\n",
      "         6.0       0.73      0.56      0.63       109\n",
      "         7.0       0.58      0.69      0.63       118\n",
      "\n",
      "    accuracy                           0.57      1050\n",
      "   macro avg       0.65      0.58      0.57      1050\n",
      "weighted avg       0.69      0.57      0.59      1050\n",
      "\n",
      "[86,     1] loss: 0.009\n",
      "acc:0.8438 \n",
      "err:0.1562 \n",
      "[TEST RESULT]\n",
      "acc:0.5019 \n",
      "err:0.4981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.48      0.64       115\n",
      "         1.0       0.51      0.29      0.37        63\n",
      "         2.0       0.54      0.48      0.51       149\n",
      "         3.0       0.41      0.64      0.50       159\n",
      "         4.0       0.93      0.41      0.57       180\n",
      "         5.0       0.36      0.73      0.48       157\n",
      "         6.0       0.46      0.39      0.43       109\n",
      "         7.0       0.55      0.42      0.48       118\n",
      "\n",
      "    accuracy                           0.50      1050\n",
      "   macro avg       0.59      0.48      0.50      1050\n",
      "weighted avg       0.60      0.50      0.51      1050\n",
      "\n",
      "[87,     1] loss: 0.027\n",
      "acc:0.7500 \n",
      "err:0.2500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST RESULT]\n",
      "acc:0.5886 \n",
      "err:0.4114\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.83      0.76       115\n",
      "         1.0       0.40      0.30      0.35        63\n",
      "         2.0       0.43      0.72      0.53       149\n",
      "         3.0       0.51      0.70      0.59       159\n",
      "         4.0       0.71      0.51      0.59       180\n",
      "         5.0       0.71      0.52      0.60       157\n",
      "         6.0       0.75      0.33      0.46       109\n",
      "         7.0       0.72      0.64      0.68       118\n",
      "\n",
      "    accuracy                           0.59      1050\n",
      "   macro avg       0.62      0.57      0.57      1050\n",
      "weighted avg       0.62      0.59      0.58      1050\n",
      "\n",
      "[88,     1] loss: 0.040\n",
      "acc:0.6875 \n",
      "err:0.3125 \n",
      "[TEST RESULT]\n",
      "acc:0.5695 \n",
      "err:0.4305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.83      0.74       115\n",
      "         1.0       0.43      0.24      0.31        63\n",
      "         2.0       0.55      0.58      0.56       149\n",
      "         3.0       0.70      0.52      0.59       159\n",
      "         4.0       0.91      0.47      0.62       180\n",
      "         5.0       0.74      0.48      0.58       157\n",
      "         6.0       0.72      0.50      0.59       109\n",
      "         7.0       0.32      0.90      0.48       118\n",
      "\n",
      "    accuracy                           0.57      1050\n",
      "   macro avg       0.63      0.56      0.56      1050\n",
      "weighted avg       0.66      0.57      0.58      1050\n",
      "\n",
      "[89,     1] loss: 0.021\n",
      "acc:0.7812 \n",
      "err:0.2188 \n",
      "[TEST RESULT]\n",
      "acc:0.6181 \n",
      "err:0.3819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.81      0.78       115\n",
      "         1.0       0.36      0.49      0.42        63\n",
      "         2.0       0.67      0.54      0.59       149\n",
      "         3.0       0.65      0.55      0.60       159\n",
      "         4.0       0.76      0.59      0.66       180\n",
      "         5.0       0.54      0.62      0.58       157\n",
      "         6.0       0.50      0.66      0.57       109\n",
      "         7.0       0.69      0.69      0.69       118\n",
      "\n",
      "    accuracy                           0.62      1050\n",
      "   macro avg       0.61      0.62      0.61      1050\n",
      "weighted avg       0.64      0.62      0.62      1050\n",
      "\n",
      "[90,     1] loss: 0.020\n",
      "acc:0.7812 \n",
      "err:0.2188 \n",
      "[TEST RESULT]\n",
      "acc:0.6286 \n",
      "err:0.3714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.79      0.82       115\n",
      "         1.0       0.46      0.41      0.43        63\n",
      "         2.0       0.63      0.52      0.57       149\n",
      "         3.0       0.61      0.60      0.60       159\n",
      "         4.0       0.69      0.66      0.67       180\n",
      "         5.0       0.68      0.56      0.61       157\n",
      "         6.0       0.57      0.61      0.59       109\n",
      "         7.0       0.52      0.84      0.64       118\n",
      "\n",
      "    accuracy                           0.63      1050\n",
      "   macro avg       0.62      0.62      0.62      1050\n",
      "weighted avg       0.64      0.63      0.63      1050\n",
      "\n",
      "[91,     1] loss: 0.010\n",
      "acc:0.9062 \n",
      "err:0.0938 \n",
      "[TEST RESULT]\n",
      "acc:0.5848 \n",
      "err:0.4152\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.67      0.78       115\n",
      "         1.0       0.47      0.27      0.34        63\n",
      "         2.0       0.72      0.54      0.62       149\n",
      "         3.0       0.49      0.71      0.58       159\n",
      "         4.0       0.67      0.57      0.62       180\n",
      "         5.0       0.40      0.76      0.52       157\n",
      "         6.0       0.68      0.46      0.55       109\n",
      "         7.0       0.86      0.47      0.60       118\n",
      "\n",
      "    accuracy                           0.58      1050\n",
      "   macro avg       0.65      0.56      0.58      1050\n",
      "weighted avg       0.65      0.58      0.59      1050\n",
      "\n",
      "[92,     1] loss: 0.024\n",
      "acc:0.7500 \n",
      "err:0.2500 \n",
      "[TEST RESULT]\n",
      "acc:0.6333 \n",
      "err:0.3667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.80      0.83       115\n",
      "         1.0       0.43      0.19      0.26        63\n",
      "         2.0       0.50      0.70      0.58       149\n",
      "         3.0       0.83      0.53      0.65       159\n",
      "         4.0       0.78      0.61      0.68       180\n",
      "         5.0       0.61      0.66      0.63       157\n",
      "         6.0       0.54      0.64      0.59       109\n",
      "         7.0       0.55      0.76      0.64       118\n",
      "\n",
      "    accuracy                           0.63      1050\n",
      "   macro avg       0.64      0.61      0.61      1050\n",
      "weighted avg       0.66      0.63      0.63      1050\n",
      "\n",
      "[93,     1] loss: 0.015\n",
      "acc:0.8438 \n",
      "err:0.1562 \n",
      "[TEST RESULT]\n",
      "acc:0.6010 \n",
      "err:0.3990\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.78      0.78       115\n",
      "         1.0       0.44      0.40      0.42        63\n",
      "         2.0       0.84      0.48      0.61       149\n",
      "         3.0       0.54      0.62      0.58       159\n",
      "         4.0       0.75      0.66      0.70       180\n",
      "         5.0       0.46      0.71      0.56       157\n",
      "         6.0       0.52      0.67      0.59       109\n",
      "         7.0       0.62      0.37      0.47       118\n",
      "\n",
      "    accuracy                           0.60      1050\n",
      "   macro avg       0.62      0.59      0.59      1050\n",
      "weighted avg       0.63      0.60      0.60      1050\n",
      "\n",
      "[94,     1] loss: 0.017\n",
      "acc:0.7812 \n",
      "err:0.2188 \n",
      "[TEST RESULT]\n",
      "acc:0.6019 \n",
      "err:0.3981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.71      0.74       115\n",
      "         1.0       0.28      0.56      0.37        63\n",
      "         2.0       0.68      0.56      0.61       149\n",
      "         3.0       0.49      0.69      0.57       159\n",
      "         4.0       0.76      0.64      0.70       180\n",
      "         5.0       0.70      0.57      0.63       157\n",
      "         6.0       0.53      0.69      0.60       109\n",
      "         7.0       0.88      0.36      0.51       118\n",
      "\n",
      "    accuracy                           0.60      1050\n",
      "   macro avg       0.63      0.60      0.59      1050\n",
      "weighted avg       0.66      0.60      0.61      1050\n",
      "\n",
      "[95,     1] loss: 0.017\n",
      "acc:0.8438 \n",
      "err:0.1562 \n",
      "[TEST RESULT]\n",
      "acc:0.5200 \n",
      "err:0.4800\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.84      0.53       115\n",
      "         1.0       0.21      0.38      0.27        63\n",
      "         2.0       0.82      0.21      0.33       149\n",
      "         3.0       0.74      0.55      0.63       159\n",
      "         4.0       0.56      0.59      0.58       180\n",
      "         5.0       0.62      0.45      0.52       157\n",
      "         6.0       0.62      0.53      0.57       109\n",
      "         7.0       0.56      0.59      0.58       118\n",
      "\n",
      "    accuracy                           0.52      1050\n",
      "   macro avg       0.56      0.52      0.50      1050\n",
      "weighted avg       0.60      0.52      0.52      1050\n",
      "\n",
      "[96,     1] loss: 0.086\n",
      "acc:0.5312 \n",
      "err:0.4688 \n",
      "[TEST RESULT]\n",
      "acc:0.5895 \n",
      "err:0.4105\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.86      0.61       115\n",
      "         1.0       0.35      0.52      0.42        63\n",
      "         2.0       0.74      0.43      0.54       149\n",
      "         3.0       0.69      0.48      0.57       159\n",
      "         4.0       0.73      0.57      0.64       180\n",
      "         5.0       0.54      0.59      0.56       157\n",
      "         6.0       0.62      0.65      0.63       109\n",
      "         7.0       0.65      0.68      0.66       118\n",
      "\n",
      "    accuracy                           0.59      1050\n",
      "   macro avg       0.60      0.60      0.58      1050\n",
      "weighted avg       0.63      0.59      0.59      1050\n",
      "\n",
      "[97,     1] loss: 0.013\n",
      "acc:0.8438 \n",
      "err:0.1562 \n",
      "[TEST RESULT]\n",
      "acc:0.6038 \n",
      "err:0.3962\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.83      0.69       115\n",
      "         1.0       0.27      0.57      0.37        63\n",
      "         2.0       0.55      0.56      0.55       149\n",
      "         3.0       0.89      0.53      0.67       159\n",
      "         4.0       0.67      0.59      0.63       180\n",
      "         5.0       0.55      0.52      0.54       157\n",
      "         6.0       0.71      0.66      0.68       109\n",
      "         7.0       0.75      0.63      0.68       118\n",
      "\n",
      "    accuracy                           0.60      1050\n",
      "   macro avg       0.62      0.61      0.60      1050\n",
      "weighted avg       0.65      0.60      0.61      1050\n",
      "\n",
      "[98,     1] loss: 0.016\n",
      "acc:0.7188 \n",
      "err:0.2812 \n",
      "[TEST RESULT]\n",
      "acc:0.5448 \n",
      "err:0.4552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.76      0.67       115\n",
      "         1.0       0.19      0.48      0.27        63\n",
      "         2.0       0.59      0.56      0.57       149\n",
      "         3.0       0.66      0.50      0.57       159\n",
      "         4.0       0.83      0.53      0.65       180\n",
      "         5.0       0.39      0.68      0.50       157\n",
      "         6.0       0.87      0.25      0.39       109\n",
      "         7.0       0.90      0.53      0.66       118\n",
      "\n",
      "    accuracy                           0.54      1050\n",
      "   macro avg       0.63      0.54      0.54      1050\n",
      "weighted avg       0.65      0.54      0.56      1050\n",
      "\n",
      "[99,     1] loss: 0.023\n",
      "acc:0.7500 \n",
      "err:0.2500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST RESULT]\n",
      "acc:0.5743 \n",
      "err:0.4257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.80      0.75       115\n",
      "         1.0       0.43      0.19      0.26        63\n",
      "         2.0       0.47      0.62      0.54       149\n",
      "         3.0       0.56      0.64      0.60       159\n",
      "         4.0       0.60      0.59      0.59       180\n",
      "         5.0       0.49      0.59      0.54       157\n",
      "         6.0       0.67      0.60      0.63       109\n",
      "         7.0       0.74      0.36      0.48       118\n",
      "\n",
      "    accuracy                           0.57      1050\n",
      "   macro avg       0.58      0.55      0.55      1050\n",
      "weighted avg       0.58      0.57      0.57      1050\n",
      "\n",
      "[100,     1] loss: 0.016\n",
      "acc:0.8750 \n",
      "err:0.1250 \n",
      "[TEST RESULT]\n",
      "acc:0.6048 \n",
      "err:0.3952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.77      0.82       115\n",
      "         1.0       0.39      0.52      0.45        63\n",
      "         2.0       0.53      0.58      0.56       149\n",
      "         3.0       0.67      0.62      0.65       159\n",
      "         4.0       0.87      0.42      0.57       180\n",
      "         5.0       0.54      0.69      0.61       157\n",
      "         6.0       0.65      0.61      0.63       109\n",
      "         7.0       0.47      0.65      0.55       118\n",
      "\n",
      "    accuracy                           0.60      1050\n",
      "   macro avg       0.62      0.61      0.60      1050\n",
      "weighted avg       0.65      0.60      0.61      1050\n",
      "\n",
      "{'Accuracy': [0.33, 0.83, 0.5, 0.33, 0.17, 0.67, 0.67, 0.83, 0.5, 0.5, 0.83, 0.33, 0.83, 0.33, 0.5, 1.0, 0.5, 0.5, 0.67, 0.67, 0.5, 1.0, 0.67, 1.0, 0.67, 0.83, 0.33, 0.33, 0.67, 0.83, 1.0, 0.67, 0.67, 0.67, 0.83, 0.5, 0.67, 0.83, 0.83, 0.67, 0.67, 0.5, 0.33, 1.0, 0.83, 0.83, 1.0, 1.0, 0.5, 0.5, 1.0, 0.67, 0.83, 0.67, 1.0, 0.67, 1.0, 1.0, 1.0, 1.0, 0.83, 0.67, 1.0, 1.0, 0.67, 1.0, 0.83, 1.0, 1.0, 1.0, 0.83, 0.67, 0.83, 0.83, 0.83, 0.83, 0.83, 1.0, 0.83, 0.83, 1.0, 1.0, 1.0, 0.5, 0.83, 1.0, 0.83, 1.0, 1.0, 0.83, 0.83, 0.67, 1.0, 1.0, 0.83, 0.67, 0.67, 0.67, 1.0, 0.67], 'F1_Score': [0.13, 0.3, 0.47, 0.53, 0.55, 0.62, 0.58, 0.65, 0.68, 0.58, 0.62, 0.62, 0.56, 0.61, 0.46, 0.62, 0.65, 0.57, 0.73, 0.69, 0.7, 0.73, 0.78, 0.69, 0.75, 0.77, 0.55, 0.38, 0.58, 0.51, 0.59, 0.69, 0.65, 0.71, 0.72, 0.67, 0.69, 0.72, 0.79, 0.79, 0.69, 0.75, 0.77, 0.78, 0.82, 0.82, 0.8, 0.76, 0.8, 0.79, 0.73, 0.72, 0.75, 0.76, 0.8, 0.82, 0.83, 0.86, 0.88, 0.89, 0.9, 0.82, 0.79, 0.84, 0.87, 0.85, 0.87, 0.85, 0.91, 0.92, 0.94, 0.83, 0.77, 0.69, 0.74, 0.85, 0.79, 0.85, 0.83, 0.86, 0.88, 0.9, 0.88, 0.89, 0.85, 0.84, 0.72, 0.78, 0.82, 0.88, 0.88, 0.86, 0.87, 0.9, 0.93, 0.71, 0.84, 0.83, 0.78, 0.86]}\n",
      "{'Accuracy': [0.18, 0.37, 0.46, 0.49, 0.45, 0.41, 0.5, 0.51, 0.48, 0.46, 0.51, 0.41, 0.46, 0.3, 0.45, 0.54, 0.42, 0.51, 0.55, 0.47, 0.59, 0.57, 0.59, 0.56, 0.6, 0.62, 0.24, 0.4, 0.47, 0.48, 0.5, 0.54, 0.56, 0.56, 0.53, 0.45, 0.53, 0.57, 0.57, 0.57, 0.58, 0.57, 0.6, 0.58, 0.61, 0.61, 0.6, 0.59, 0.6, 0.62, 0.59, 0.56, 0.58, 0.6, 0.61, 0.61, 0.62, 0.62, 0.62, 0.64, 0.59, 0.59, 0.59, 0.61, 0.61, 0.6, 0.63, 0.62, 0.63, 0.63, 0.6, 0.54, 0.56, 0.5, 0.61, 0.52, 0.6, 0.6, 0.6, 0.61, 0.59, 0.61, 0.63, 0.59, 0.57, 0.5, 0.59, 0.57, 0.62, 0.63, 0.58, 0.63, 0.6, 0.6, 0.52, 0.59, 0.6, 0.54, 0.57, 0.6], 'F1_Score': [0.07, 0.35, 0.45, 0.5, 0.47, 0.41, 0.52, 0.52, 0.52, 0.46, 0.53, 0.38, 0.45, 0.28, 0.43, 0.53, 0.45, 0.54, 0.56, 0.45, 0.61, 0.58, 0.59, 0.56, 0.62, 0.64, 0.2, 0.38, 0.45, 0.49, 0.51, 0.54, 0.59, 0.59, 0.51, 0.45, 0.52, 0.57, 0.59, 0.58, 0.6, 0.57, 0.61, 0.59, 0.63, 0.62, 0.59, 0.6, 0.59, 0.64, 0.6, 0.55, 0.59, 0.59, 0.61, 0.61, 0.62, 0.63, 0.63, 0.65, 0.6, 0.59, 0.59, 0.61, 0.61, 0.61, 0.62, 0.63, 0.63, 0.64, 0.61, 0.54, 0.57, 0.51, 0.61, 0.51, 0.6, 0.61, 0.61, 0.61, 0.6, 0.61, 0.64, 0.6, 0.59, 0.51, 0.58, 0.58, 0.62, 0.63, 0.59, 0.63, 0.6, 0.61, 0.52, 0.59, 0.61, 0.56, 0.57, 0.61]}\n",
      "Finished Training 100\n"
     ]
    }
   ],
   "source": [
    "net=Solver(params)\n",
    "baseline_train, baseline_valid=net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir_path = pathlib.Path().absolute()\n",
    "SAVE_DIR_PATH = str(working_dir_path) + '/Dictionaries/baseline'\n",
    "fileName =str(params['train_dataset_percentage'])+'baseline_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeToJSONFile(path, fileName, data):\n",
    "    filePathNameWExt =  path + '/' + fileName + '.json'\n",
    "    with open(filePathNameWExt, 'w') as fp:\n",
    "        json.dump(data, fp)\n",
    "\n",
    "# Example\n",
    "data = baseline_train\n",
    "\n",
    "writeToJSONFile(SAVE_DIR_PATH,fileName,data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName =str(params['train_dataset_percentage'])+'baseline_valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeToJSONFile(path, fileName, data):\n",
    "    filePathNameWExt =  path + '/' + fileName + '.json'\n",
    "    with open(filePathNameWExt, 'w') as fp:\n",
    "        json.dump(data, fp)\n",
    "\n",
    "# Example\n",
    "data = baseline_valid\n",
    "\n",
    "writeToJSONFile(SAVE_DIR_PATH,fileName,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SAVE_DIR_PATH+'/'+fileName+'.json') as js:\n",
    "    data = json.load(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': [0.18,\n",
       "  0.37,\n",
       "  0.46,\n",
       "  0.49,\n",
       "  0.45,\n",
       "  0.41,\n",
       "  0.5,\n",
       "  0.51,\n",
       "  0.48,\n",
       "  0.46,\n",
       "  0.51,\n",
       "  0.41,\n",
       "  0.46,\n",
       "  0.3,\n",
       "  0.45,\n",
       "  0.54,\n",
       "  0.42,\n",
       "  0.51,\n",
       "  0.55,\n",
       "  0.47,\n",
       "  0.59,\n",
       "  0.57,\n",
       "  0.59,\n",
       "  0.56,\n",
       "  0.6,\n",
       "  0.62,\n",
       "  0.24,\n",
       "  0.4,\n",
       "  0.47,\n",
       "  0.48,\n",
       "  0.5,\n",
       "  0.54,\n",
       "  0.56,\n",
       "  0.56,\n",
       "  0.53,\n",
       "  0.45,\n",
       "  0.53,\n",
       "  0.57,\n",
       "  0.57,\n",
       "  0.57,\n",
       "  0.58,\n",
       "  0.57,\n",
       "  0.6,\n",
       "  0.58,\n",
       "  0.61,\n",
       "  0.61,\n",
       "  0.6,\n",
       "  0.59,\n",
       "  0.6,\n",
       "  0.62,\n",
       "  0.59,\n",
       "  0.56,\n",
       "  0.58,\n",
       "  0.6,\n",
       "  0.61,\n",
       "  0.61,\n",
       "  0.62,\n",
       "  0.62,\n",
       "  0.62,\n",
       "  0.64,\n",
       "  0.59,\n",
       "  0.59,\n",
       "  0.59,\n",
       "  0.61,\n",
       "  0.61,\n",
       "  0.6,\n",
       "  0.63,\n",
       "  0.62,\n",
       "  0.63,\n",
       "  0.63,\n",
       "  0.6,\n",
       "  0.54,\n",
       "  0.56,\n",
       "  0.5,\n",
       "  0.61,\n",
       "  0.52,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.61,\n",
       "  0.59,\n",
       "  0.61,\n",
       "  0.63,\n",
       "  0.59,\n",
       "  0.57,\n",
       "  0.5,\n",
       "  0.59,\n",
       "  0.57,\n",
       "  0.62,\n",
       "  0.63,\n",
       "  0.58,\n",
       "  0.63,\n",
       "  0.6,\n",
       "  0.6,\n",
       "  0.52,\n",
       "  0.59,\n",
       "  0.6,\n",
       "  0.54,\n",
       "  0.57,\n",
       "  0.6],\n",
       " 'F1_Score': [0.07,\n",
       "  0.35,\n",
       "  0.45,\n",
       "  0.5,\n",
       "  0.47,\n",
       "  0.41,\n",
       "  0.52,\n",
       "  0.52,\n",
       "  0.52,\n",
       "  0.46,\n",
       "  0.53,\n",
       "  0.38,\n",
       "  0.45,\n",
       "  0.28,\n",
       "  0.43,\n",
       "  0.53,\n",
       "  0.45,\n",
       "  0.54,\n",
       "  0.56,\n",
       "  0.45,\n",
       "  0.61,\n",
       "  0.58,\n",
       "  0.59,\n",
       "  0.56,\n",
       "  0.62,\n",
       "  0.64,\n",
       "  0.2,\n",
       "  0.38,\n",
       "  0.45,\n",
       "  0.49,\n",
       "  0.51,\n",
       "  0.54,\n",
       "  0.59,\n",
       "  0.59,\n",
       "  0.51,\n",
       "  0.45,\n",
       "  0.52,\n",
       "  0.57,\n",
       "  0.59,\n",
       "  0.58,\n",
       "  0.6,\n",
       "  0.57,\n",
       "  0.61,\n",
       "  0.59,\n",
       "  0.63,\n",
       "  0.62,\n",
       "  0.59,\n",
       "  0.6,\n",
       "  0.59,\n",
       "  0.64,\n",
       "  0.6,\n",
       "  0.55,\n",
       "  0.59,\n",
       "  0.59,\n",
       "  0.61,\n",
       "  0.61,\n",
       "  0.62,\n",
       "  0.63,\n",
       "  0.63,\n",
       "  0.65,\n",
       "  0.6,\n",
       "  0.59,\n",
       "  0.59,\n",
       "  0.61,\n",
       "  0.61,\n",
       "  0.61,\n",
       "  0.62,\n",
       "  0.63,\n",
       "  0.63,\n",
       "  0.64,\n",
       "  0.61,\n",
       "  0.54,\n",
       "  0.57,\n",
       "  0.51,\n",
       "  0.61,\n",
       "  0.51,\n",
       "  0.6,\n",
       "  0.61,\n",
       "  0.61,\n",
       "  0.61,\n",
       "  0.6,\n",
       "  0.61,\n",
       "  0.64,\n",
       "  0.6,\n",
       "  0.59,\n",
       "  0.51,\n",
       "  0.58,\n",
       "  0.58,\n",
       "  0.62,\n",
       "  0.63,\n",
       "  0.59,\n",
       "  0.63,\n",
       "  0.6,\n",
       "  0.61,\n",
       "  0.52,\n",
       "  0.59,\n",
       "  0.61,\n",
       "  0.56,\n",
       "  0.57,\n",
       "  0.61]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_train['Accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'name': nme, \n",
    "        'baseline_train_acc':baseline_train['Accuracy'] ,\n",
    "        'baseline_valid_acc':baseline_valid['Accuracy'],\n",
    "        'VIB_train_acc:      'score': scr}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nme=['baseline_train_acc','baseline_valid_acc','VIB_train_acc','VIB_test_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline_train = pd.DataFrame(baseline_train) \n",
    "df_baseline_valid =\n",
    "df_baseline_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_train={'a':1,'b':[1,2]}\n",
    "def myfunc(baseline_train):\n",
    "    return baseline_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res.json', 'w') as jf:\n",
    "    json.dump(dic_res['base_train'], jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vib_acc = [0.23, .30, .4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res.json', 'r') as jf:\n",
    "    res=json.load(jf)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
