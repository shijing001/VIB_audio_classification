{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revised Linear Layer Architecture without VIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tensorboardX import SummaryWriter\n",
    "#from utils import cuda\n",
    "import pdb\n",
    "import time\n",
    "from numbers import Number\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import argparse\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### neural networks architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyNet(nn.Module):\n",
    "    '''\n",
    "    Construct a MLP that is used to train the model \n",
    "    param[in]: X_train, output_features\n",
    "    param[out]: output \n",
    "    \n",
    "    Note: initialize the weight with a self-defined method\n",
    "    '''\n",
    "\n",
    "    def __init__(self, output_features=8):\n",
    "        super(ToyNet, self).__init__()\n",
    "        self.encode = nn.Sequential(\n",
    "            nn.Linear(40, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, output_features))\n",
    "        #self.optim = optim.Adam(self.toynet.parameters(),lr=self.lr,betas=(0.5,0.999))\n",
    "        #self.scheduler = lr_scheduler.ExponentialLR(self.optim,gamma=0.97\n",
    "    def forward(self, X_train):\n",
    "        output=self.encode(X_train)\n",
    "        #prediction = F.softmax(output,dim=1).max(1)[1]\n",
    "        \n",
    "        #print(prediction)\n",
    "        return output\n",
    "    def weight_init(self):\n",
    "        for m in self._modules:\n",
    "            xavier_init(self._modules[m])\n",
    "            \n",
    "def xavier_init(ms):\n",
    "    \"\"\"\n",
    "    Xavier initialization\n",
    "    \"\"\"\n",
    "    for m in ms :\n",
    "        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "            nn.init.xavier_uniform(m.weight,gain=nn.init.calculate_gain('relu'))\n",
    "            m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda(tensor, is_cuda):\n",
    "    if is_cuda : return tensor.cuda()\n",
    "    else : return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    'epoch':50,\n",
    "    'batch_size':64,\n",
    "    'lr':0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"\n",
    "    construct dataset from numpy and split it \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, data, target, transform=None):\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "        self.target = torch.from_numpy(target).long()\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "X = joblib.load('./joblib_features/X.joblib')\n",
    "y = joblib.load('./joblib_features/y.joblib')\n",
    "full_dataset = CustomDataset(X, y)\n",
    "train_size = int(0.6 * len(full_dataset))\n",
    "valid_size = int(0.2 * len(full_dataset))\n",
    "test_size = len(full_dataset) - valid_size-train_size\n",
    "batch_size = params['batch_size']\n",
    "#train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, \n",
    "                                                            #[train_size, test_size])\n",
    "### split dataset into training, validation and test                     \n",
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    full_dataset, (train_size, valid_size, test_size), generator=torch.Generator().manual_seed(42))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "my_dataloader = {'train': train_dataloader , 'validate':valid_dataloader, 'test': test_dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver(object):\n",
    "#train the model\n",
    "\n",
    "    def __init__(self, params):\n",
    "        \"\"\"\n",
    "        initialization of a Solver object\n",
    "        \n",
    "        \"\"\"\n",
    "        self.cuda =torch.cuda.is_available ()\n",
    "        self.epoch = params['epoch']\n",
    "        self.batch_size = params['batch_size']\n",
    "        self.lr = params['lr']\n",
    "        self.toynet = cuda(ToyNet(), self.cuda)\n",
    "        self.toynet.weight_init()\n",
    "        self.optim = optim.Adam(self.toynet.parameters(),\n",
    "                                lr=self.lr,\n",
    "                                betas=(0.5,0.999))\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def train(self):\n",
    "        for epc in range(self.epoch):  # loop over the dataset multiple times\n",
    "            self.toynet.train('True')  # training neural networks mode\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(train_dataloader):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs, labels = data\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                self.optim.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = self.toynet.forward(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optim.step()\n",
    "                \n",
    "                prediction = F.softmax(outputs,dim=1).max(1)[1]\n",
    "                accuracy = torch.eq(prediction,labels).float().mean()\n",
    "                avg_accuracy = Variable(cuda(torch.zeros(accuracy.size()), self.cuda))\n",
    "                \n",
    "\n",
    "                # print statistics\n",
    "                running_loss += loss.item()\n",
    "                if i % self.batch_size == 0:    # print every 30 mini-batches\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                            (epc + 1, i + 1, running_loss / self.batch_size))\n",
    "                    print('acc:{:.4f} '\n",
    "                            .format(accuracy.item(), end=' '))\n",
    "                    print('err:{:.4f} '\n",
    "                            .format(1-accuracy.item()))\n",
    "                    running_loss = 0.0\n",
    "                    \n",
    "            ## validation set at each epoch\n",
    "            self.test()\n",
    "        print('Finished Training',(epc+1))\n",
    "    \n",
    "    def test(self):\n",
    "        \"\"\"\n",
    "        Testing over a dataset\n",
    "        \"\"\"\n",
    "        self.toynet.train('False')  # evaluation mode      \n",
    "        loss, correct, total_num = 0,0,0\n",
    "        \n",
    "        y_real=torch.randn([0])\n",
    "        y_hat=torch.randn([0])\n",
    "        \n",
    "        for i, data in enumerate(valid_dataloader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            outputs = self.toynet.forward(inputs)\n",
    "            #loss\n",
    "            total_num += labels.shape[0]\n",
    "            loss += self.criterion(outputs,labels)\n",
    "            prediction = F.softmax(outputs,dim=1).max(1)[1]\n",
    "            y_real=torch.cat([y_real,labels],dim=0)\n",
    "            y_hat=torch.cat([y_hat,prediction],dim=0)\n",
    "            correct += torch.eq(prediction,labels).float().sum()\n",
    "            avg_correct = Variable(cuda(torch.zeros(correct.size()), self.cuda))\n",
    "        accuracy = correct/total_num\n",
    "        avg_accuracy = avg_correct/total_num\n",
    "        \n",
    "        print('[TEST RESULT]')\n",
    "        print('acc:{:.4f} '\n",
    "                .format(accuracy.item(),end=' '))\n",
    "        print('err:{:.4f}'\n",
    "                .format(1-accuracy.item()))\n",
    "        print(classification_report(y_real,y_hat))\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shiji\\Anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:36: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.663\n",
      "acc:0.1094 \n",
      "err:0.8906 \n",
      "[TEST RESULT]\n",
      "acc:0.5962 \n",
      "err:0.4038\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.76      0.86       115\n",
      "         1.0       0.50      0.05      0.09        63\n",
      "         2.0       0.83      0.45      0.58       149\n",
      "         3.0       0.33      0.98      0.50       159\n",
      "         4.0       0.65      0.66      0.65       180\n",
      "         5.0       0.79      0.57      0.66       157\n",
      "         6.0       0.97      0.28      0.44       109\n",
      "         7.0       0.94      0.63      0.75       118\n",
      "\n",
      "    accuracy                           0.60      1050\n",
      "   macro avg       0.75      0.55      0.57      1050\n",
      "weighted avg       0.74      0.60      0.60      1050\n",
      "\n",
      "[2,     1] loss: 0.017\n",
      "acc:0.6094 \n",
      "err:0.3906 \n",
      "[TEST RESULT]\n",
      "acc:0.6162 \n",
      "err:0.3838\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.74      0.85       115\n",
      "         1.0       0.31      0.71      0.43        63\n",
      "         2.0       0.42      0.79      0.55       149\n",
      "         3.0       0.96      0.57      0.71       159\n",
      "         4.0       0.51      0.65      0.57       180\n",
      "         5.0       0.99      0.50      0.66       157\n",
      "         6.0       0.74      0.60      0.66       109\n",
      "         7.0       1.00      0.42      0.59       118\n",
      "\n",
      "    accuracy                           0.62      1050\n",
      "   macro avg       0.74      0.62      0.63      1050\n",
      "weighted avg       0.76      0.62      0.64      1050\n",
      "\n",
      "[3,     1] loss: 0.015\n",
      "acc:0.6406 \n",
      "err:0.3594 \n",
      "[TEST RESULT]\n",
      "acc:0.6686 \n",
      "err:0.3314\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.77      0.84       115\n",
      "         1.0       0.45      0.44      0.45        63\n",
      "         2.0       0.57      0.70      0.63       149\n",
      "         3.0       0.55      0.81      0.65       159\n",
      "         4.0       0.68      0.73      0.71       180\n",
      "         5.0       0.66      0.50      0.57       157\n",
      "         6.0       0.81      0.62      0.70       109\n",
      "         7.0       0.90      0.64      0.75       118\n",
      "\n",
      "    accuracy                           0.67      1050\n",
      "   macro avg       0.70      0.65      0.66      1050\n",
      "weighted avg       0.70      0.67      0.67      1050\n",
      "\n",
      "[4,     1] loss: 0.017\n",
      "acc:0.6094 \n",
      "err:0.3906 \n",
      "[TEST RESULT]\n",
      "acc:0.6552 \n",
      "err:0.3448\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.81      0.88       115\n",
      "         1.0       0.38      0.33      0.35        63\n",
      "         2.0       0.51      0.72      0.60       149\n",
      "         3.0       0.76      0.66      0.70       159\n",
      "         4.0       0.93      0.61      0.73       180\n",
      "         5.0       0.89      0.57      0.69       157\n",
      "         6.0       0.38      0.93      0.54       109\n",
      "         7.0       0.95      0.53      0.68       118\n",
      "\n",
      "    accuracy                           0.66      1050\n",
      "   macro avg       0.72      0.64      0.65      1050\n",
      "weighted avg       0.75      0.66      0.67      1050\n",
      "\n",
      "[5,     1] loss: 0.015\n",
      "acc:0.6719 \n",
      "err:0.3281 \n",
      "[TEST RESULT]\n",
      "acc:0.6933 \n",
      "err:0.3067\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.83      0.70       115\n",
      "         1.0       0.66      0.37      0.47        63\n",
      "         2.0       0.88      0.62      0.73       149\n",
      "         3.0       0.68      0.74      0.71       159\n",
      "         4.0       0.79      0.69      0.74       180\n",
      "         5.0       0.55      0.73      0.63       157\n",
      "         6.0       0.91      0.62      0.74       109\n",
      "         7.0       0.65      0.79      0.72       118\n",
      "\n",
      "    accuracy                           0.69      1050\n",
      "   macro avg       0.72      0.67      0.68      1050\n",
      "weighted avg       0.72      0.69      0.69      1050\n",
      "\n",
      "[6,     1] loss: 0.011\n",
      "acc:0.7188 \n",
      "err:0.2812 \n",
      "[TEST RESULT]\n",
      "acc:0.5848 \n",
      "err:0.4152\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.75      0.84       115\n",
      "         1.0       0.37      0.40      0.38        63\n",
      "         2.0       0.81      0.52      0.63       149\n",
      "         3.0       0.32      0.97      0.48       159\n",
      "         4.0       1.00      0.49      0.66       180\n",
      "         5.0       0.69      0.48      0.56       157\n",
      "         6.0       1.00      0.43      0.60       109\n",
      "         7.0       0.85      0.52      0.64       118\n",
      "\n",
      "    accuracy                           0.58      1050\n",
      "   macro avg       0.75      0.57      0.60      1050\n",
      "weighted avg       0.76      0.58      0.61      1050\n",
      "\n",
      "[7,     1] loss: 0.022\n",
      "acc:0.5625 \n",
      "err:0.4375 \n",
      "[TEST RESULT]\n",
      "acc:0.6848 \n",
      "err:0.3152\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.83      0.81       115\n",
      "         1.0       0.39      0.46      0.42        63\n",
      "         2.0       0.57      0.60      0.59       149\n",
      "         3.0       0.78      0.65      0.71       159\n",
      "         4.0       0.69      0.86      0.76       180\n",
      "         5.0       0.60      0.62      0.61       157\n",
      "         6.0       0.88      0.62      0.73       109\n",
      "         7.0       0.81      0.67      0.73       118\n",
      "\n",
      "    accuracy                           0.68      1050\n",
      "   macro avg       0.69      0.67      0.67      1050\n",
      "weighted avg       0.70      0.68      0.69      1050\n",
      "\n",
      "[8,     1] loss: 0.011\n",
      "acc:0.7188 \n",
      "err:0.2812 \n",
      "[TEST RESULT]\n",
      "acc:0.6390 \n",
      "err:0.3610\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.85      0.78       115\n",
      "         1.0       0.36      0.57      0.44        63\n",
      "         2.0       0.76      0.23      0.36       149\n",
      "         3.0       0.58      0.74      0.65       159\n",
      "         4.0       0.67      0.80      0.73       180\n",
      "         5.0       0.82      0.54      0.65       157\n",
      "         6.0       0.55      0.73      0.63       109\n",
      "         7.0       0.75      0.64      0.69       118\n",
      "\n",
      "    accuracy                           0.64      1050\n",
      "   macro avg       0.65      0.64      0.62      1050\n",
      "weighted avg       0.67      0.64      0.63      1050\n",
      "\n",
      "[9,     1] loss: 0.017\n",
      "acc:0.6250 \n",
      "err:0.3750 \n",
      "[TEST RESULT]\n",
      "acc:0.6724 \n",
      "err:0.3276\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.84      0.82       115\n",
      "         1.0       0.42      0.43      0.42        63\n",
      "         2.0       0.39      0.88      0.54       149\n",
      "         3.0       0.79      0.68      0.73       159\n",
      "         4.0       0.94      0.61      0.74       180\n",
      "         5.0       0.76      0.62      0.68       157\n",
      "         6.0       0.94      0.59      0.72       109\n",
      "         7.0       0.92      0.62      0.74       118\n",
      "\n",
      "    accuracy                           0.67      1050\n",
      "   macro avg       0.74      0.66      0.67      1050\n",
      "weighted avg       0.76      0.67      0.69      1050\n",
      "\n",
      "[10,     1] loss: 0.013\n",
      "acc:0.6719 \n",
      "err:0.3281 \n",
      "[TEST RESULT]\n",
      "acc:0.7124 \n",
      "err:0.2876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.83      0.88       115\n",
      "         1.0       0.42      0.81      0.56        63\n",
      "         2.0       0.67      0.68      0.67       149\n",
      "         3.0       0.57      0.82      0.67       159\n",
      "         4.0       0.91      0.62      0.74       180\n",
      "         5.0       0.77      0.63      0.69       157\n",
      "         6.0       0.83      0.64      0.73       109\n",
      "         7.0       0.79      0.75      0.77       118\n",
      "\n",
      "    accuracy                           0.71      1050\n",
      "   macro avg       0.74      0.72      0.71      1050\n",
      "weighted avg       0.76      0.71      0.72      1050\n",
      "\n",
      "[11,     1] loss: 0.011\n",
      "acc:0.7500 \n",
      "err:0.2500 \n",
      "[TEST RESULT]\n",
      "acc:0.7010 \n",
      "err:0.2990\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.90      0.74       115\n",
      "         1.0       0.80      0.32      0.45        63\n",
      "         2.0       0.79      0.72      0.76       149\n",
      "         3.0       0.88      0.65      0.75       159\n",
      "         4.0       0.58      0.92      0.72       180\n",
      "         5.0       0.93      0.52      0.66       157\n",
      "         6.0       0.78      0.55      0.65       109\n",
      "         7.0       0.60      0.81      0.69       118\n",
      "\n",
      "    accuracy                           0.70      1050\n",
      "   macro avg       0.75      0.67      0.68      1050\n",
      "weighted avg       0.75      0.70      0.69      1050\n",
      "\n",
      "[12,     1] loss: 0.011\n",
      "acc:0.7500 \n",
      "err:0.2500 \n",
      "[TEST RESULT]\n",
      "acc:0.7324 \n",
      "err:0.2676\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.83      0.90       115\n",
      "         1.0       0.44      0.59      0.50        63\n",
      "         2.0       0.80      0.66      0.72       149\n",
      "         3.0       0.67      0.78      0.72       159\n",
      "         4.0       0.83      0.78      0.80       180\n",
      "         5.0       0.94      0.55      0.70       157\n",
      "         6.0       0.63      0.80      0.70       109\n",
      "         7.0       0.61      0.86      0.71       118\n",
      "\n",
      "    accuracy                           0.73      1050\n",
      "   macro avg       0.74      0.73      0.72      1050\n",
      "weighted avg       0.77      0.73      0.74      1050\n",
      "\n",
      "[13,     1] loss: 0.008\n",
      "acc:0.7812 \n",
      "err:0.2188 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST RESULT]\n",
      "acc:0.6800 \n",
      "err:0.3200\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.88      0.78       115\n",
      "         1.0       0.00      0.00      0.00        63\n",
      "         2.0       0.37      0.95      0.53       149\n",
      "         3.0       0.89      0.63      0.74       159\n",
      "         4.0       0.96      0.69      0.80       180\n",
      "         5.0       0.84      0.61      0.70       157\n",
      "         6.0       0.89      0.68      0.77       109\n",
      "         7.0       0.91      0.66      0.76       118\n",
      "\n",
      "    accuracy                           0.68      1050\n",
      "   macro avg       0.70      0.64      0.64      1050\n",
      "weighted avg       0.75      0.68      0.68      1050\n",
      "\n",
      "[14,     1] loss: 0.017\n",
      "acc:0.7188 \n",
      "err:0.2812 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shiji\\Anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST RESULT]\n",
      "acc:0.7000 \n",
      "err:0.3000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.88      0.79       115\n",
      "         1.0       0.52      0.44      0.48        63\n",
      "         2.0       0.79      0.70      0.74       149\n",
      "         3.0       0.94      0.60      0.74       159\n",
      "         4.0       0.47      0.97      0.64       180\n",
      "         5.0       0.95      0.51      0.66       157\n",
      "         6.0       0.90      0.64      0.75       109\n",
      "         7.0       0.90      0.69      0.78       118\n",
      "\n",
      "    accuracy                           0.70      1050\n",
      "   macro avg       0.77      0.68      0.70      1050\n",
      "weighted avg       0.78      0.70      0.71      1050\n",
      "\n",
      "[15,     1] loss: 0.010\n",
      "acc:0.7500 \n",
      "err:0.2500 \n",
      "[TEST RESULT]\n",
      "acc:0.6914 \n",
      "err:0.3086\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.77      0.87       115\n",
      "         1.0       0.27      0.98      0.43        63\n",
      "         2.0       0.71      0.62      0.66       149\n",
      "         3.0       0.78      0.68      0.73       159\n",
      "         4.0       0.96      0.64      0.77       180\n",
      "         5.0       0.91      0.55      0.69       157\n",
      "         6.0       0.86      0.66      0.75       109\n",
      "         7.0       0.60      0.86      0.71       118\n",
      "\n",
      "    accuracy                           0.69      1050\n",
      "   macro avg       0.76      0.72      0.70      1050\n",
      "weighted avg       0.80      0.69      0.72      1050\n",
      "\n",
      "[16,     1] loss: 0.008\n",
      "acc:0.7812 \n",
      "err:0.2188 \n",
      "[TEST RESULT]\n",
      "acc:0.7543 \n",
      "err:0.2457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.78      0.87       115\n",
      "         1.0       0.55      0.57      0.56        63\n",
      "         2.0       0.72      0.69      0.71       149\n",
      "         3.0       0.81      0.78      0.79       159\n",
      "         4.0       0.78      0.84      0.81       180\n",
      "         5.0       0.84      0.69      0.76       157\n",
      "         6.0       0.56      0.81      0.66       109\n",
      "         7.0       0.78      0.78      0.78       118\n",
      "\n",
      "    accuracy                           0.75      1050\n",
      "   macro avg       0.75      0.74      0.74      1050\n",
      "weighted avg       0.77      0.75      0.76      1050\n",
      "\n",
      "[17,     1] loss: 0.007\n",
      "acc:0.8281 \n",
      "err:0.1719 \n",
      "[TEST RESULT]\n",
      "acc:0.7048 \n",
      "err:0.2952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.78      0.88       115\n",
      "         1.0       0.79      0.30      0.44        63\n",
      "         2.0       0.71      0.71      0.71       149\n",
      "         3.0       0.72      0.81      0.76       159\n",
      "         4.0       0.55      0.90      0.69       180\n",
      "         5.0       0.87      0.45      0.59       157\n",
      "         6.0       0.59      0.75      0.66       109\n",
      "         7.0       0.85      0.69      0.77       118\n",
      "\n",
      "    accuracy                           0.70      1050\n",
      "   macro avg       0.76      0.68      0.69      1050\n",
      "weighted avg       0.75      0.70      0.70      1050\n",
      "\n",
      "[18,     1] loss: 0.012\n",
      "acc:0.7031 \n",
      "err:0.2969 \n",
      "[TEST RESULT]\n",
      "acc:0.7305 \n",
      "err:0.2695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.85      0.89       115\n",
      "         1.0       0.52      0.41      0.46        63\n",
      "         2.0       0.62      0.77      0.69       149\n",
      "         3.0       0.86      0.74      0.79       159\n",
      "         4.0       0.84      0.75      0.79       180\n",
      "         5.0       0.93      0.60      0.73       157\n",
      "         6.0       0.56      0.75      0.64       109\n",
      "         7.0       0.61      0.86      0.71       118\n",
      "\n",
      "    accuracy                           0.73      1050\n",
      "   macro avg       0.73      0.72      0.71      1050\n",
      "weighted avg       0.76      0.73      0.73      1050\n",
      "\n",
      "[19,     1] loss: 0.014\n",
      "acc:0.7344 \n",
      "err:0.2656 \n",
      "[TEST RESULT]\n",
      "acc:0.6971 \n",
      "err:0.3029\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.82      0.90       115\n",
      "         1.0       0.71      0.08      0.14        63\n",
      "         2.0       0.76      0.75      0.75       149\n",
      "         3.0       0.54      0.70      0.61       159\n",
      "         4.0       0.84      0.76      0.80       180\n",
      "         5.0       0.69      0.64      0.67       157\n",
      "         6.0       0.48      0.85      0.61       109\n",
      "         7.0       0.85      0.67      0.75       118\n",
      "\n",
      "    accuracy                           0.70      1050\n",
      "   macro avg       0.73      0.66      0.65      1050\n",
      "weighted avg       0.73      0.70      0.69      1050\n",
      "\n",
      "[20,     1] loss: 0.013\n",
      "acc:0.7188 \n",
      "err:0.2812 \n",
      "[TEST RESULT]\n",
      "acc:0.6629 \n",
      "err:0.3371\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.80      0.86       115\n",
      "         1.0       0.46      0.57      0.51        63\n",
      "         2.0       0.63      0.56      0.59       149\n",
      "         3.0       0.92      0.65      0.76       159\n",
      "         4.0       0.79      0.72      0.76       180\n",
      "         5.0       0.44      0.59      0.51       157\n",
      "         6.0       0.72      0.62      0.67       109\n",
      "         7.0       0.56      0.78      0.65       118\n",
      "\n",
      "    accuracy                           0.66      1050\n",
      "   macro avg       0.68      0.66      0.66      1050\n",
      "weighted avg       0.70      0.66      0.67      1050\n",
      "\n",
      "[21,     1] loss: 0.016\n",
      "acc:0.7188 \n",
      "err:0.2812 \n",
      "[TEST RESULT]\n",
      "acc:0.7486 \n",
      "err:0.2514\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.83      0.91       115\n",
      "         1.0       0.54      0.59      0.56        63\n",
      "         2.0       0.82      0.72      0.77       149\n",
      "         3.0       0.88      0.70      0.78       159\n",
      "         4.0       0.80      0.78      0.79       180\n",
      "         5.0       0.70      0.71      0.71       157\n",
      "         6.0       0.64      0.72      0.68       109\n",
      "         7.0       0.61      0.87      0.72       118\n",
      "\n",
      "    accuracy                           0.75      1050\n",
      "   macro avg       0.75      0.74      0.74      1050\n",
      "weighted avg       0.77      0.75      0.75      1050\n",
      "\n",
      "[22,     1] loss: 0.006\n",
      "acc:0.8594 \n",
      "err:0.1406 \n",
      "[TEST RESULT]\n",
      "acc:0.7486 \n",
      "err:0.2514\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.90      0.86       115\n",
      "         1.0       0.65      0.56      0.60        63\n",
      "         2.0       0.78      0.68      0.72       149\n",
      "         3.0       0.73      0.77      0.75       159\n",
      "         4.0       0.77      0.86      0.81       180\n",
      "         5.0       0.76      0.64      0.69       157\n",
      "         6.0       0.67      0.74      0.70       109\n",
      "         7.0       0.76      0.75      0.76       118\n",
      "\n",
      "    accuracy                           0.75      1050\n",
      "   macro avg       0.74      0.74      0.74      1050\n",
      "weighted avg       0.75      0.75      0.75      1050\n",
      "\n",
      "[23,     1] loss: 0.007\n",
      "acc:0.8281 \n",
      "err:0.1719 \n",
      "[TEST RESULT]\n",
      "acc:0.7210 \n",
      "err:0.2790\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.81      0.89       115\n",
      "         1.0       0.69      0.49      0.57        63\n",
      "         2.0       0.73      0.68      0.71       149\n",
      "         3.0       0.49      0.90      0.64       159\n",
      "         4.0       0.92      0.68      0.78       180\n",
      "         5.0       0.78      0.65      0.71       157\n",
      "         6.0       0.82      0.66      0.73       109\n",
      "         7.0       0.71      0.77      0.74       118\n",
      "\n",
      "    accuracy                           0.72      1050\n",
      "   macro avg       0.77      0.71      0.72      1050\n",
      "weighted avg       0.77      0.72      0.73      1050\n",
      "\n",
      "[24,     1] loss: 0.004\n",
      "acc:0.9062 \n",
      "err:0.0938 \n",
      "[TEST RESULT]\n",
      "acc:0.7152 \n",
      "err:0.2848\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.84      0.90       115\n",
      "         1.0       0.46      0.48      0.47        63\n",
      "         2.0       0.67      0.64      0.65       149\n",
      "         3.0       0.84      0.76      0.80       159\n",
      "         4.0       0.97      0.63      0.77       180\n",
      "         5.0       0.71      0.74      0.72       157\n",
      "         6.0       0.84      0.65      0.73       109\n",
      "         7.0       0.46      0.91      0.61       118\n",
      "\n",
      "    accuracy                           0.72      1050\n",
      "   macro avg       0.74      0.71      0.71      1050\n",
      "weighted avg       0.77      0.72      0.72      1050\n",
      "\n",
      "[25,     1] loss: 0.010\n",
      "acc:0.7812 \n",
      "err:0.2188 \n",
      "[TEST RESULT]\n",
      "acc:0.7410 \n",
      "err:0.2590\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.84      0.88       115\n",
      "         1.0       0.53      0.56      0.54        63\n",
      "         2.0       0.73      0.78      0.75       149\n",
      "         3.0       1.00      0.61      0.76       159\n",
      "         4.0       0.64      0.94      0.76       180\n",
      "         5.0       0.82      0.61      0.70       157\n",
      "         6.0       0.58      0.74      0.65       109\n",
      "         7.0       0.86      0.75      0.80       118\n",
      "\n",
      "    accuracy                           0.74      1050\n",
      "   macro avg       0.76      0.73      0.73      1050\n",
      "weighted avg       0.78      0.74      0.74      1050\n",
      "\n",
      "[26,     1] loss: 0.009\n",
      "acc:0.7969 \n",
      "err:0.2031 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST RESULT]\n",
      "acc:0.6305 \n",
      "err:0.3695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.83      0.81       115\n",
      "         1.0       0.73      0.13      0.22        63\n",
      "         2.0       0.77      0.66      0.71       149\n",
      "         3.0       0.54      0.72      0.61       159\n",
      "         4.0       0.93      0.48      0.63       180\n",
      "         5.0       0.40      0.90      0.56       157\n",
      "         6.0       1.00      0.40      0.58       109\n",
      "         7.0       0.82      0.63      0.71       118\n",
      "\n",
      "    accuracy                           0.63      1050\n",
      "   macro avg       0.75      0.59      0.60      1050\n",
      "weighted avg       0.74      0.63      0.63      1050\n",
      "\n",
      "[27,     1] loss: 0.015\n",
      "acc:0.6719 \n",
      "err:0.3281 \n",
      "[TEST RESULT]\n",
      "acc:0.7533 \n",
      "err:0.2467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.88      0.86       115\n",
      "         1.0       0.46      0.90      0.61        63\n",
      "         2.0       0.80      0.69      0.74       149\n",
      "         3.0       0.90      0.72      0.80       159\n",
      "         4.0       0.92      0.74      0.82       180\n",
      "         5.0       0.85      0.67      0.75       157\n",
      "         6.0       0.53      0.83      0.65       109\n",
      "         7.0       0.78      0.74      0.76       118\n",
      "\n",
      "    accuracy                           0.75      1050\n",
      "   macro avg       0.76      0.77      0.75      1050\n",
      "weighted avg       0.80      0.75      0.76      1050\n",
      "\n",
      "[28,     1] loss: 0.008\n",
      "acc:0.8281 \n",
      "err:0.1719 \n",
      "[TEST RESULT]\n",
      "acc:0.6867 \n",
      "err:0.3133\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.85      0.92       115\n",
      "         1.0       0.44      0.51      0.47        63\n",
      "         2.0       0.81      0.61      0.70       149\n",
      "         3.0       0.75      0.74      0.74       159\n",
      "         4.0       0.61      0.77      0.68       180\n",
      "         5.0       0.71      0.73      0.72       157\n",
      "         6.0       0.34      0.37      0.35       109\n",
      "         7.0       0.87      0.75      0.81       118\n",
      "\n",
      "    accuracy                           0.69      1050\n",
      "   macro avg       0.69      0.67      0.67      1050\n",
      "weighted avg       0.71      0.69      0.69      1050\n",
      "\n",
      "[29,     1] loss: 0.025\n",
      "acc:0.6250 \n",
      "err:0.3750 \n",
      "[TEST RESULT]\n",
      "acc:0.7276 \n",
      "err:0.2724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.84      0.91       115\n",
      "         1.0       0.89      0.27      0.41        63\n",
      "         2.0       0.54      0.87      0.67       149\n",
      "         3.0       0.71      0.72      0.72       159\n",
      "         4.0       0.82      0.76      0.79       180\n",
      "         5.0       0.73      0.65      0.69       157\n",
      "         6.0       0.79      0.72      0.76       109\n",
      "         7.0       0.70      0.75      0.72       118\n",
      "\n",
      "    accuracy                           0.73      1050\n",
      "   macro avg       0.77      0.70      0.71      1050\n",
      "weighted avg       0.76      0.73      0.73      1050\n",
      "\n",
      "[30,     1] loss: 0.012\n",
      "acc:0.7656 \n",
      "err:0.2344 \n",
      "[TEST RESULT]\n",
      "acc:0.7505 \n",
      "err:0.2495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.81      0.89       115\n",
      "         1.0       0.46      0.51      0.48        63\n",
      "         2.0       0.79      0.72      0.75       149\n",
      "         3.0       0.73      0.74      0.73       159\n",
      "         4.0       0.84      0.84      0.84       180\n",
      "         5.0       0.54      0.87      0.67       157\n",
      "         6.0       0.97      0.66      0.79       109\n",
      "         7.0       0.93      0.67      0.78       118\n",
      "\n",
      "    accuracy                           0.75      1050\n",
      "   macro avg       0.78      0.73      0.74      1050\n",
      "weighted avg       0.79      0.75      0.76      1050\n",
      "\n",
      "[31,     1] loss: 0.011\n",
      "acc:0.7656 \n",
      "err:0.2344 \n",
      "[TEST RESULT]\n",
      "acc:0.7581 \n",
      "err:0.2419\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.86      0.90       115\n",
      "         1.0       0.62      0.54      0.58        63\n",
      "         2.0       0.91      0.62      0.74       149\n",
      "         3.0       0.62      0.82      0.71       159\n",
      "         4.0       0.82      0.82      0.82       180\n",
      "         5.0       0.66      0.78      0.71       157\n",
      "         6.0       0.93      0.68      0.78       109\n",
      "         7.0       0.72      0.81      0.76       118\n",
      "\n",
      "    accuracy                           0.76      1050\n",
      "   macro avg       0.78      0.74      0.75      1050\n",
      "weighted avg       0.78      0.76      0.76      1050\n",
      "\n",
      "[32,     1] loss: 0.005\n",
      "acc:0.8438 \n",
      "err:0.1562 \n",
      "[TEST RESULT]\n",
      "acc:0.7448 \n",
      "err:0.2552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.81      0.89       115\n",
      "         1.0       0.67      0.59      0.63        63\n",
      "         2.0       0.53      0.82      0.65       149\n",
      "         3.0       0.84      0.75      0.79       159\n",
      "         4.0       0.68      0.84      0.75       180\n",
      "         5.0       0.87      0.57      0.69       157\n",
      "         6.0       0.79      0.78      0.78       109\n",
      "         7.0       0.87      0.71      0.78       118\n",
      "\n",
      "    accuracy                           0.74      1050\n",
      "   macro avg       0.78      0.73      0.75      1050\n",
      "weighted avg       0.78      0.74      0.75      1050\n",
      "\n",
      "[33,     1] loss: 0.008\n",
      "acc:0.8125 \n",
      "err:0.1875 \n",
      "[TEST RESULT]\n",
      "acc:0.7210 \n",
      "err:0.2790\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.79      0.88       115\n",
      "         1.0       0.52      0.40      0.45        63\n",
      "         2.0       0.72      0.65      0.69       149\n",
      "         3.0       0.57      0.90      0.70       159\n",
      "         4.0       0.94      0.69      0.79       180\n",
      "         5.0       0.84      0.68      0.75       157\n",
      "         6.0       0.57      0.84      0.68       109\n",
      "         7.0       0.75      0.66      0.70       118\n",
      "\n",
      "    accuracy                           0.72      1050\n",
      "   macro avg       0.74      0.70      0.71      1050\n",
      "weighted avg       0.76      0.72      0.72      1050\n",
      "\n",
      "[34,     1] loss: 0.012\n",
      "acc:0.7188 \n",
      "err:0.2812 \n",
      "[TEST RESULT]\n",
      "acc:0.7010 \n",
      "err:0.2990\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.81      0.88       115\n",
      "         1.0       0.30      0.79      0.43        63\n",
      "         2.0       0.62      0.75      0.68       149\n",
      "         3.0       0.96      0.57      0.71       159\n",
      "         4.0       0.73      0.81      0.77       180\n",
      "         5.0       0.90      0.52      0.66       157\n",
      "         6.0       0.69      0.72      0.71       109\n",
      "         7.0       0.79      0.73      0.76       118\n",
      "\n",
      "    accuracy                           0.70      1050\n",
      "   macro avg       0.74      0.71      0.70      1050\n",
      "weighted avg       0.78      0.70      0.71      1050\n",
      "\n",
      "[35,     1] loss: 0.022\n",
      "acc:0.6719 \n",
      "err:0.3281 \n",
      "[TEST RESULT]\n",
      "acc:0.7305 \n",
      "err:0.2695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.85      0.90       115\n",
      "         1.0       0.46      0.52      0.49        63\n",
      "         2.0       0.82      0.70      0.75       149\n",
      "         3.0       0.90      0.67      0.77       159\n",
      "         4.0       0.80      0.84      0.82       180\n",
      "         5.0       0.83      0.56      0.67       157\n",
      "         6.0       0.76      0.73      0.75       109\n",
      "         7.0       0.46      0.90      0.61       118\n",
      "\n",
      "    accuracy                           0.73      1050\n",
      "   macro avg       0.75      0.72      0.72      1050\n",
      "weighted avg       0.78      0.73      0.74      1050\n",
      "\n",
      "[36,     1] loss: 0.012\n",
      "acc:0.6875 \n",
      "err:0.3125 \n",
      "[TEST RESULT]\n",
      "acc:0.7590 \n",
      "err:0.2410\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.85      0.90       115\n",
      "         1.0       0.72      0.44      0.55        63\n",
      "         2.0       0.77      0.74      0.76       149\n",
      "         3.0       0.94      0.68      0.79       159\n",
      "         4.0       0.82      0.86      0.84       180\n",
      "         5.0       0.67      0.72      0.70       157\n",
      "         6.0       0.57      0.78      0.66       109\n",
      "         7.0       0.69      0.84      0.76       118\n",
      "\n",
      "    accuracy                           0.76      1050\n",
      "   macro avg       0.77      0.74      0.74      1050\n",
      "weighted avg       0.78      0.76      0.76      1050\n",
      "\n",
      "[37,     1] loss: 0.007\n",
      "acc:0.8281 \n",
      "err:0.1719 \n",
      "[TEST RESULT]\n",
      "acc:0.7390 \n",
      "err:0.2610\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.85      0.88       115\n",
      "         1.0       0.41      0.83      0.55        63\n",
      "         2.0       0.91      0.57      0.70       149\n",
      "         3.0       0.93      0.70      0.80       159\n",
      "         4.0       0.95      0.68      0.79       180\n",
      "         5.0       0.56      0.84      0.67       157\n",
      "         6.0       0.76      0.72      0.74       109\n",
      "         7.0       0.72      0.83      0.77       118\n",
      "\n",
      "    accuracy                           0.74      1050\n",
      "   macro avg       0.77      0.75      0.74      1050\n",
      "weighted avg       0.80      0.74      0.75      1050\n",
      "\n",
      "[38,     1] loss: 0.011\n",
      "acc:0.6875 \n",
      "err:0.3125 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST RESULT]\n",
      "acc:0.7571 \n",
      "err:0.2429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.82      0.90       115\n",
      "         1.0       0.59      0.51      0.55        63\n",
      "         2.0       0.67      0.81      0.73       149\n",
      "         3.0       0.88      0.69      0.77       159\n",
      "         4.0       0.86      0.76      0.80       180\n",
      "         5.0       0.64      0.84      0.73       157\n",
      "         6.0       0.68      0.76      0.72       109\n",
      "         7.0       0.80      0.75      0.77       118\n",
      "\n",
      "    accuracy                           0.76      1050\n",
      "   macro avg       0.76      0.74      0.75      1050\n",
      "weighted avg       0.78      0.76      0.76      1050\n",
      "\n",
      "[39,     1] loss: 0.012\n",
      "acc:0.7969 \n",
      "err:0.2031 \n",
      "[TEST RESULT]\n",
      "acc:0.6410 \n",
      "err:0.3590\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.88      0.81       115\n",
      "         1.0       0.52      0.51      0.51        63\n",
      "         2.0       0.73      0.60      0.66       149\n",
      "         3.0       0.43      0.91      0.59       159\n",
      "         4.0       0.92      0.61      0.73       180\n",
      "         5.0       0.61      0.70      0.65       157\n",
      "         6.0       0.92      0.10      0.18       109\n",
      "         7.0       0.87      0.65      0.74       118\n",
      "\n",
      "    accuracy                           0.64      1050\n",
      "   macro avg       0.72      0.62      0.61      1050\n",
      "weighted avg       0.72      0.64      0.63      1050\n",
      "\n",
      "[40,     1] loss: 0.043\n",
      "acc:0.6562 \n",
      "err:0.3438 \n",
      "[TEST RESULT]\n",
      "acc:0.7133 \n",
      "err:0.2867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.86      0.85       115\n",
      "         1.0       0.78      0.46      0.58        63\n",
      "         2.0       0.89      0.56      0.69       149\n",
      "         3.0       0.57      0.85      0.68       159\n",
      "         4.0       0.79      0.78      0.78       180\n",
      "         5.0       0.86      0.52      0.65       157\n",
      "         6.0       0.84      0.70      0.76       109\n",
      "         7.0       0.52      0.88      0.65       118\n",
      "\n",
      "    accuracy                           0.71      1050\n",
      "   macro avg       0.76      0.70      0.71      1050\n",
      "weighted avg       0.76      0.71      0.71      1050\n",
      "\n",
      "[41,     1] loss: 0.010\n",
      "acc:0.7188 \n",
      "err:0.2812 \n",
      "[TEST RESULT]\n",
      "acc:0.7400 \n",
      "err:0.2600\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.84      0.92       115\n",
      "         1.0       0.37      0.89      0.53        63\n",
      "         2.0       0.81      0.60      0.69       149\n",
      "         3.0       0.73      0.78      0.75       159\n",
      "         4.0       0.92      0.72      0.81       180\n",
      "         5.0       0.79      0.71      0.75       157\n",
      "         6.0       0.75      0.75      0.75       109\n",
      "         7.0       0.66      0.74      0.70       118\n",
      "\n",
      "    accuracy                           0.74      1050\n",
      "   macro avg       0.75      0.75      0.74      1050\n",
      "weighted avg       0.79      0.74      0.75      1050\n",
      "\n",
      "[42,     1] loss: 0.010\n",
      "acc:0.7500 \n",
      "err:0.2500 \n",
      "[TEST RESULT]\n",
      "acc:0.7457 \n",
      "err:0.2543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.89      0.79       115\n",
      "         1.0       0.71      0.56      0.63        63\n",
      "         2.0       0.83      0.67      0.74       149\n",
      "         3.0       0.55      0.86      0.67       159\n",
      "         4.0       0.91      0.76      0.83       180\n",
      "         5.0       0.78      0.68      0.73       157\n",
      "         6.0       0.82      0.82      0.82       109\n",
      "         7.0       0.83      0.64      0.72       118\n",
      "\n",
      "    accuracy                           0.75      1050\n",
      "   macro avg       0.77      0.73      0.74      1050\n",
      "weighted avg       0.77      0.75      0.75      1050\n",
      "\n",
      "[43,     1] loss: 0.010\n",
      "acc:0.7656 \n",
      "err:0.2344 \n",
      "[TEST RESULT]\n",
      "acc:0.6743 \n",
      "err:0.3257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.83      0.86       115\n",
      "         1.0       0.57      0.41      0.48        63\n",
      "         2.0       0.87      0.52      0.65       149\n",
      "         3.0       0.96      0.63      0.76       159\n",
      "         4.0       0.44      0.94      0.60       180\n",
      "         5.0       0.86      0.55      0.67       157\n",
      "         6.0       0.62      0.69      0.65       109\n",
      "         7.0       0.80      0.65      0.72       118\n",
      "\n",
      "    accuracy                           0.67      1050\n",
      "   macro avg       0.75      0.65      0.67      1050\n",
      "weighted avg       0.76      0.67      0.68      1050\n",
      "\n",
      "[44,     1] loss: 0.013\n",
      "acc:0.7031 \n",
      "err:0.2969 \n",
      "[TEST RESULT]\n",
      "acc:0.6505 \n",
      "err:0.3495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.81      0.87       115\n",
      "         1.0       0.23      0.81      0.36        63\n",
      "         2.0       0.57      0.66      0.61       149\n",
      "         3.0       0.82      0.65      0.73       159\n",
      "         4.0       0.92      0.57      0.71       180\n",
      "         5.0       0.93      0.54      0.69       157\n",
      "         6.0       0.60      0.73      0.66       109\n",
      "         7.0       0.74      0.58      0.65       118\n",
      "\n",
      "    accuracy                           0.65      1050\n",
      "   macro avg       0.72      0.67      0.66      1050\n",
      "weighted avg       0.76      0.65      0.68      1050\n",
      "\n",
      "[45,     1] loss: 0.018\n",
      "acc:0.6875 \n",
      "err:0.3125 \n",
      "[TEST RESULT]\n",
      "acc:0.7524 \n",
      "err:0.2476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.88      0.92       115\n",
      "         1.0       0.66      0.59      0.62        63\n",
      "         2.0       0.75      0.74      0.74       149\n",
      "         3.0       0.57      0.84      0.68       159\n",
      "         4.0       0.92      0.74      0.82       180\n",
      "         5.0       0.67      0.75      0.71       157\n",
      "         6.0       0.85      0.76      0.80       109\n",
      "         7.0       0.81      0.64      0.71       118\n",
      "\n",
      "    accuracy                           0.75      1050\n",
      "   macro avg       0.78      0.74      0.75      1050\n",
      "weighted avg       0.78      0.75      0.76      1050\n",
      "\n",
      "[46,     1] loss: 0.007\n",
      "acc:0.8281 \n",
      "err:0.1719 \n",
      "[TEST RESULT]\n",
      "acc:0.7543 \n",
      "err:0.2457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.83      0.90       115\n",
      "         1.0       0.55      0.67      0.60        63\n",
      "         2.0       0.76      0.72      0.74       149\n",
      "         3.0       0.63      0.84      0.72       159\n",
      "         4.0       0.95      0.72      0.82       180\n",
      "         5.0       0.72      0.71      0.72       157\n",
      "         6.0       0.93      0.69      0.79       109\n",
      "         7.0       0.65      0.83      0.73       118\n",
      "\n",
      "    accuracy                           0.75      1050\n",
      "   macro avg       0.77      0.75      0.75      1050\n",
      "weighted avg       0.78      0.75      0.76      1050\n",
      "\n",
      "[47,     1] loss: 0.006\n",
      "acc:0.8750 \n",
      "err:0.1250 \n",
      "[TEST RESULT]\n",
      "acc:0.7114 \n",
      "err:0.2886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.88      0.81       115\n",
      "         1.0       0.60      0.63      0.62        63\n",
      "         2.0       0.62      0.77      0.68       149\n",
      "         3.0       0.93      0.66      0.77       159\n",
      "         4.0       0.70      0.76      0.73       180\n",
      "         5.0       0.80      0.60      0.69       157\n",
      "         6.0       0.90      0.61      0.73       109\n",
      "         7.0       0.55      0.77      0.64       118\n",
      "\n",
      "    accuracy                           0.71      1050\n",
      "   macro avg       0.73      0.71      0.71      1050\n",
      "weighted avg       0.74      0.71      0.71      1050\n",
      "\n",
      "[48,     1] loss: 0.010\n",
      "acc:0.7969 \n",
      "err:0.2031 \n",
      "[TEST RESULT]\n",
      "acc:0.7476 \n",
      "err:0.2524\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.85      0.90       115\n",
      "         1.0       0.44      0.87      0.59        63\n",
      "         2.0       0.85      0.66      0.74       149\n",
      "         3.0       0.78      0.75      0.77       159\n",
      "         4.0       0.91      0.64      0.76       180\n",
      "         5.0       0.64      0.77      0.70       157\n",
      "         6.0       0.68      0.80      0.73       109\n",
      "         7.0       0.82      0.75      0.78       118\n",
      "\n",
      "    accuracy                           0.75      1050\n",
      "   macro avg       0.76      0.76      0.75      1050\n",
      "weighted avg       0.78      0.75      0.75      1050\n",
      "\n",
      "[49,     1] loss: 0.015\n",
      "acc:0.8281 \n",
      "err:0.1719 \n",
      "[TEST RESULT]\n",
      "acc:0.7495 \n",
      "err:0.2505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.87      0.88       115\n",
      "         1.0       0.72      0.57      0.64        63\n",
      "         2.0       0.68      0.74      0.71       149\n",
      "         3.0       0.89      0.68      0.77       159\n",
      "         4.0       0.86      0.77      0.81       180\n",
      "         5.0       0.52      0.90      0.66       157\n",
      "         6.0       0.88      0.72      0.79       109\n",
      "         7.0       0.93      0.63      0.75       118\n",
      "\n",
      "    accuracy                           0.75      1050\n",
      "   macro avg       0.79      0.74      0.75      1050\n",
      "weighted avg       0.79      0.75      0.76      1050\n",
      "\n",
      "[50,     1] loss: 0.010\n",
      "acc:0.7812 \n",
      "err:0.2188 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST RESULT]\n",
      "acc:0.7629 \n",
      "err:0.2371\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.85      0.88       115\n",
      "         1.0       0.58      0.67      0.62        63\n",
      "         2.0       0.71      0.72      0.72       149\n",
      "         3.0       0.76      0.80      0.78       159\n",
      "         4.0       0.89      0.80      0.84       180\n",
      "         5.0       0.87      0.68      0.76       157\n",
      "         6.0       0.62      0.81      0.70       109\n",
      "         7.0       0.72      0.75      0.73       118\n",
      "\n",
      "    accuracy                           0.76      1050\n",
      "   macro avg       0.75      0.76      0.75      1050\n",
      "weighted avg       0.78      0.76      0.77      1050\n",
      "\n",
      "Finished Training 50\n"
     ]
    }
   ],
   "source": [
    "net=Solver(params)\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST RESULT]\n",
      "acc:0.1408 \n",
      "err:0.8592\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       126\n",
      "         1.0       0.00      0.00      0.00        74\n",
      "         2.0       0.00      0.00      0.00       151\n",
      "         3.0       0.00      0.00      0.00       158\n",
      "         4.0       0.00      0.00      0.00       174\n",
      "         5.0       0.14      1.00      0.25       148\n",
      "         6.0       0.00      0.00      0.00       104\n",
      "         7.0       0.00      0.00      0.00       116\n",
      "\n",
      "    accuracy                           0.14      1051\n",
      "   macro avg       0.02      0.12      0.03      1051\n",
      "weighted avg       0.02      0.14      0.03      1051\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shiji\\Anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    }
   ],
   "source": [
    " net.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "dic_res = {'base_train':[],\n",
    "          'base_valid':[],\n",
    "          'bib_valid':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res.json', 'w') as jf:\n",
    "    json.dump(dic_res, jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vib_acc = [0.23, .30, .4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
