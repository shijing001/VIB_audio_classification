{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  you can also run in the command line directly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ARGUMENTS]\n",
      "Namespace(K=256, batch_size=32, beta=0.01, ckpt_dir='checkpoints', cuda=True, dataset={'train': <torch.utils.data.dataloader.DataLoader object at 0x7fb493abcf10>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7fb49a0eb450>}, dset_dir='joblib_features', env_name='main', epoch=200, load_ckpt='', lr=0.001, mode='train', num_avg=0, seed=1, summary_dir='summary', tensorboard=False)\n",
      "\n",
      "/Users/sunhuiming/Desktop/VIB_audio_classification-main/model.py:67: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  nn.init.xavier_uniform(m.weight,gain=nn.init.calculate_gain('relu'))\n",
      "{'train': <torch.utils.data.dataloader.DataLoader object at 0x7fb493abcf10>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7fb49a0eb450>}\n",
      "epoch.  1\n",
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "[TEST RESULT]\n",
      "epoch:1 IZY:-5663.29 IZX:13230633.00 acc:0.1351 avg_acc:0.0000 err:0.8649 avg_erra:1.0000\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.14      0.20      0.17       113\n",
      "         1.0       0.00      0.00      0.00        75\n",
      "         2.0       0.12      0.21      0.15       154\n",
      "         3.0       0.00      0.00      0.00       165\n",
      "         4.0       0.14      0.43      0.21       150\n",
      "         5.0       0.31      0.02      0.04       171\n",
      "         6.0       0.16      0.05      0.08       112\n",
      "         7.0       0.10      0.12      0.11       111\n",
      "\n",
      "    accuracy                           0.14      1051\n",
      "   macro avg       0.12      0.13      0.10      1051\n",
      "weighted avg       0.13      0.14      0.10      1051\n",
      "\n",
      "epoch.  2\n",
      "[TEST RESULT]\n",
      "epoch:2 IZY:-3913.02 IZX:7182366.00 acc:0.1475 avg_acc:0.0000 err:0.8525 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.14      0.19      0.16       113\n",
      "         1.0       0.20      0.01      0.03        75\n",
      "         2.0       0.17      0.21      0.19       154\n",
      "         3.0       0.00      0.00      0.00       165\n",
      "         4.0       0.16      0.52      0.24       150\n",
      "         5.0       0.11      0.01      0.01       171\n",
      "         6.0       0.16      0.05      0.08       112\n",
      "         7.0       0.10      0.14      0.11       111\n",
      "\n",
      "    accuracy                           0.15      1051\n",
      "   macro avg       0.13      0.14      0.10      1051\n",
      "weighted avg       0.12      0.15      0.10      1051\n",
      "\n",
      "epoch.  3\n",
      "[TEST RESULT]\n",
      "epoch:3 IZY:-2393.32 IZX:3743382.50 acc:0.1874 avg_acc:0.0000 err:0.8126 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.17      0.18      0.18       113\n",
      "         1.0       0.14      0.03      0.04        75\n",
      "         2.0       0.19      0.23      0.21       154\n",
      "         3.0       0.00      0.00      0.00       165\n",
      "         4.0       0.21      0.69      0.32       150\n",
      "         5.0       0.31      0.03      0.05       171\n",
      "         6.0       0.09      0.04      0.06       112\n",
      "         7.0       0.15      0.23      0.18       111\n",
      "\n",
      "    accuracy                           0.19      1051\n",
      "   macro avg       0.16      0.18      0.13      1051\n",
      "weighted avg       0.16      0.19      0.13      1051\n",
      "\n",
      "epoch.  4\n",
      "[TEST RESULT]\n",
      "epoch:4 IZY:-1633.72 IZX:1923510.50 acc:0.2008 avg_acc:0.0000 err:0.7992 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.24      0.25      0.24       113\n",
      "         1.0       0.18      0.04      0.07        75\n",
      "         2.0       0.23      0.25      0.24       154\n",
      "         3.0       0.00      0.00      0.00       165\n",
      "         4.0       0.19      0.65      0.30       150\n",
      "         5.0       0.28      0.04      0.07       171\n",
      "         6.0       0.23      0.17      0.20       112\n",
      "         7.0       0.13      0.16      0.14       111\n",
      "\n",
      "    accuracy                           0.20      1051\n",
      "   macro avg       0.18      0.20      0.16      1051\n",
      "weighted avg       0.18      0.20      0.16      1051\n",
      "\n",
      "epoch.  5\n",
      "[TEST RESULT]\n",
      "epoch:5 IZY:-947.88 IZX:982223.69 acc:0.2103 avg_acc:0.0000 err:0.7897 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.29      0.27      0.28       113\n",
      "         1.0       0.12      0.07      0.09        75\n",
      "         2.0       0.22      0.19      0.20       154\n",
      "         3.0       0.00      0.00      0.00       165\n",
      "         4.0       0.18      0.63      0.28       150\n",
      "         5.0       0.42      0.08      0.14       171\n",
      "         6.0       0.25      0.17      0.20       112\n",
      "         7.0       0.20      0.27      0.23       111\n",
      "\n",
      "    accuracy                           0.21      1051\n",
      "   macro avg       0.21      0.21      0.18      1051\n",
      "weighted avg       0.22      0.21      0.17      1051\n",
      "\n",
      "epoch.  6\n",
      "[TEST RESULT]\n",
      "epoch:6 IZY:-608.53 IZX:518718.41 acc:0.2407 avg_acc:0.0000 err:0.7593 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.31      0.26      0.28       113\n",
      "         1.0       0.14      0.15      0.14        75\n",
      "         2.0       0.25      0.19      0.22       154\n",
      "         3.0       0.80      0.02      0.05       165\n",
      "         4.0       0.22      0.75      0.34       150\n",
      "         5.0       0.60      0.16      0.25       171\n",
      "         6.0       0.22      0.20      0.21       112\n",
      "         7.0       0.18      0.16      0.17       111\n",
      "\n",
      "    accuracy                           0.24      1051\n",
      "   macro avg       0.34      0.24      0.21      1051\n",
      "weighted avg       0.38      0.24      0.21      1051\n",
      "\n",
      "epoch.  7\n",
      "[TEST RESULT]\n",
      "epoch:7 IZY:-373.59 IZX:274348.34 acc:0.2778 avg_acc:0.0000 err:0.7222 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.34      0.21      0.26       113\n",
      "         1.0       0.09      0.13      0.10        75\n",
      "         2.0       0.34      0.20      0.25       154\n",
      "         3.0       0.74      0.14      0.23       165\n",
      "         4.0       0.24      0.81      0.37       150\n",
      "         5.0       0.51      0.20      0.29       171\n",
      "         6.0       0.30      0.23      0.26       112\n",
      "         7.0       0.27      0.20      0.23       111\n",
      "\n",
      "    accuracy                           0.28      1051\n",
      "   macro avg       0.35      0.27      0.25      1051\n",
      "weighted avg       0.39      0.28      0.26      1051\n",
      "\n",
      "epoch.  8\n",
      "[TEST RESULT]\n",
      "epoch:8 IZY:-257.53 IZX:147424.42 acc:0.3397 avg_acc:0.0000 err:0.6603 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.42      0.48       113\n",
      "         1.0       0.10      0.29      0.15        75\n",
      "         2.0       0.46      0.19      0.27       154\n",
      "         3.0       0.73      0.18      0.29       165\n",
      "         4.0       0.29      0.75      0.41       150\n",
      "         5.0       0.61      0.41      0.49       171\n",
      "         6.0       0.27      0.18      0.22       112\n",
      "         7.0       0.45      0.23      0.31       111\n",
      "\n",
      "    accuracy                           0.34      1051\n",
      "   macro avg       0.43      0.33      0.33      1051\n",
      "weighted avg       0.47      0.34      0.34      1051\n",
      "\n",
      "epoch.  9\n",
      "[TEST RESULT]\n",
      "epoch:9 IZY:-187.88 IZX:81897.82 acc:0.3796 avg_acc:0.0000 err:0.6204 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.44      0.51       113\n",
      "         1.0       0.14      0.53      0.22        75\n",
      "         2.0       0.30      0.06      0.11       154\n",
      "         3.0       0.61      0.38      0.47       165\n",
      "         4.0       0.36      0.73      0.48       150\n",
      "         5.0       0.59      0.46      0.51       171\n",
      "         6.0       0.44      0.24      0.31       112\n",
      "         7.0       0.45      0.20      0.28       111\n",
      "\n",
      "    accuracy                           0.38      1051\n",
      "   macro avg       0.43      0.38      0.36      1051\n",
      "weighted avg       0.45      0.38      0.37      1051\n",
      "\n",
      "epoch.  10\n",
      "[TEST RESULT]\n",
      "epoch:10 IZY:-158.94 IZX:49488.32 acc:0.4044 avg_acc:0.0000 err:0.5956 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.51      0.60       113\n",
      "         1.0       0.13      0.61      0.21        75\n",
      "         2.0       0.42      0.06      0.11       154\n",
      "         3.0       0.53      0.50      0.51       165\n",
      "         4.0       0.44      0.67      0.53       150\n",
      "         5.0       0.73      0.47      0.57       171\n",
      "         6.0       0.49      0.20      0.28       112\n",
      "         7.0       0.62      0.23      0.33       111\n",
      "\n",
      "    accuracy                           0.40      1051\n",
      "   macro avg       0.51      0.41      0.39      1051\n",
      "weighted avg       0.53      0.40      0.41      1051\n",
      "\n",
      "epoch.  11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST RESULT]\n",
      "epoch:11 IZY:-130.98 IZX:31785.26 acc:0.4129 avg_acc:0.0000 err:0.5871 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.50      0.58       113\n",
      "         1.0       0.12      0.63      0.21        75\n",
      "         2.0       0.64      0.06      0.11       154\n",
      "         3.0       0.50      0.52      0.51       165\n",
      "         4.0       0.47      0.67      0.56       150\n",
      "         5.0       0.73      0.53      0.61       171\n",
      "         6.0       0.66      0.21      0.31       112\n",
      "         7.0       0.68      0.19      0.30       111\n",
      "\n",
      "    accuracy                           0.41      1051\n",
      "   macro avg       0.56      0.41      0.40      1051\n",
      "weighted avg       0.58      0.41      0.42      1051\n",
      "\n",
      "epoch.  12\n",
      "[TEST RESULT]\n",
      "epoch:12 IZY:-111.55 IZX:21029.79 acc:0.4691 avg_acc:0.0000 err:0.5309 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.55      0.64       113\n",
      "         1.0       0.15      0.73      0.25        75\n",
      "         2.0       0.72      0.15      0.25       154\n",
      "         3.0       0.56      0.55      0.55       165\n",
      "         4.0       0.53      0.68      0.60       150\n",
      "         5.0       0.72      0.58      0.64       171\n",
      "         6.0       0.83      0.21      0.34       112\n",
      "         7.0       0.78      0.34      0.47       111\n",
      "\n",
      "    accuracy                           0.47      1051\n",
      "   macro avg       0.63      0.47      0.47      1051\n",
      "weighted avg       0.65      0.47      0.49      1051\n",
      "\n",
      "epoch.  13\n",
      "[TEST RESULT]\n",
      "epoch:13 IZY:-89.69 IZX:14993.85 acc:0.5157 avg_acc:0.0000 err:0.4843 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.60      0.69       113\n",
      "         1.0       0.16      0.76      0.27        75\n",
      "         2.0       0.66      0.27      0.38       154\n",
      "         3.0       0.62      0.52      0.56       165\n",
      "         4.0       0.61      0.75      0.67       150\n",
      "         5.0       0.74      0.60      0.66       171\n",
      "         6.0       0.81      0.27      0.40       112\n",
      "         7.0       0.75      0.41      0.53       111\n",
      "\n",
      "    accuracy                           0.52      1051\n",
      "   macro avg       0.65      0.52      0.52      1051\n",
      "weighted avg       0.67      0.52      0.54      1051\n",
      "\n",
      "epoch.  14\n",
      "[TEST RESULT]\n",
      "epoch:14 IZY:-70.11 IZX:11276.86 acc:0.5756 avg_acc:0.0000 err:0.4244 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.63      0.70       113\n",
      "         1.0       0.20      0.69      0.31        75\n",
      "         2.0       0.54      0.43      0.48       154\n",
      "         3.0       0.66      0.59      0.62       165\n",
      "         4.0       0.68      0.75      0.72       150\n",
      "         5.0       0.81      0.64      0.71       171\n",
      "         6.0       0.87      0.37      0.52       112\n",
      "         7.0       0.66      0.50      0.57       111\n",
      "\n",
      "    accuracy                           0.58      1051\n",
      "   macro avg       0.65      0.57      0.58      1051\n",
      "weighted avg       0.68      0.58      0.60      1051\n",
      "\n",
      "epoch.  15\n",
      "[TEST RESULT]\n",
      "epoch:15 IZY:-65.40 IZX:9986.35 acc:0.5890 avg_acc:0.0000 err:0.4110 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.65      0.74       113\n",
      "         1.0       0.21      0.77      0.34        75\n",
      "         2.0       0.49      0.51      0.50       154\n",
      "         3.0       0.80      0.52      0.63       165\n",
      "         4.0       0.71      0.67      0.69       150\n",
      "         5.0       0.84      0.63      0.72       171\n",
      "         6.0       0.89      0.44      0.59       112\n",
      "         7.0       0.62      0.60      0.61       111\n",
      "\n",
      "    accuracy                           0.59      1051\n",
      "   macro avg       0.68      0.60      0.60      1051\n",
      "weighted avg       0.71      0.59      0.62      1051\n",
      "\n",
      "epoch.  16\n",
      "[TEST RESULT]\n",
      "epoch:16 IZY:-61.52 IZX:8571.91 acc:0.6089 avg_acc:0.0000 err:0.3911 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.63      0.73       113\n",
      "         1.0       0.23      0.60      0.34        75\n",
      "         2.0       0.47      0.59      0.52       154\n",
      "         3.0       0.94      0.48      0.63       165\n",
      "         4.0       0.72      0.72      0.72       150\n",
      "         5.0       0.91      0.58      0.71       171\n",
      "         6.0       0.85      0.57      0.68       112\n",
      "         7.0       0.50      0.75      0.60       111\n",
      "\n",
      "    accuracy                           0.61      1051\n",
      "   macro avg       0.69      0.61      0.62      1051\n",
      "weighted avg       0.72      0.61      0.63      1051\n",
      "\n",
      "epoch.  17\n",
      "[TEST RESULT]\n",
      "epoch:17 IZY:-58.55 IZX:6869.52 acc:0.5947 avg_acc:0.0000 err:0.4053 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.65      0.74       113\n",
      "         1.0       0.28      0.43      0.34        75\n",
      "         2.0       0.45      0.62      0.52       154\n",
      "         3.0       0.89      0.44      0.59       165\n",
      "         4.0       0.77      0.71      0.74       150\n",
      "         5.0       0.95      0.54      0.69       171\n",
      "         6.0       0.86      0.56      0.68       112\n",
      "         7.0       0.35      0.79      0.49       111\n",
      "\n",
      "    accuracy                           0.59      1051\n",
      "   macro avg       0.68      0.59      0.60      1051\n",
      "weighted avg       0.71      0.59      0.62      1051\n",
      "\n",
      "epoch.  18\n",
      "[TEST RESULT]\n",
      "epoch:18 IZY:-57.09 IZX:5556.80 acc:0.6099 avg_acc:0.0000 err:0.3901 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.65      0.78       113\n",
      "         1.0       0.38      0.20      0.26        75\n",
      "         2.0       0.51      0.62      0.56       154\n",
      "         3.0       0.90      0.47      0.62       165\n",
      "         4.0       0.77      0.80      0.79       150\n",
      "         5.0       0.95      0.58      0.72       171\n",
      "         6.0       0.71      0.58      0.64       112\n",
      "         7.0       0.31      0.86      0.45       111\n",
      "\n",
      "    accuracy                           0.61      1051\n",
      "   macro avg       0.69      0.59      0.60      1051\n",
      "weighted avg       0.72      0.61      0.63      1051\n",
      "\n",
      "epoch.  19\n",
      "[TEST RESULT]\n",
      "epoch:19 IZY:-60.88 IZX:4568.61 acc:0.5747 avg_acc:0.0000 err:0.4253 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.56      0.70       113\n",
      "         1.0       0.26      0.07      0.11        75\n",
      "         2.0       0.67      0.47      0.56       154\n",
      "         3.0       0.86      0.47      0.61       165\n",
      "         4.0       0.69      0.77      0.73       150\n",
      "         5.0       0.97      0.58      0.73       171\n",
      "         6.0       0.39      0.71      0.50       112\n",
      "         7.0       0.31      0.81      0.45       111\n",
      "\n",
      "    accuracy                           0.57      1051\n",
      "   macro avg       0.64      0.56      0.55      1051\n",
      "weighted avg       0.68      0.57      0.58      1051\n",
      "\n",
      "epoch.  20\n",
      "[TEST RESULT]\n",
      "epoch:20 IZY:-67.07 IZX:3588.00 acc:0.5233 avg_acc:0.0000 err:0.4767 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.47      0.59       113\n",
      "         1.0       0.14      0.04      0.06        75\n",
      "         2.0       0.48      0.30      0.37       154\n",
      "         3.0       0.76      0.54      0.63       165\n",
      "         4.0       0.76      0.60      0.67       150\n",
      "         5.0       0.83      0.54      0.65       171\n",
      "         6.0       0.43      0.75      0.55       112\n",
      "         7.0       0.29      0.84      0.43       111\n",
      "\n",
      "    accuracy                           0.52      1051\n",
      "   macro avg       0.56      0.51      0.49      1051\n",
      "weighted avg       0.61      0.52      0.53      1051\n",
      "\n",
      "epoch.  21\n",
      "[TEST RESULT]\n",
      "epoch:21 IZY:-73.95 IZX:2925.11 acc:0.4424 avg_acc:0.0000 err:0.5576 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.39      0.50       113\n",
      "         1.0       0.22      0.11      0.14        75\n",
      "         2.0       0.39      0.45      0.42       154\n",
      "         3.0       0.70      0.50      0.59       165\n",
      "         4.0       0.69      0.45      0.55       150\n",
      "         5.0       0.35      0.15      0.21       171\n",
      "         6.0       0.42      0.70      0.52       112\n",
      "         7.0       0.30      0.80      0.43       111\n",
      "\n",
      "    accuracy                           0.44      1051\n",
      "   macro avg       0.47      0.44      0.42      1051\n",
      "weighted avg       0.49      0.44      0.43      1051\n",
      "\n",
      "epoch.  22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST RESULT]\n",
      "epoch:22 IZY:-69.85 IZX:2526.90 acc:0.4824 avg_acc:0.0000 err:0.5176 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.54      0.50       113\n",
      "         1.0       0.19      0.07      0.10        75\n",
      "         2.0       0.35      0.55      0.43       154\n",
      "         3.0       0.64      0.54      0.58       165\n",
      "         4.0       0.66      0.48      0.56       150\n",
      "         5.0       0.46      0.22      0.29       171\n",
      "         6.0       0.60      0.70      0.64       112\n",
      "         7.0       0.41      0.72      0.52       111\n",
      "\n",
      "    accuracy                           0.48      1051\n",
      "   macro avg       0.47      0.48      0.45      1051\n",
      "weighted avg       0.49      0.48      0.47      1051\n",
      "\n",
      "epoch.  23\n",
      "[TEST RESULT]\n",
      "epoch:23 IZY:-61.87 IZX:2199.80 acc:0.5347 avg_acc:0.0000 err:0.4653 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      0.64      0.49       113\n",
      "         1.0       0.26      0.09      0.14        75\n",
      "         2.0       0.42      0.55      0.47       154\n",
      "         3.0       0.56      0.58      0.57       165\n",
      "         4.0       0.72      0.58      0.64       150\n",
      "         5.0       0.56      0.40      0.47       171\n",
      "         6.0       0.76      0.68      0.72       112\n",
      "         7.0       0.55      0.65      0.60       111\n",
      "\n",
      "    accuracy                           0.53      1051\n",
      "   macro avg       0.53      0.52      0.51      1051\n",
      "weighted avg       0.54      0.53      0.53      1051\n",
      "\n",
      "epoch.  24\n",
      "[TEST RESULT]\n",
      "epoch:24 IZY:-63.45 IZX:1911.46 acc:0.5338 avg_acc:0.0000 err:0.4662 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.37      0.58      0.45       113\n",
      "         1.0       0.27      0.08      0.12        75\n",
      "         2.0       0.39      0.55      0.45       154\n",
      "         3.0       0.54      0.58      0.56       165\n",
      "         4.0       0.72      0.61      0.66       150\n",
      "         5.0       0.61      0.51      0.55       171\n",
      "         6.0       0.84      0.60      0.70       112\n",
      "         7.0       0.60      0.58      0.59       111\n",
      "\n",
      "    accuracy                           0.53      1051\n",
      "   macro avg       0.54      0.51      0.51      1051\n",
      "weighted avg       0.56      0.53      0.53      1051\n",
      "\n",
      "epoch.  25\n",
      "[TEST RESULT]\n",
      "epoch:25 IZY:-62.96 IZX:1761.51 acc:0.5385 avg_acc:0.0000 err:0.4615 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.35      0.45      0.40       113\n",
      "         1.0       0.08      0.03      0.04        75\n",
      "         2.0       0.39      0.62      0.48       154\n",
      "         3.0       0.54      0.55      0.54       165\n",
      "         4.0       0.65      0.65      0.65       150\n",
      "         5.0       0.76      0.55      0.64       171\n",
      "         6.0       0.75      0.62      0.68       112\n",
      "         7.0       0.66      0.59      0.62       111\n",
      "\n",
      "    accuracy                           0.54      1051\n",
      "   macro avg       0.52      0.51      0.51      1051\n",
      "weighted avg       0.55      0.54      0.54      1051\n",
      "\n",
      "epoch.  26\n",
      "[TEST RESULT]\n",
      "epoch:26 IZY:-58.79 IZX:1641.16 acc:0.5652 avg_acc:0.0000 err:0.4348 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.37      0.35      0.36       113\n",
      "         1.0       0.28      0.17      0.21        75\n",
      "         2.0       0.42      0.66      0.51       154\n",
      "         3.0       0.59      0.59      0.59       165\n",
      "         4.0       0.72      0.67      0.69       150\n",
      "         5.0       0.75      0.56      0.64       171\n",
      "         6.0       0.62      0.69      0.65       112\n",
      "         7.0       0.72      0.61      0.66       111\n",
      "\n",
      "    accuracy                           0.57      1051\n",
      "   macro avg       0.56      0.54      0.54      1051\n",
      "weighted avg       0.58      0.57      0.56      1051\n",
      "\n",
      "epoch.  27\n",
      "[TEST RESULT]\n",
      "epoch:27 IZY:-57.99 IZX:1565.89 acc:0.5918 avg_acc:0.0000 err:0.4082 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.44      0.47       113\n",
      "         1.0       0.21      0.16      0.18        75\n",
      "         2.0       0.47      0.68      0.55       154\n",
      "         3.0       0.56      0.59      0.57       165\n",
      "         4.0       0.79      0.70      0.74       150\n",
      "         5.0       0.76      0.61      0.68       171\n",
      "         6.0       0.62      0.70      0.66       112\n",
      "         7.0       0.71      0.65      0.68       111\n",
      "\n",
      "    accuracy                           0.59      1051\n",
      "   macro avg       0.58      0.56      0.57      1051\n",
      "weighted avg       0.60      0.59      0.59      1051\n",
      "\n",
      "epoch.  28\n",
      "[TEST RESULT]\n",
      "epoch:28 IZY:-54.06 IZX:1517.70 acc:0.6451 avg_acc:0.0000 err:0.3549 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.61      0.60       113\n",
      "         1.0       0.27      0.19      0.22        75\n",
      "         2.0       0.55      0.72      0.62       154\n",
      "         3.0       0.61      0.67      0.64       165\n",
      "         4.0       0.81      0.76      0.78       150\n",
      "         5.0       0.81      0.61      0.69       171\n",
      "         6.0       0.66      0.73      0.69       112\n",
      "         7.0       0.70      0.67      0.69       111\n",
      "\n",
      "    accuracy                           0.65      1051\n",
      "   macro avg       0.62      0.62      0.62      1051\n",
      "weighted avg       0.65      0.65      0.64      1051\n",
      "\n",
      "epoch.  29\n",
      "[TEST RESULT]\n",
      "epoch:29 IZY:-51.19 IZX:1458.21 acc:0.6299 avg_acc:0.0000 err:0.3701 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.59      0.61       113\n",
      "         1.0       0.24      0.27      0.25        75\n",
      "         2.0       0.57      0.67      0.61       154\n",
      "         3.0       0.57      0.58      0.58       165\n",
      "         4.0       0.79      0.78      0.78       150\n",
      "         5.0       0.83      0.61      0.71       171\n",
      "         6.0       0.58      0.76      0.66       112\n",
      "         7.0       0.74      0.62      0.68       111\n",
      "\n",
      "    accuracy                           0.63      1051\n",
      "   macro avg       0.62      0.61      0.61      1051\n",
      "weighted avg       0.65      0.63      0.63      1051\n",
      "\n",
      "epoch.  30\n",
      "[TEST RESULT]\n",
      "epoch:30 IZY:-50.47 IZX:1388.77 acc:0.6308 avg_acc:0.0000 err:0.3692 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.45      0.50       113\n",
      "         1.0       0.23      0.24      0.23        75\n",
      "         2.0       0.61      0.71      0.66       154\n",
      "         3.0       0.56      0.58      0.57       165\n",
      "         4.0       0.82      0.77      0.80       150\n",
      "         5.0       0.81      0.63      0.71       171\n",
      "         6.0       0.56      0.83      0.67       112\n",
      "         7.0       0.81      0.64      0.71       111\n",
      "\n",
      "    accuracy                           0.63      1051\n",
      "   macro avg       0.62      0.61      0.61      1051\n",
      "weighted avg       0.65      0.63      0.63      1051\n",
      "\n",
      "epoch.  31\n",
      "[TEST RESULT]\n",
      "epoch:31 IZY:-53.75 IZX:1324.44 acc:0.6013 avg_acc:0.0000 err:0.3987 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.35      0.25      0.29       113\n",
      "         1.0       0.18      0.19      0.18        75\n",
      "         2.0       0.62      0.69      0.65       154\n",
      "         3.0       0.53      0.59      0.56       165\n",
      "         4.0       0.83      0.79      0.81       150\n",
      "         5.0       0.77      0.63      0.69       171\n",
      "         6.0       0.54      0.79      0.64       112\n",
      "         7.0       0.78      0.66      0.71       111\n",
      "\n",
      "    accuracy                           0.60      1051\n",
      "   macro avg       0.57      0.57      0.57      1051\n",
      "weighted avg       0.61      0.60      0.60      1051\n",
      "\n",
      "epoch.  32\n",
      "[TEST RESULT]\n",
      "epoch:32 IZY:-51.00 IZX:1293.93 acc:0.6242 avg_acc:0.0000 err:0.3758 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      0.46      0.45       113\n",
      "         1.0       0.28      0.17      0.21        75\n",
      "         2.0       0.62      0.72      0.66       154\n",
      "         3.0       0.54      0.56      0.55       165\n",
      "         4.0       0.75      0.80      0.78       150\n",
      "         5.0       0.78      0.63      0.70       171\n",
      "         6.0       0.60      0.78      0.68       112\n",
      "         7.0       0.76      0.65      0.70       111\n",
      "\n",
      "    accuracy                           0.62      1051\n",
      "   macro avg       0.60      0.60      0.59      1051\n",
      "weighted avg       0.62      0.62      0.62      1051\n",
      "\n",
      "epoch.  33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST RESULT]\n",
      "epoch:33 IZY:-48.54 IZX:1298.69 acc:0.6432 avg_acc:0.0000 err:0.3568 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.54      0.53       113\n",
      "         1.0       0.15      0.09      0.11        75\n",
      "         2.0       0.58      0.71      0.64       154\n",
      "         3.0       0.58      0.58      0.58       165\n",
      "         4.0       0.79      0.80      0.79       150\n",
      "         5.0       0.75      0.67      0.71       171\n",
      "         6.0       0.76      0.78      0.77       112\n",
      "         7.0       0.74      0.74      0.74       111\n",
      "\n",
      "    accuracy                           0.64      1051\n",
      "   macro avg       0.61      0.61      0.61      1051\n",
      "weighted avg       0.63      0.64      0.64      1051\n",
      "\n",
      "epoch.  34\n",
      "[TEST RESULT]\n",
      "epoch:34 IZY:-48.52 IZX:1280.90 acc:0.6527 avg_acc:0.0000 err:0.3473 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.64      0.61       113\n",
      "         1.0       0.24      0.16      0.19        75\n",
      "         2.0       0.57      0.70      0.63       154\n",
      "         3.0       0.64      0.54      0.59       165\n",
      "         4.0       0.79      0.83      0.81       150\n",
      "         5.0       0.75      0.64      0.69       171\n",
      "         6.0       0.75      0.78      0.76       112\n",
      "         7.0       0.64      0.76      0.69       111\n",
      "\n",
      "    accuracy                           0.65      1051\n",
      "   macro avg       0.62      0.63      0.62      1051\n",
      "weighted avg       0.65      0.65      0.65      1051\n",
      "\n",
      "epoch.  35\n",
      "[TEST RESULT]\n",
      "epoch:35 IZY:-45.07 IZX:1269.83 acc:0.6727 avg_acc:0.0000 err:0.3273 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.73      0.67       113\n",
      "         1.0       0.33      0.16      0.22        75\n",
      "         2.0       0.58      0.77      0.66       154\n",
      "         3.0       0.61      0.56      0.58       165\n",
      "         4.0       0.77      0.81      0.79       150\n",
      "         5.0       0.77      0.66      0.71       171\n",
      "         6.0       0.78      0.75      0.76       112\n",
      "         7.0       0.73      0.74      0.73       111\n",
      "\n",
      "    accuracy                           0.67      1051\n",
      "   macro avg       0.65      0.65      0.64      1051\n",
      "weighted avg       0.67      0.67      0.66      1051\n",
      "\n",
      "epoch.  36\n",
      "[TEST RESULT]\n",
      "epoch:36 IZY:-46.85 IZX:1253.18 acc:0.6794 avg_acc:0.0000 err:0.3206 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.70      0.67       113\n",
      "         1.0       0.30      0.19      0.23        75\n",
      "         2.0       0.59      0.78      0.67       154\n",
      "         3.0       0.66      0.60      0.63       165\n",
      "         4.0       0.75      0.85      0.80       150\n",
      "         5.0       0.77      0.65      0.71       171\n",
      "         6.0       0.82      0.73      0.77       112\n",
      "         7.0       0.72      0.72      0.72       111\n",
      "\n",
      "    accuracy                           0.68      1051\n",
      "   macro avg       0.66      0.65      0.65      1051\n",
      "weighted avg       0.68      0.68      0.67      1051\n",
      "\n",
      "epoch.  37\n",
      "[TEST RESULT]\n",
      "epoch:37 IZY:-45.36 IZX:1238.67 acc:0.6698 avg_acc:0.0000 err:0.3302 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.70      0.66       113\n",
      "         1.0       0.28      0.19      0.22        75\n",
      "         2.0       0.56      0.77      0.65       154\n",
      "         3.0       0.62      0.56      0.59       165\n",
      "         4.0       0.79      0.80      0.80       150\n",
      "         5.0       0.79      0.65      0.72       171\n",
      "         6.0       0.81      0.74      0.78       112\n",
      "         7.0       0.71      0.77      0.74       111\n",
      "\n",
      "    accuracy                           0.67      1051\n",
      "   macro avg       0.65      0.65      0.64      1051\n",
      "weighted avg       0.67      0.67      0.67      1051\n",
      "\n",
      "epoch.  38\n",
      "[TEST RESULT]\n",
      "epoch:38 IZY:-43.58 IZX:1228.51 acc:0.6698 avg_acc:0.0000 err:0.3302 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.73      0.72       113\n",
      "         1.0       0.31      0.21      0.25        75\n",
      "         2.0       0.57      0.74      0.64       154\n",
      "         3.0       0.65      0.59      0.62       165\n",
      "         4.0       0.78      0.81      0.79       150\n",
      "         5.0       0.79      0.65      0.71       171\n",
      "         6.0       0.76      0.70      0.73       112\n",
      "         7.0       0.62      0.76      0.68       111\n",
      "\n",
      "    accuracy                           0.67      1051\n",
      "   macro avg       0.65      0.65      0.64      1051\n",
      "weighted avg       0.67      0.67      0.67      1051\n",
      "\n",
      "epoch.  39\n",
      "[TEST RESULT]\n",
      "epoch:39 IZY:-44.20 IZX:1209.03 acc:0.6651 avg_acc:0.0000 err:0.3349 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.69      0.69       113\n",
      "         1.0       0.21      0.15      0.17        75\n",
      "         2.0       0.58      0.76      0.66       154\n",
      "         3.0       0.64      0.57      0.60       165\n",
      "         4.0       0.74      0.81      0.77       150\n",
      "         5.0       0.77      0.65      0.71       171\n",
      "         6.0       0.81      0.74      0.77       112\n",
      "         7.0       0.68      0.75      0.71       111\n",
      "\n",
      "    accuracy                           0.67      1051\n",
      "   macro avg       0.64      0.64      0.64      1051\n",
      "weighted avg       0.66      0.67      0.66      1051\n",
      "\n",
      "epoch.  40\n",
      "[TEST RESULT]\n",
      "epoch:40 IZY:-44.55 IZX:1152.59 acc:0.6698 avg_acc:0.0000 err:0.3302 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.72      0.71       113\n",
      "         1.0       0.23      0.16      0.19        75\n",
      "         2.0       0.59      0.75      0.66       154\n",
      "         3.0       0.63      0.55      0.58       165\n",
      "         4.0       0.77      0.80      0.78       150\n",
      "         5.0       0.72      0.68      0.70       171\n",
      "         6.0       0.78      0.74      0.76       112\n",
      "         7.0       0.70      0.77      0.74       111\n",
      "\n",
      "    accuracy                           0.67      1051\n",
      "   macro avg       0.64      0.65      0.64      1051\n",
      "weighted avg       0.66      0.67      0.66      1051\n",
      "\n",
      "epoch.  41\n",
      "[TEST RESULT]\n",
      "epoch:41 IZY:-43.10 IZX:1159.24 acc:0.6860 avg_acc:0.0000 err:0.3140 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.76      0.72       113\n",
      "         1.0       0.25      0.20      0.22        75\n",
      "         2.0       0.60      0.76      0.67       154\n",
      "         3.0       0.65      0.54      0.59       165\n",
      "         4.0       0.82      0.84      0.83       150\n",
      "         5.0       0.75      0.70      0.73       171\n",
      "         6.0       0.81      0.73      0.77       112\n",
      "         7.0       0.72      0.77      0.75       111\n",
      "\n",
      "    accuracy                           0.69      1051\n",
      "   macro avg       0.66      0.66      0.66      1051\n",
      "weighted avg       0.68      0.69      0.68      1051\n",
      "\n",
      "epoch.  42\n",
      "[TEST RESULT]\n",
      "epoch:42 IZY:-43.79 IZX:1126.65 acc:0.6679 avg_acc:0.0000 err:0.3321 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.69      0.72       113\n",
      "         1.0       0.21      0.17      0.19        75\n",
      "         2.0       0.59      0.73      0.65       154\n",
      "         3.0       0.66      0.58      0.61       165\n",
      "         4.0       0.74      0.81      0.78       150\n",
      "         5.0       0.73      0.66      0.69       171\n",
      "         6.0       0.77      0.73      0.75       112\n",
      "         7.0       0.70      0.78      0.74       111\n",
      "\n",
      "    accuracy                           0.67      1051\n",
      "   macro avg       0.64      0.64      0.64      1051\n",
      "weighted avg       0.66      0.67      0.66      1051\n",
      "\n",
      "epoch.  43\n",
      "[TEST RESULT]\n",
      "epoch:43 IZY:-43.98 IZX:1123.15 acc:0.6908 avg_acc:0.0000 err:0.3092 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.74      0.75       113\n",
      "         1.0       0.28      0.31      0.29        75\n",
      "         2.0       0.63      0.76      0.69       154\n",
      "         3.0       0.67      0.58      0.62       165\n",
      "         4.0       0.78      0.83      0.80       150\n",
      "         5.0       0.79      0.66      0.72       171\n",
      "         6.0       0.83      0.76      0.79       112\n",
      "         7.0       0.67      0.75      0.71       111\n",
      "\n",
      "    accuracy                           0.69      1051\n",
      "   macro avg       0.68      0.67      0.67      1051\n",
      "weighted avg       0.70      0.69      0.69      1051\n",
      "\n",
      "epoch.  44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST RESULT]\n",
      "epoch:44 IZY:-39.59 IZX:1106.02 acc:0.6870 avg_acc:0.0000 err:0.3130 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.69      0.73       113\n",
      "         1.0       0.27      0.27      0.27        75\n",
      "         2.0       0.63      0.73      0.67       154\n",
      "         3.0       0.65      0.61      0.63       165\n",
      "         4.0       0.81      0.86      0.83       150\n",
      "         5.0       0.77      0.68      0.72       171\n",
      "         6.0       0.77      0.74      0.75       112\n",
      "         7.0       0.67      0.76      0.71       111\n",
      "\n",
      "    accuracy                           0.69      1051\n",
      "   macro avg       0.67      0.67      0.66      1051\n",
      "weighted avg       0.69      0.69      0.69      1051\n",
      "\n",
      "epoch.  45\n",
      "[TEST RESULT]\n",
      "epoch:45 IZY:-41.89 IZX:1088.51 acc:0.6936 avg_acc:0.0000 err:0.3064 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.76      0.74       113\n",
      "         1.0       0.30      0.28      0.29        75\n",
      "         2.0       0.59      0.71      0.65       154\n",
      "         3.0       0.70      0.58      0.63       165\n",
      "         4.0       0.78      0.87      0.82       150\n",
      "         5.0       0.77      0.65      0.71       171\n",
      "         6.0       0.79      0.78      0.78       112\n",
      "         7.0       0.73      0.79      0.76       111\n",
      "\n",
      "    accuracy                           0.69      1051\n",
      "   macro avg       0.67      0.68      0.67      1051\n",
      "weighted avg       0.70      0.69      0.69      1051\n",
      "\n",
      "epoch.  46\n",
      "[TEST RESULT]\n",
      "epoch:46 IZY:-40.37 IZX:1106.57 acc:0.6946 avg_acc:0.0000 err:0.3054 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.73      0.77       113\n",
      "         1.0       0.32      0.37      0.34        75\n",
      "         2.0       0.67      0.73      0.70       154\n",
      "         3.0       0.65      0.60      0.62       165\n",
      "         4.0       0.73      0.87      0.80       150\n",
      "         5.0       0.76      0.67      0.71       171\n",
      "         6.0       0.79      0.71      0.75       112\n",
      "         7.0       0.74      0.76      0.75       111\n",
      "\n",
      "    accuracy                           0.69      1051\n",
      "   macro avg       0.69      0.68      0.68      1051\n",
      "weighted avg       0.70      0.69      0.70      1051\n",
      "\n",
      "epoch.  47\n",
      "[TEST RESULT]\n",
      "epoch:47 IZY:-41.78 IZX:1087.06 acc:0.6765 avg_acc:0.0000 err:0.3235 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.71      0.72       113\n",
      "         1.0       0.27      0.27      0.27        75\n",
      "         2.0       0.64      0.69      0.66       154\n",
      "         3.0       0.67      0.61      0.63       165\n",
      "         4.0       0.75      0.85      0.80       150\n",
      "         5.0       0.75      0.67      0.71       171\n",
      "         6.0       0.69      0.72      0.70       112\n",
      "         7.0       0.71      0.75      0.73       111\n",
      "\n",
      "    accuracy                           0.68      1051\n",
      "   macro avg       0.65      0.66      0.65      1051\n",
      "weighted avg       0.68      0.68      0.67      1051\n",
      "\n",
      "epoch.  48\n",
      "[TEST RESULT]\n",
      "epoch:48 IZY:-41.11 IZX:1085.67 acc:0.6851 avg_acc:0.0000 err:0.3149 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.73      0.75       113\n",
      "         1.0       0.30      0.33      0.32        75\n",
      "         2.0       0.66      0.72      0.69       154\n",
      "         3.0       0.62      0.57      0.59       165\n",
      "         4.0       0.80      0.83      0.81       150\n",
      "         5.0       0.71      0.68      0.70       171\n",
      "         6.0       0.78      0.75      0.76       112\n",
      "         7.0       0.73      0.73      0.73       111\n",
      "\n",
      "    accuracy                           0.69      1051\n",
      "   macro avg       0.67      0.67      0.67      1051\n",
      "weighted avg       0.69      0.69      0.69      1051\n",
      "\n",
      "epoch.  49\n",
      "[TEST RESULT]\n",
      "epoch:49 IZY:-41.29 IZX:1103.27 acc:0.6765 avg_acc:0.0000 err:0.3235 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.73      0.71       113\n",
      "         1.0       0.25      0.27      0.26        75\n",
      "         2.0       0.66      0.73      0.69       154\n",
      "         3.0       0.70      0.60      0.64       165\n",
      "         4.0       0.71      0.80      0.75       150\n",
      "         5.0       0.76      0.65      0.70       171\n",
      "         6.0       0.79      0.77      0.78       112\n",
      "         7.0       0.69      0.71      0.70       111\n",
      "\n",
      "    accuracy                           0.68      1051\n",
      "   macro avg       0.66      0.66      0.66      1051\n",
      "weighted avg       0.68      0.68      0.68      1051\n",
      "\n",
      "epoch.  50\n",
      "[TEST RESULT]\n",
      "epoch:50 IZY:-40.31 IZX:1074.65 acc:0.6851 avg_acc:0.0000 err:0.3149 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.73      0.74       113\n",
      "         1.0       0.28      0.27      0.27        75\n",
      "         2.0       0.67      0.71      0.69       154\n",
      "         3.0       0.68      0.59      0.63       165\n",
      "         4.0       0.74      0.85      0.79       150\n",
      "         5.0       0.70      0.68      0.69       171\n",
      "         6.0       0.74      0.77      0.75       112\n",
      "         7.0       0.74      0.73      0.74       111\n",
      "\n",
      "    accuracy                           0.69      1051\n",
      "   macro avg       0.66      0.67      0.66      1051\n",
      "weighted avg       0.68      0.69      0.68      1051\n",
      "\n",
      "epoch.  51\n",
      "[TEST RESULT]\n",
      "epoch:51 IZY:-40.70 IZX:1087.58 acc:0.6955 avg_acc:0.0000 err:0.3045 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.73      0.76       113\n",
      "         1.0       0.37      0.39      0.38        75\n",
      "         2.0       0.66      0.76      0.71       154\n",
      "         3.0       0.66      0.58      0.62       165\n",
      "         4.0       0.75      0.84      0.79       150\n",
      "         5.0       0.75      0.65      0.70       171\n",
      "         6.0       0.73      0.79      0.76       112\n",
      "         7.0       0.74      0.73      0.74       111\n",
      "\n",
      "    accuracy                           0.70      1051\n",
      "   macro avg       0.68      0.68      0.68      1051\n",
      "weighted avg       0.70      0.70      0.69      1051\n",
      "\n",
      "epoch.  52\n",
      "[TEST RESULT]\n",
      "epoch:52 IZY:-40.34 IZX:1061.76 acc:0.6784 avg_acc:0.0000 err:0.3216 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.68      0.70       113\n",
      "         1.0       0.26      0.27      0.26        75\n",
      "         2.0       0.67      0.71      0.69       154\n",
      "         3.0       0.67      0.59      0.63       165\n",
      "         4.0       0.73      0.81      0.77       150\n",
      "         5.0       0.75      0.68      0.71       171\n",
      "         6.0       0.70      0.77      0.74       112\n",
      "         7.0       0.75      0.77      0.76       111\n",
      "\n",
      "    accuracy                           0.68      1051\n",
      "   macro avg       0.66      0.66      0.66      1051\n",
      "weighted avg       0.68      0.68      0.68      1051\n",
      "\n",
      "epoch.  53\n",
      "[TEST RESULT]\n",
      "epoch:53 IZY:-41.01 IZX:1050.82 acc:0.6927 avg_acc:0.0000 err:0.3073 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.74      0.78       113\n",
      "         1.0       0.32      0.37      0.34        75\n",
      "         2.0       0.64      0.68      0.66       154\n",
      "         3.0       0.70      0.62      0.66       165\n",
      "         4.0       0.74      0.84      0.79       150\n",
      "         5.0       0.75      0.67      0.71       171\n",
      "         6.0       0.73      0.78      0.75       112\n",
      "         7.0       0.76      0.73      0.74       111\n",
      "\n",
      "    accuracy                           0.69      1051\n",
      "   macro avg       0.68      0.68      0.68      1051\n",
      "weighted avg       0.70      0.69      0.69      1051\n",
      "\n",
      "epoch.  54\n",
      "[TEST RESULT]\n",
      "epoch:54 IZY:-41.11 IZX:1034.01 acc:0.7127 avg_acc:0.0000 err:0.2873 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.72      0.73       113\n",
      "         1.0       0.35      0.39      0.37        75\n",
      "         2.0       0.74      0.72      0.73       154\n",
      "         3.0       0.72      0.63      0.67       165\n",
      "         4.0       0.74      0.85      0.79       150\n",
      "         5.0       0.74      0.72      0.73       171\n",
      "         6.0       0.77      0.79      0.78       112\n",
      "         7.0       0.76      0.77      0.77       111\n",
      "\n",
      "    accuracy                           0.71      1051\n",
      "   macro avg       0.70      0.70      0.70      1051\n",
      "weighted avg       0.71      0.71      0.71      1051\n",
      "\n",
      "epoch.  55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST RESULT]\n",
      "epoch:55 IZY:-41.47 IZX:1070.58 acc:0.7088 avg_acc:0.0000 err:0.2912 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.73      0.77       113\n",
      "         1.0       0.32      0.39      0.35        75\n",
      "         2.0       0.75      0.74      0.74       154\n",
      "         3.0       0.65      0.56      0.60       165\n",
      "         4.0       0.76      0.86      0.81       150\n",
      "         5.0       0.75      0.68      0.71       171\n",
      "         6.0       0.76      0.84      0.80       112\n",
      "         7.0       0.76      0.80      0.78       111\n",
      "\n",
      "    accuracy                           0.71      1051\n",
      "   macro avg       0.70      0.70      0.70      1051\n",
      "weighted avg       0.71      0.71      0.71      1051\n",
      "\n",
      "epoch.  56\n",
      "[TEST RESULT]\n",
      "epoch:56 IZY:-40.40 IZX:1017.77 acc:0.6946 avg_acc:0.0000 err:0.3054 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.71      0.74       113\n",
      "         1.0       0.29      0.32      0.30        75\n",
      "         2.0       0.64      0.67      0.66       154\n",
      "         3.0       0.66      0.61      0.63       165\n",
      "         4.0       0.73      0.83      0.78       150\n",
      "         5.0       0.81      0.70      0.75       171\n",
      "         6.0       0.76      0.81      0.78       112\n",
      "         7.0       0.78      0.77      0.78       111\n",
      "\n",
      "    accuracy                           0.69      1051\n",
      "   macro avg       0.68      0.68      0.68      1051\n",
      "weighted avg       0.70      0.69      0.70      1051\n",
      "\n",
      "epoch.  57\n",
      "[TEST RESULT]\n",
      "epoch:57 IZY:-40.56 IZX:1037.41 acc:0.6955 avg_acc:0.0000 err:0.3045 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.71      0.74       113\n",
      "         1.0       0.32      0.33      0.32        75\n",
      "         2.0       0.70      0.71      0.71       154\n",
      "         3.0       0.62      0.59      0.61       165\n",
      "         4.0       0.76      0.87      0.81       150\n",
      "         5.0       0.76      0.67      0.71       171\n",
      "         6.0       0.72      0.77      0.74       112\n",
      "         7.0       0.78      0.80      0.79       111\n",
      "\n",
      "    accuracy                           0.70      1051\n",
      "   macro avg       0.68      0.68      0.68      1051\n",
      "weighted avg       0.70      0.70      0.69      1051\n",
      "\n",
      "epoch.  58\n",
      "[TEST RESULT]\n",
      "epoch:58 IZY:-41.35 IZX:1029.08 acc:0.6917 avg_acc:0.0000 err:0.3083 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.73      0.77       113\n",
      "         1.0       0.33      0.35      0.34        75\n",
      "         2.0       0.70      0.73      0.72       154\n",
      "         3.0       0.66      0.59      0.62       165\n",
      "         4.0       0.75      0.85      0.79       150\n",
      "         5.0       0.74      0.65      0.69       171\n",
      "         6.0       0.73      0.76      0.75       112\n",
      "         7.0       0.68      0.77      0.72       111\n",
      "\n",
      "    accuracy                           0.69      1051\n",
      "   macro avg       0.67      0.68      0.67      1051\n",
      "weighted avg       0.69      0.69      0.69      1051\n",
      "\n",
      "epoch.  59\n",
      "[TEST RESULT]\n",
      "epoch:59 IZY:-41.44 IZX:1032.28 acc:0.6860 avg_acc:0.0000 err:0.3140 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.67      0.72       113\n",
      "         1.0       0.29      0.32      0.30        75\n",
      "         2.0       0.71      0.71      0.71       154\n",
      "         3.0       0.66      0.58      0.61       165\n",
      "         4.0       0.72      0.84      0.77       150\n",
      "         5.0       0.72      0.70      0.71       171\n",
      "         6.0       0.70      0.79      0.74       112\n",
      "         7.0       0.79      0.75      0.77       111\n",
      "\n",
      "    accuracy                           0.69      1051\n",
      "   macro avg       0.67      0.67      0.67      1051\n",
      "weighted avg       0.69      0.69      0.69      1051\n",
      "\n",
      "epoch.  60\n",
      "[TEST RESULT]\n",
      "epoch:60 IZY:-39.03 IZX:1021.66 acc:0.7117 avg_acc:0.0000 err:0.2883 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.73      0.76       113\n",
      "         1.0       0.35      0.49      0.41        75\n",
      "         2.0       0.74      0.73      0.73       154\n",
      "         3.0       0.67      0.57      0.62       165\n",
      "         4.0       0.78      0.88      0.82       150\n",
      "         5.0       0.77      0.71      0.74       171\n",
      "         6.0       0.76      0.78      0.77       112\n",
      "         7.0       0.75      0.73      0.74       111\n",
      "\n",
      "    accuracy                           0.71      1051\n",
      "   macro avg       0.70      0.70      0.70      1051\n",
      "weighted avg       0.72      0.71      0.71      1051\n",
      "\n",
      "epoch.  61\n",
      "[TEST RESULT]\n",
      "epoch:61 IZY:-39.39 IZX:1018.51 acc:0.7041 avg_acc:0.0000 err:0.2959 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.76      0.78       113\n",
      "         1.0       0.37      0.47      0.41        75\n",
      "         2.0       0.70      0.75      0.73       154\n",
      "         3.0       0.66      0.55      0.60       165\n",
      "         4.0       0.78      0.84      0.81       150\n",
      "         5.0       0.68      0.65      0.66       171\n",
      "         6.0       0.79      0.78      0.78       112\n",
      "         7.0       0.79      0.80      0.79       111\n",
      "\n",
      "    accuracy                           0.70      1051\n",
      "   macro avg       0.70      0.70      0.70      1051\n",
      "weighted avg       0.71      0.70      0.70      1051\n",
      "\n",
      "epoch.  62\n",
      "[TEST RESULT]\n",
      "epoch:62 IZY:-40.32 IZX:1023.00 acc:0.6927 avg_acc:0.0000 err:0.3073 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.75      0.78       113\n",
      "         1.0       0.35      0.39      0.37        75\n",
      "         2.0       0.70      0.71      0.70       154\n",
      "         3.0       0.66      0.58      0.62       165\n",
      "         4.0       0.75      0.83      0.79       150\n",
      "         5.0       0.72      0.68      0.70       171\n",
      "         6.0       0.72      0.79      0.75       112\n",
      "         7.0       0.70      0.73      0.72       111\n",
      "\n",
      "    accuracy                           0.69      1051\n",
      "   macro avg       0.68      0.68      0.68      1051\n",
      "weighted avg       0.69      0.69      0.69      1051\n",
      "\n",
      "epoch.  63\n",
      "[TEST RESULT]\n",
      "epoch:63 IZY:-39.48 IZX:1017.47 acc:0.7003 avg_acc:0.0000 err:0.2997 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.72      0.72       113\n",
      "         1.0       0.31      0.39      0.34        75\n",
      "         2.0       0.72      0.72      0.72       154\n",
      "         3.0       0.73      0.60      0.66       165\n",
      "         4.0       0.77      0.86      0.81       150\n",
      "         5.0       0.77      0.70      0.73       171\n",
      "         6.0       0.74      0.75      0.74       112\n",
      "         7.0       0.72      0.76      0.74       111\n",
      "\n",
      "    accuracy                           0.70      1051\n",
      "   macro avg       0.68      0.69      0.68      1051\n",
      "weighted avg       0.71      0.70      0.70      1051\n",
      "\n",
      "epoch.  64\n",
      "[TEST RESULT]\n",
      "epoch:64 IZY:-39.66 IZX:1014.52 acc:0.6908 avg_acc:0.0000 err:0.3092 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.70      0.74       113\n",
      "         1.0       0.31      0.43      0.36        75\n",
      "         2.0       0.73      0.67      0.70       154\n",
      "         3.0       0.62      0.56      0.59       165\n",
      "         4.0       0.78      0.85      0.81       150\n",
      "         5.0       0.73      0.72      0.72       171\n",
      "         6.0       0.77      0.76      0.76       112\n",
      "         7.0       0.75      0.75      0.75       111\n",
      "\n",
      "    accuracy                           0.69      1051\n",
      "   macro avg       0.68      0.68      0.68      1051\n",
      "weighted avg       0.70      0.69      0.69      1051\n",
      "\n",
      "epoch.  65\n",
      "[TEST RESULT]\n",
      "epoch:65 IZY:-38.98 IZX:1043.11 acc:0.7108 avg_acc:0.0000 err:0.2892 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.72      0.76       113\n",
      "         1.0       0.37      0.43      0.40        75\n",
      "         2.0       0.71      0.71      0.71       154\n",
      "         3.0       0.68      0.62      0.65       165\n",
      "         4.0       0.78      0.86      0.82       150\n",
      "         5.0       0.75      0.68      0.72       171\n",
      "         6.0       0.74      0.80      0.77       112\n",
      "         7.0       0.74      0.77      0.76       111\n",
      "\n",
      "    accuracy                           0.71      1051\n",
      "   macro avg       0.70      0.70      0.70      1051\n",
      "weighted avg       0.71      0.71      0.71      1051\n",
      "\n",
      "epoch.  66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST RESULT]\n",
      "epoch:66 IZY:-39.30 IZX:1010.82 acc:0.6974 avg_acc:0.0000 err:0.3026 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.73      0.73       113\n",
      "         1.0       0.31      0.32      0.31        75\n",
      "         2.0       0.73      0.73      0.73       154\n",
      "         3.0       0.66      0.58      0.61       165\n",
      "         4.0       0.77      0.85      0.81       150\n",
      "         5.0       0.73      0.70      0.71       171\n",
      "         6.0       0.77      0.77      0.77       112\n",
      "         7.0       0.71      0.77      0.74       111\n",
      "\n",
      "    accuracy                           0.70      1051\n",
      "   macro avg       0.68      0.68      0.68      1051\n",
      "weighted avg       0.70      0.70      0.70      1051\n",
      "\n",
      "epoch.  67\n",
      "[TEST RESULT]\n",
      "epoch:67 IZY:-37.58 IZX:991.96 acc:0.6965 avg_acc:0.0000 err:0.3035 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.72      0.73       113\n",
      "         1.0       0.32      0.41      0.36        75\n",
      "         2.0       0.76      0.68      0.72       154\n",
      "         3.0       0.69      0.56      0.62       165\n",
      "         4.0       0.75      0.87      0.81       150\n",
      "         5.0       0.71      0.68      0.69       171\n",
      "         6.0       0.78      0.79      0.79       112\n",
      "         7.0       0.73      0.78      0.76       111\n",
      "\n",
      "    accuracy                           0.70      1051\n",
      "   macro avg       0.68      0.69      0.68      1051\n",
      "weighted avg       0.70      0.70      0.70      1051\n",
      "\n",
      "epoch.  68\n",
      "[TEST RESULT]\n",
      "epoch:68 IZY:-38.61 IZX:993.09 acc:0.7012 avg_acc:0.0000 err:0.2988 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.72      0.76       113\n",
      "         1.0       0.35      0.44      0.39        75\n",
      "         2.0       0.75      0.69      0.72       154\n",
      "         3.0       0.68      0.60      0.64       165\n",
      "         4.0       0.74      0.83      0.79       150\n",
      "         5.0       0.74      0.68      0.71       171\n",
      "         6.0       0.71      0.79      0.75       112\n",
      "         7.0       0.75      0.80      0.77       111\n",
      "\n",
      "    accuracy                           0.70      1051\n",
      "   macro avg       0.69      0.69      0.69      1051\n",
      "weighted avg       0.71      0.70      0.70      1051\n",
      "\n",
      "epoch.  69\n",
      "[TEST RESULT]\n",
      "epoch:69 IZY:-37.41 IZX:995.59 acc:0.7174 avg_acc:0.0000 err:0.2826 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.71      0.74       113\n",
      "         1.0       0.40      0.53      0.45        75\n",
      "         2.0       0.75      0.73      0.74       154\n",
      "         3.0       0.69      0.61      0.65       165\n",
      "         4.0       0.76      0.87      0.81       150\n",
      "         5.0       0.77      0.73      0.75       171\n",
      "         6.0       0.73      0.76      0.75       112\n",
      "         7.0       0.78      0.75      0.76       111\n",
      "\n",
      "    accuracy                           0.72      1051\n",
      "   macro avg       0.71      0.71      0.71      1051\n",
      "weighted avg       0.73      0.72      0.72      1051\n",
      "\n",
      "epoch.  70\n",
      "[TEST RESULT]\n",
      "epoch:70 IZY:-39.22 IZX:984.77 acc:0.7060 avg_acc:0.0000 err:0.2940 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.74      0.78       113\n",
      "         1.0       0.35      0.41      0.38        75\n",
      "         2.0       0.72      0.70      0.71       154\n",
      "         3.0       0.65      0.61      0.63       165\n",
      "         4.0       0.73      0.85      0.79       150\n",
      "         5.0       0.77      0.68      0.72       171\n",
      "         6.0       0.74      0.78      0.76       112\n",
      "         7.0       0.78      0.78      0.78       111\n",
      "\n",
      "    accuracy                           0.71      1051\n",
      "   macro avg       0.70      0.70      0.69      1051\n",
      "weighted avg       0.71      0.71      0.71      1051\n",
      "\n",
      "epoch.  71\n",
      "[TEST RESULT]\n",
      "epoch:71 IZY:-38.60 IZX:970.86 acc:0.7079 avg_acc:0.0000 err:0.2921 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.73      0.76       113\n",
      "         1.0       0.32      0.40      0.35        75\n",
      "         2.0       0.73      0.69      0.71       154\n",
      "         3.0       0.67      0.61      0.63       165\n",
      "         4.0       0.73      0.84      0.78       150\n",
      "         5.0       0.76      0.68      0.72       171\n",
      "         6.0       0.79      0.82      0.80       112\n",
      "         7.0       0.79      0.80      0.80       111\n",
      "\n",
      "    accuracy                           0.71      1051\n",
      "   macro avg       0.70      0.70      0.70      1051\n",
      "weighted avg       0.72      0.71      0.71      1051\n",
      "\n",
      "epoch.  72\n",
      "[TEST RESULT]\n",
      "epoch:72 IZY:-39.51 IZX:970.76 acc:0.7136 avg_acc:0.0000 err:0.2864 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.75      0.79       113\n",
      "         1.0       0.38      0.47      0.42        75\n",
      "         2.0       0.76      0.71      0.73       154\n",
      "         3.0       0.66      0.65      0.65       165\n",
      "         4.0       0.76      0.85      0.81       150\n",
      "         5.0       0.78      0.71      0.74       171\n",
      "         6.0       0.75      0.73      0.74       112\n",
      "         7.0       0.70      0.75      0.72       111\n",
      "\n",
      "    accuracy                           0.71      1051\n",
      "   macro avg       0.70      0.70      0.70      1051\n",
      "weighted avg       0.72      0.71      0.72      1051\n",
      "\n",
      "epoch.  73\n",
      "[TEST RESULT]\n",
      "epoch:73 IZY:-37.58 IZX:980.15 acc:0.7117 avg_acc:0.0000 err:0.2883 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.75      0.79       113\n",
      "         1.0       0.31      0.40      0.35        75\n",
      "         2.0       0.73      0.71      0.72       154\n",
      "         3.0       0.66      0.63      0.64       165\n",
      "         4.0       0.73      0.85      0.78       150\n",
      "         5.0       0.79      0.70      0.74       171\n",
      "         6.0       0.77      0.79      0.78       112\n",
      "         7.0       0.79      0.77      0.78       111\n",
      "\n",
      "    accuracy                           0.71      1051\n",
      "   macro avg       0.70      0.70      0.70      1051\n",
      "weighted avg       0.72      0.71      0.72      1051\n",
      "\n",
      "epoch.  74\n",
      "[TEST RESULT]\n",
      "epoch:74 IZY:-38.23 IZX:984.97 acc:0.7146 avg_acc:0.0000 err:0.2854 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.72      0.78       113\n",
      "         1.0       0.33      0.44      0.38        75\n",
      "         2.0       0.78      0.68      0.72       154\n",
      "         3.0       0.64      0.64      0.64       165\n",
      "         4.0       0.78      0.86      0.82       150\n",
      "         5.0       0.75      0.72      0.73       171\n",
      "         6.0       0.77      0.79      0.78       112\n",
      "         7.0       0.75      0.78      0.77       111\n",
      "\n",
      "    accuracy                           0.71      1051\n",
      "   macro avg       0.71      0.70      0.70      1051\n",
      "weighted avg       0.73      0.71      0.72      1051\n",
      "\n",
      "epoch.  75\n",
      "[TEST RESULT]\n",
      "epoch:75 IZY:-39.03 IZX:946.35 acc:0.7031 avg_acc:0.0000 err:0.2969 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.73      0.75       113\n",
      "         1.0       0.32      0.36      0.34        75\n",
      "         2.0       0.73      0.73      0.73       154\n",
      "         3.0       0.66      0.60      0.63       165\n",
      "         4.0       0.72      0.85      0.78       150\n",
      "         5.0       0.77      0.69      0.73       171\n",
      "         6.0       0.76      0.78      0.77       112\n",
      "         7.0       0.75      0.77      0.76       111\n",
      "\n",
      "    accuracy                           0.70      1051\n",
      "   macro avg       0.69      0.69      0.69      1051\n",
      "weighted avg       0.71      0.70      0.70      1051\n",
      "\n",
      "epoch.  76\n",
      "[TEST RESULT]\n",
      "epoch:76 IZY:-37.39 IZX:970.15 acc:0.7212 avg_acc:0.0000 err:0.2788 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.71      0.76       113\n",
      "         1.0       0.37      0.45      0.40        75\n",
      "         2.0       0.76      0.75      0.76       154\n",
      "         3.0       0.65      0.62      0.64       165\n",
      "         4.0       0.77      0.83      0.80       150\n",
      "         5.0       0.78      0.73      0.75       171\n",
      "         6.0       0.75      0.82      0.79       112\n",
      "         7.0       0.79      0.76      0.77       111\n",
      "\n",
      "    accuracy                           0.72      1051\n",
      "   macro avg       0.71      0.71      0.71      1051\n",
      "weighted avg       0.73      0.72      0.72      1051\n",
      "\n",
      "epoch.  77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST RESULT]\n",
      "epoch:77 IZY:-36.52 IZX:976.40 acc:0.7050 avg_acc:0.0000 err:0.2950 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.71      0.74       113\n",
      "         1.0       0.38      0.51      0.43        75\n",
      "         2.0       0.74      0.71      0.72       154\n",
      "         3.0       0.62      0.55      0.58       165\n",
      "         4.0       0.75      0.84      0.79       150\n",
      "         5.0       0.76      0.71      0.73       171\n",
      "         6.0       0.76      0.78      0.77       112\n",
      "         7.0       0.80      0.80      0.80       111\n",
      "\n",
      "    accuracy                           0.71      1051\n",
      "   macro avg       0.70      0.70      0.70      1051\n",
      "weighted avg       0.71      0.71      0.71      1051\n",
      "\n",
      "epoch.  78\n",
      "[TEST RESULT]\n",
      "epoch:78 IZY:-36.47 IZX:971.21 acc:0.7260 avg_acc:0.0000 err:0.2740 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.74      0.79       113\n",
      "         1.0       0.35      0.47      0.40        75\n",
      "         2.0       0.77      0.71      0.74       154\n",
      "         3.0       0.67      0.65      0.66       165\n",
      "         4.0       0.75      0.83      0.79       150\n",
      "         5.0       0.79      0.73      0.76       171\n",
      "         6.0       0.80      0.80      0.80       112\n",
      "         7.0       0.77      0.80      0.78       111\n",
      "\n",
      "    accuracy                           0.73      1051\n",
      "   macro avg       0.72      0.72      0.72      1051\n",
      "weighted avg       0.74      0.73      0.73      1051\n",
      "\n",
      "epoch.  79\n",
      "[TEST RESULT]\n",
      "epoch:79 IZY:-37.91 IZX:959.92 acc:0.7307 avg_acc:0.0000 err:0.2693 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.71      0.78       113\n",
      "         1.0       0.35      0.45      0.39        75\n",
      "         2.0       0.77      0.73      0.75       154\n",
      "         3.0       0.68      0.65      0.66       165\n",
      "         4.0       0.81      0.87      0.84       150\n",
      "         5.0       0.79      0.73      0.76       171\n",
      "         6.0       0.76      0.84      0.80       112\n",
      "         7.0       0.75      0.77      0.76       111\n",
      "\n",
      "    accuracy                           0.73      1051\n",
      "   macro avg       0.72      0.72      0.72      1051\n",
      "weighted avg       0.74      0.73      0.73      1051\n",
      "\n",
      "epoch.  80\n",
      "[TEST RESULT]\n",
      "epoch:80 IZY:-36.58 IZX:963.31 acc:0.7269 avg_acc:0.0000 err:0.2731 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.73      0.77       113\n",
      "         1.0       0.37      0.48      0.42        75\n",
      "         2.0       0.76      0.71      0.73       154\n",
      "         3.0       0.68      0.64      0.66       165\n",
      "         4.0       0.78      0.87      0.82       150\n",
      "         5.0       0.78      0.72      0.75       171\n",
      "         6.0       0.74      0.79      0.76       112\n",
      "         7.0       0.81      0.79      0.80       111\n",
      "\n",
      "    accuracy                           0.73      1051\n",
      "   macro avg       0.72      0.72      0.72      1051\n",
      "weighted avg       0.74      0.73      0.73      1051\n",
      "\n",
      "epoch.  81\n",
      "[TEST RESULT]\n",
      "epoch:81 IZY:-38.09 IZX:949.95 acc:0.7203 avg_acc:0.0000 err:0.2797 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.73      0.78       113\n",
      "         1.0       0.38      0.53      0.44        75\n",
      "         2.0       0.79      0.71      0.75       154\n",
      "         3.0       0.68      0.59      0.63       165\n",
      "         4.0       0.78      0.85      0.81       150\n",
      "         5.0       0.74      0.75      0.75       171\n",
      "         6.0       0.74      0.79      0.77       112\n",
      "         7.0       0.77      0.73      0.75       111\n",
      "\n",
      "    accuracy                           0.72      1051\n",
      "   macro avg       0.72      0.71      0.71      1051\n",
      "weighted avg       0.73      0.72      0.72      1051\n",
      "\n",
      "epoch.  82\n",
      "[TEST RESULT]\n",
      "epoch:82 IZY:-37.06 IZX:971.15 acc:0.7146 avg_acc:0.0000 err:0.2854 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.73      0.78       113\n",
      "         1.0       0.34      0.45      0.39        75\n",
      "         2.0       0.77      0.69      0.73       154\n",
      "         3.0       0.64      0.61      0.63       165\n",
      "         4.0       0.73      0.85      0.78       150\n",
      "         5.0       0.77      0.71      0.74       171\n",
      "         6.0       0.81      0.81      0.81       112\n",
      "         7.0       0.78      0.78      0.78       111\n",
      "\n",
      "    accuracy                           0.71      1051\n",
      "   macro avg       0.71      0.71      0.71      1051\n",
      "weighted avg       0.73      0.71      0.72      1051\n",
      "\n",
      "epoch.  83\n",
      "[TEST RESULT]\n",
      "epoch:83 IZY:-38.24 IZX:926.29 acc:0.7174 avg_acc:0.0000 err:0.2826 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.73      0.75       113\n",
      "         1.0       0.41      0.45      0.43        75\n",
      "         2.0       0.75      0.73      0.74       154\n",
      "         3.0       0.61      0.59      0.60       165\n",
      "         4.0       0.78      0.85      0.81       150\n",
      "         5.0       0.78      0.71      0.75       171\n",
      "         6.0       0.75      0.82      0.79       112\n",
      "         7.0       0.78      0.77      0.77       111\n",
      "\n",
      "    accuracy                           0.72      1051\n",
      "   macro avg       0.71      0.71      0.71      1051\n",
      "weighted avg       0.72      0.72      0.72      1051\n",
      "\n",
      "epoch.  84\n",
      "[TEST RESULT]\n",
      "epoch:84 IZY:-37.44 IZX:938.97 acc:0.7193 avg_acc:0.0000 err:0.2807 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.72      0.78       113\n",
      "         1.0       0.38      0.48      0.42        75\n",
      "         2.0       0.76      0.71      0.74       154\n",
      "         3.0       0.66      0.61      0.63       165\n",
      "         4.0       0.77      0.87      0.82       150\n",
      "         5.0       0.74      0.72      0.73       171\n",
      "         6.0       0.77      0.79      0.78       112\n",
      "         7.0       0.75      0.78      0.77       111\n",
      "\n",
      "    accuracy                           0.72      1051\n",
      "   macro avg       0.71      0.71      0.71      1051\n",
      "weighted avg       0.73      0.72      0.72      1051\n",
      "\n",
      "epoch.  85\n",
      "[TEST RESULT]\n",
      "epoch:85 IZY:-37.04 IZX:954.38 acc:0.7146 avg_acc:0.0000 err:0.2854 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.72      0.76       113\n",
      "         1.0       0.42      0.56      0.48        75\n",
      "         2.0       0.80      0.71      0.75       154\n",
      "         3.0       0.66      0.59      0.62       165\n",
      "         4.0       0.78      0.86      0.82       150\n",
      "         5.0       0.72      0.70      0.71       171\n",
      "         6.0       0.71      0.77      0.74       112\n",
      "         7.0       0.75      0.77      0.76       111\n",
      "\n",
      "    accuracy                           0.71      1051\n",
      "   macro avg       0.71      0.71      0.71      1051\n",
      "weighted avg       0.72      0.71      0.72      1051\n",
      "\n",
      "epoch.  86\n",
      "[TEST RESULT]\n",
      "epoch:86 IZY:-36.60 IZX:937.01 acc:0.7174 avg_acc:0.0000 err:0.2826 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.72      0.76       113\n",
      "         1.0       0.35      0.48      0.41        75\n",
      "         2.0       0.74      0.73      0.73       154\n",
      "         3.0       0.69      0.62      0.65       165\n",
      "         4.0       0.77      0.88      0.82       150\n",
      "         5.0       0.79      0.69      0.74       171\n",
      "         6.0       0.75      0.78      0.76       112\n",
      "         7.0       0.76      0.77      0.77       111\n",
      "\n",
      "    accuracy                           0.72      1051\n",
      "   macro avg       0.71      0.71      0.71      1051\n",
      "weighted avg       0.73      0.72      0.72      1051\n",
      "\n",
      "epoch.  87\n",
      "[TEST RESULT]\n",
      "epoch:87 IZY:-37.12 IZX:965.23 acc:0.7136 avg_acc:0.0000 err:0.2864 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.73      0.78       113\n",
      "         1.0       0.39      0.53      0.45        75\n",
      "         2.0       0.75      0.71      0.73       154\n",
      "         3.0       0.66      0.56      0.61       165\n",
      "         4.0       0.77      0.85      0.81       150\n",
      "         5.0       0.79      0.72      0.75       171\n",
      "         6.0       0.72      0.80      0.76       112\n",
      "         7.0       0.72      0.77      0.75       111\n",
      "\n",
      "    accuracy                           0.71      1051\n",
      "   macro avg       0.71      0.71      0.70      1051\n",
      "weighted avg       0.72      0.71      0.72      1051\n",
      "\n",
      "epoch.  88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST RESULT]\n",
      "epoch:88 IZY:-37.83 IZX:943.27 acc:0.7165 avg_acc:0.0000 err:0.2835 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.73      0.77       113\n",
      "         1.0       0.36      0.51      0.42        75\n",
      "         2.0       0.74      0.69      0.71       154\n",
      "         3.0       0.67      0.58      0.62       165\n",
      "         4.0       0.80      0.86      0.83       150\n",
      "         5.0       0.78      0.72      0.75       171\n",
      "         6.0       0.72      0.84      0.77       112\n",
      "         7.0       0.78      0.77      0.77       111\n",
      "\n",
      "    accuracy                           0.72      1051\n",
      "   macro avg       0.71      0.71      0.71      1051\n",
      "weighted avg       0.73      0.72      0.72      1051\n",
      "\n",
      "epoch.  89\n",
      "[TEST RESULT]\n",
      "epoch:89 IZY:-35.55 IZX:924.40 acc:0.7203 avg_acc:0.0000 err:0.2797 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.72      0.77       113\n",
      "         1.0       0.40      0.52      0.45        75\n",
      "         2.0       0.77      0.70      0.73       154\n",
      "         3.0       0.66      0.59      0.62       165\n",
      "         4.0       0.77      0.85      0.81       150\n",
      "         5.0       0.76      0.72      0.74       171\n",
      "         6.0       0.74      0.79      0.76       112\n",
      "         7.0       0.76      0.83      0.79       111\n",
      "\n",
      "    accuracy                           0.72      1051\n",
      "   macro avg       0.71      0.71      0.71      1051\n",
      "weighted avg       0.73      0.72      0.72      1051\n",
      "\n",
      "epoch.  90\n",
      "[TEST RESULT]\n",
      "epoch:90 IZY:-36.44 IZX:923.11 acc:0.7355 avg_acc:0.0000 err:0.2645 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.76      0.81       113\n",
      "         1.0       0.35      0.52      0.42        75\n",
      "         2.0       0.80      0.71      0.75       154\n",
      "         3.0       0.68      0.62      0.65       165\n",
      "         4.0       0.76      0.87      0.81       150\n",
      "         5.0       0.82      0.73      0.77       171\n",
      "         6.0       0.78      0.82      0.80       112\n",
      "         7.0       0.80      0.82      0.81       111\n",
      "\n",
      "    accuracy                           0.74      1051\n",
      "   macro avg       0.73      0.73      0.73      1051\n",
      "weighted avg       0.75      0.74      0.74      1051\n",
      "\n",
      "epoch.  91\n",
      "[TEST RESULT]\n",
      "epoch:91 IZY:-36.92 IZX:922.05 acc:0.7165 avg_acc:0.0000 err:0.2835 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.73      0.78       113\n",
      "         1.0       0.37      0.53      0.44        75\n",
      "         2.0       0.78      0.71      0.75       154\n",
      "         3.0       0.65      0.59      0.62       165\n",
      "         4.0       0.76      0.85      0.81       150\n",
      "         5.0       0.74      0.69      0.72       171\n",
      "         6.0       0.76      0.80      0.78       112\n",
      "         7.0       0.82      0.78      0.80       111\n",
      "\n",
      "    accuracy                           0.72      1051\n",
      "   macro avg       0.71      0.71      0.71      1051\n",
      "weighted avg       0.73      0.72      0.72      1051\n",
      "\n",
      "epoch.  92\n",
      "[TEST RESULT]\n",
      "epoch:92 IZY:-35.30 IZX:921.34 acc:0.7279 avg_acc:0.0000 err:0.2721 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.72      0.78       113\n",
      "         1.0       0.39      0.51      0.44        75\n",
      "         2.0       0.79      0.73      0.76       154\n",
      "         3.0       0.63      0.62      0.63       165\n",
      "         4.0       0.77      0.86      0.81       150\n",
      "         5.0       0.78      0.73      0.76       171\n",
      "         6.0       0.78      0.82      0.80       112\n",
      "         7.0       0.79      0.77      0.78       111\n",
      "\n",
      "    accuracy                           0.73      1051\n",
      "   macro avg       0.72      0.72      0.72      1051\n",
      "weighted avg       0.74      0.73      0.73      1051\n",
      "\n",
      "epoch.  93\n",
      "[TEST RESULT]\n",
      "epoch:93 IZY:-37.00 IZX:927.99 acc:0.7260 avg_acc:0.0000 err:0.2740 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.73      0.77       113\n",
      "         1.0       0.34      0.44      0.38        75\n",
      "         2.0       0.78      0.74      0.76       154\n",
      "         3.0       0.68      0.61      0.65       165\n",
      "         4.0       0.78      0.85      0.81       150\n",
      "         5.0       0.77      0.73      0.75       171\n",
      "         6.0       0.77      0.86      0.81       112\n",
      "         7.0       0.79      0.77      0.78       111\n",
      "\n",
      "    accuracy                           0.73      1051\n",
      "   macro avg       0.71      0.71      0.71      1051\n",
      "weighted avg       0.73      0.73      0.73      1051\n",
      "\n",
      "epoch.  94\n",
      "[TEST RESULT]\n",
      "epoch:94 IZY:-35.91 IZX:929.50 acc:0.7203 avg_acc:0.0000 err:0.2797 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.71      0.77       113\n",
      "         1.0       0.34      0.48      0.40        75\n",
      "         2.0       0.77      0.71      0.74       154\n",
      "         3.0       0.70      0.62      0.66       165\n",
      "         4.0       0.77      0.86      0.81       150\n",
      "         5.0       0.77      0.74      0.75       171\n",
      "         6.0       0.75      0.82      0.79       112\n",
      "         7.0       0.76      0.75      0.75       111\n",
      "\n",
      "    accuracy                           0.72      1051\n",
      "   macro avg       0.71      0.71      0.71      1051\n",
      "weighted avg       0.73      0.72      0.72      1051\n",
      "\n",
      "epoch.  95\n",
      "[TEST RESULT]\n",
      "epoch:95 IZY:-34.84 IZX:905.77 acc:0.7222 avg_acc:0.0000 err:0.2778 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.73      0.79       113\n",
      "         1.0       0.37      0.49      0.42        75\n",
      "         2.0       0.76      0.72      0.74       154\n",
      "         3.0       0.70      0.59      0.64       165\n",
      "         4.0       0.79      0.87      0.83       150\n",
      "         5.0       0.73      0.71      0.72       171\n",
      "         6.0       0.79      0.80      0.80       112\n",
      "         7.0       0.73      0.79      0.76       111\n",
      "\n",
      "    accuracy                           0.72      1051\n",
      "   macro avg       0.71      0.71      0.71      1051\n",
      "weighted avg       0.73      0.72      0.72      1051\n",
      "\n",
      "epoch.  96\n",
      "[TEST RESULT]\n",
      "epoch:96 IZY:-35.64 IZX:916.46 acc:0.7260 avg_acc:0.0000 err:0.2740 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.73      0.78       113\n",
      "         1.0       0.40      0.52      0.45        75\n",
      "         2.0       0.78      0.73      0.75       154\n",
      "         3.0       0.65      0.62      0.63       165\n",
      "         4.0       0.75      0.86      0.80       150\n",
      "         5.0       0.79      0.71      0.75       171\n",
      "         6.0       0.78      0.80      0.79       112\n",
      "         7.0       0.78      0.78      0.78       111\n",
      "\n",
      "    accuracy                           0.73      1051\n",
      "   macro avg       0.72      0.72      0.72      1051\n",
      "weighted avg       0.73      0.73      0.73      1051\n",
      "\n",
      "epoch.  97\n",
      "[TEST RESULT]\n",
      "epoch:97 IZY:-37.55 IZX:920.82 acc:0.7174 avg_acc:0.0000 err:0.2826 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.72      0.77       113\n",
      "         1.0       0.37      0.51      0.42        75\n",
      "         2.0       0.80      0.72      0.76       154\n",
      "         3.0       0.63      0.58      0.61       165\n",
      "         4.0       0.77      0.87      0.82       150\n",
      "         5.0       0.77      0.70      0.73       171\n",
      "         6.0       0.75      0.81      0.78       112\n",
      "         7.0       0.77      0.78      0.78       111\n",
      "\n",
      "    accuracy                           0.72      1051\n",
      "   macro avg       0.71      0.71      0.71      1051\n",
      "weighted avg       0.73      0.72      0.72      1051\n",
      "\n",
      "epoch.  98\n",
      "[TEST RESULT]\n",
      "epoch:98 IZY:-35.57 IZX:893.44 acc:0.7222 avg_acc:0.0000 err:0.2778 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.73      0.77       113\n",
      "         1.0       0.37      0.48      0.42        75\n",
      "         2.0       0.78      0.72      0.75       154\n",
      "         3.0       0.67      0.63      0.65       165\n",
      "         4.0       0.77      0.85      0.81       150\n",
      "         5.0       0.80      0.70      0.74       171\n",
      "         6.0       0.74      0.80      0.77       112\n",
      "         7.0       0.74      0.80      0.77       111\n",
      "\n",
      "    accuracy                           0.72      1051\n",
      "   macro avg       0.71      0.71      0.71      1051\n",
      "weighted avg       0.73      0.72      0.72      1051\n",
      "\n",
      "epoch.  99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST RESULT]\n",
      "epoch:99 IZY:-34.48 IZX:911.68 acc:0.7298 avg_acc:0.0000 err:0.2702 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.73      0.80       113\n",
      "         1.0       0.36      0.51      0.42        75\n",
      "         2.0       0.82      0.73      0.78       154\n",
      "         3.0       0.65      0.61      0.63       165\n",
      "         4.0       0.80      0.87      0.83       150\n",
      "         5.0       0.77      0.74      0.75       171\n",
      "         6.0       0.77      0.80      0.79       112\n",
      "         7.0       0.74      0.77      0.76       111\n",
      "\n",
      "    accuracy                           0.73      1051\n",
      "   macro avg       0.72      0.72      0.72      1051\n",
      "weighted avg       0.74      0.73      0.73      1051\n",
      "\n",
      "epoch.  100\n",
      "[TEST RESULT]\n",
      "epoch:100 IZY:-35.02 IZX:905.00 acc:0.7184 avg_acc:0.0000 err:0.2816 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.73      0.79       113\n",
      "         1.0       0.39      0.45      0.42        75\n",
      "         2.0       0.76      0.75      0.75       154\n",
      "         3.0       0.60      0.58      0.59       165\n",
      "         4.0       0.80      0.86      0.83       150\n",
      "         5.0       0.74      0.70      0.72       171\n",
      "         6.0       0.75      0.85      0.80       112\n",
      "         7.0       0.78      0.77      0.77       111\n",
      "\n",
      "    accuracy                           0.72      1051\n",
      "   macro avg       0.71      0.71      0.71      1051\n",
      "weighted avg       0.72      0.72      0.72      1051\n",
      "\n",
      "epoch.  101\n",
      "[TEST RESULT]\n",
      "epoch:101 IZY:-34.45 IZX:904.62 acc:0.7269 avg_acc:0.0000 err:0.2731 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.73      0.79       113\n",
      "         1.0       0.38      0.59      0.46        75\n",
      "         2.0       0.79      0.73      0.76       154\n",
      "         3.0       0.70      0.58      0.63       165\n",
      "         4.0       0.77      0.85      0.81       150\n",
      "         5.0       0.77      0.73      0.75       171\n",
      "         6.0       0.75      0.82      0.79       112\n",
      "         7.0       0.77      0.77      0.77       111\n",
      "\n",
      "    accuracy                           0.73      1051\n",
      "   macro avg       0.72      0.72      0.72      1051\n",
      "weighted avg       0.74      0.73      0.73      1051\n",
      "\n",
      "epoch.  102\n",
      "[TEST RESULT]\n",
      "epoch:102 IZY:-33.95 IZX:892.91 acc:0.7307 avg_acc:0.0000 err:0.2693 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.72      0.78       113\n",
      "         1.0       0.40      0.56      0.46        75\n",
      "         2.0       0.84      0.75      0.79       154\n",
      "         3.0       0.64      0.60      0.62       165\n",
      "         4.0       0.80      0.87      0.84       150\n",
      "         5.0       0.78      0.74      0.76       171\n",
      "         6.0       0.76      0.80      0.78       112\n",
      "         7.0       0.73      0.75      0.74       111\n",
      "\n",
      "    accuracy                           0.73      1051\n",
      "   macro avg       0.72      0.72      0.72      1051\n",
      "weighted avg       0.74      0.73      0.73      1051\n",
      "\n",
      "epoch.  103\n",
      "[TEST RESULT]\n",
      "epoch:103 IZY:-33.98 IZX:909.50 acc:0.7317 avg_acc:0.0000 err:0.2683 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.73      0.79       113\n",
      "         1.0       0.46      0.60      0.52        75\n",
      "         2.0       0.79      0.73      0.76       154\n",
      "         3.0       0.66      0.61      0.63       165\n",
      "         4.0       0.76      0.83      0.79       150\n",
      "         5.0       0.76      0.74      0.75       171\n",
      "         6.0       0.75      0.79      0.77       112\n",
      "         7.0       0.79      0.80      0.79       111\n",
      "\n",
      "    accuracy                           0.73      1051\n",
      "   macro avg       0.73      0.73      0.73      1051\n",
      "weighted avg       0.74      0.73      0.73      1051\n",
      "\n",
      "epoch.  104\n",
      "[TEST RESULT]\n",
      "epoch:104 IZY:-33.70 IZX:891.50 acc:0.7412 avg_acc:0.0000 err:0.2588 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.75      0.79       113\n",
      "         1.0       0.42      0.55      0.47        75\n",
      "         2.0       0.82      0.73      0.77       154\n",
      "         3.0       0.71      0.62      0.66       165\n",
      "         4.0       0.77      0.89      0.82       150\n",
      "         5.0       0.78      0.71      0.75       171\n",
      "         6.0       0.76      0.83      0.79       112\n",
      "         7.0       0.78      0.80      0.79       111\n",
      "\n",
      "    accuracy                           0.74      1051\n",
      "   macro avg       0.73      0.74      0.73      1051\n",
      "weighted avg       0.75      0.74      0.74      1051\n",
      "\n",
      "epoch.  105\n",
      "[TEST RESULT]\n",
      "epoch:105 IZY:-35.15 IZX:907.12 acc:0.7279 avg_acc:0.0000 err:0.2721 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.73      0.79       113\n",
      "         1.0       0.40      0.52      0.45        75\n",
      "         2.0       0.82      0.73      0.77       154\n",
      "         3.0       0.64      0.61      0.62       165\n",
      "         4.0       0.80      0.86      0.83       150\n",
      "         5.0       0.76      0.74      0.75       171\n",
      "         6.0       0.71      0.82      0.76       112\n",
      "         7.0       0.79      0.76      0.77       111\n",
      "\n",
      "    accuracy                           0.73      1051\n",
      "   macro avg       0.72      0.72      0.72      1051\n",
      "weighted avg       0.74      0.73      0.73      1051\n",
      "\n",
      "epoch.  106\n",
      "[TEST RESULT]\n",
      "epoch:106 IZY:-34.19 IZX:906.94 acc:0.7383 avg_acc:0.0000 err:0.2617 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.74      0.80       113\n",
      "         1.0       0.41      0.59      0.48        75\n",
      "         2.0       0.81      0.73      0.77       154\n",
      "         3.0       0.66      0.61      0.64       165\n",
      "         4.0       0.82      0.86      0.84       150\n",
      "         5.0       0.75      0.75      0.75       171\n",
      "         6.0       0.78      0.79      0.78       112\n",
      "         7.0       0.79      0.79      0.79       111\n",
      "\n",
      "    accuracy                           0.74      1051\n",
      "   macro avg       0.73      0.73      0.73      1051\n",
      "weighted avg       0.75      0.74      0.74      1051\n",
      "\n",
      "epoch.  107\n",
      "[TEST RESULT]\n",
      "epoch:107 IZY:-34.35 IZX:909.75 acc:0.7193 avg_acc:0.0000 err:0.2807 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.73      0.77       113\n",
      "         1.0       0.42      0.56      0.48        75\n",
      "         2.0       0.82      0.69      0.75       154\n",
      "         3.0       0.62      0.61      0.62       165\n",
      "         4.0       0.77      0.83      0.79       150\n",
      "         5.0       0.75      0.70      0.73       171\n",
      "         6.0       0.74      0.83      0.78       112\n",
      "         7.0       0.77      0.80      0.79       111\n",
      "\n",
      "    accuracy                           0.72      1051\n",
      "   macro avg       0.72      0.72      0.71      1051\n",
      "weighted avg       0.73      0.72      0.72      1051\n",
      "\n",
      "epoch.  108\n",
      "[TEST RESULT]\n",
      "epoch:108 IZY:-35.48 IZX:894.96 acc:0.7298 avg_acc:0.0000 err:0.2702 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.73      0.79       113\n",
      "         1.0       0.37      0.51      0.42        75\n",
      "         2.0       0.81      0.70      0.75       154\n",
      "         3.0       0.65      0.62      0.64       165\n",
      "         4.0       0.82      0.86      0.84       150\n",
      "         5.0       0.76      0.74      0.75       171\n",
      "         6.0       0.74      0.79      0.76       112\n",
      "         7.0       0.79      0.81      0.80       111\n",
      "\n",
      "    accuracy                           0.73      1051\n",
      "   macro avg       0.72      0.72      0.72      1051\n",
      "weighted avg       0.74      0.73      0.73      1051\n",
      "\n",
      "epoch.  109\n",
      "[TEST RESULT]\n",
      "epoch:109 IZY:-35.80 IZX:908.87 acc:0.7260 avg_acc:0.0000 err:0.2740 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.75      0.81       113\n",
      "         1.0       0.38      0.48      0.42        75\n",
      "         2.0       0.78      0.70      0.74       154\n",
      "         3.0       0.69      0.62      0.65       165\n",
      "         4.0       0.81      0.87      0.84       150\n",
      "         5.0       0.78      0.73      0.75       171\n",
      "         6.0       0.70      0.79      0.74       112\n",
      "         7.0       0.72      0.78      0.75       111\n",
      "\n",
      "    accuracy                           0.73      1051\n",
      "   macro avg       0.71      0.72      0.71      1051\n",
      "weighted avg       0.74      0.73      0.73      1051\n",
      "\n",
      "epoch.  110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST RESULT]\n",
      "epoch:110 IZY:-36.41 IZX:898.89 acc:0.7355 avg_acc:0.0000 err:0.2645 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.73      0.80       113\n",
      "         1.0       0.43      0.57      0.49        75\n",
      "         2.0       0.80      0.72      0.76       154\n",
      "         3.0       0.67      0.64      0.65       165\n",
      "         4.0       0.80      0.86      0.83       150\n",
      "         5.0       0.77      0.72      0.75       171\n",
      "         6.0       0.75      0.82      0.78       112\n",
      "         7.0       0.74      0.78      0.76       111\n",
      "\n",
      "    accuracy                           0.74      1051\n",
      "   macro avg       0.73      0.73      0.73      1051\n",
      "weighted avg       0.74      0.74      0.74      1051\n",
      "\n",
      "epoch.  111\n",
      "[TEST RESULT]\n",
      "epoch:111 IZY:-34.42 IZX:896.31 acc:0.7241 avg_acc:0.0000 err:0.2759 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.71      0.75       113\n",
      "         1.0       0.37      0.55      0.44        75\n",
      "         2.0       0.79      0.72      0.76       154\n",
      "         3.0       0.69      0.61      0.65       165\n",
      "         4.0       0.81      0.86      0.83       150\n",
      "         5.0       0.74      0.69      0.71       171\n",
      "         6.0       0.76      0.81      0.79       112\n",
      "         7.0       0.78      0.81      0.79       111\n",
      "\n",
      "    accuracy                           0.72      1051\n",
      "   macro avg       0.72      0.72      0.72      1051\n",
      "weighted avg       0.74      0.72      0.73      1051\n",
      "\n",
      "epoch.  112\n",
      "[TEST RESULT]\n",
      "epoch:112 IZY:-34.80 IZX:893.27 acc:0.7307 avg_acc:0.0000 err:0.2693 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.73      0.79       113\n",
      "         1.0       0.42      0.61      0.50        75\n",
      "         2.0       0.82      0.69      0.75       154\n",
      "         3.0       0.67      0.65      0.66       165\n",
      "         4.0       0.77      0.87      0.82       150\n",
      "         5.0       0.81      0.71      0.76       171\n",
      "         6.0       0.75      0.79      0.77       112\n",
      "         7.0       0.70      0.77      0.73       111\n",
      "\n",
      "    accuracy                           0.73      1051\n",
      "   macro avg       0.73      0.73      0.72      1051\n",
      "weighted avg       0.75      0.73      0.73      1051\n",
      "\n",
      "epoch.  113\n",
      "[TEST RESULT]\n",
      "epoch:113 IZY:-34.06 IZX:900.02 acc:0.7326 avg_acc:0.0000 err:0.2674 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.75      0.81       113\n",
      "         1.0       0.38      0.55      0.45        75\n",
      "         2.0       0.81      0.74      0.78       154\n",
      "         3.0       0.68      0.62      0.65       165\n",
      "         4.0       0.81      0.84      0.82       150\n",
      "         5.0       0.74      0.71      0.73       171\n",
      "         6.0       0.78      0.81      0.80       112\n",
      "         7.0       0.75      0.79      0.77       111\n",
      "\n",
      "    accuracy                           0.73      1051\n",
      "   macro avg       0.73      0.73      0.73      1051\n",
      "weighted avg       0.75      0.73      0.74      1051\n",
      "\n",
      "epoch.  114\n",
      "[TEST RESULT]\n",
      "epoch:114 IZY:-33.58 IZX:889.49 acc:0.7355 avg_acc:0.0000 err:0.2645 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.76      0.80       113\n",
      "         1.0       0.48      0.60      0.54        75\n",
      "         2.0       0.77      0.73      0.75       154\n",
      "         3.0       0.67      0.65      0.66       165\n",
      "         4.0       0.80      0.85      0.83       150\n",
      "         5.0       0.78      0.69      0.73       171\n",
      "         6.0       0.71      0.81      0.76       112\n",
      "         7.0       0.76      0.76      0.76       111\n",
      "\n",
      "    accuracy                           0.74      1051\n",
      "   macro avg       0.73      0.73      0.73      1051\n",
      "weighted avg       0.74      0.74      0.74      1051\n",
      "\n",
      "epoch.  115\n",
      "[TEST RESULT]\n",
      "epoch:115 IZY:-35.26 IZX:884.48 acc:0.7393 avg_acc:0.0000 err:0.2607 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.74      0.82       113\n",
      "         1.0       0.44      0.57      0.50        75\n",
      "         2.0       0.80      0.73      0.77       154\n",
      "         3.0       0.67      0.64      0.65       165\n",
      "         4.0       0.80      0.88      0.84       150\n",
      "         5.0       0.73      0.73      0.73       171\n",
      "         6.0       0.74      0.83      0.78       112\n",
      "         7.0       0.78      0.75      0.76       111\n",
      "\n",
      "    accuracy                           0.74      1051\n",
      "   macro avg       0.74      0.73      0.73      1051\n",
      "weighted avg       0.75      0.74      0.74      1051\n",
      "\n",
      "epoch.  116\n",
      "[TEST RESULT]\n",
      "epoch:116 IZY:-33.88 IZX:870.34 acc:0.7288 avg_acc:0.0000 err:0.2712 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.73      0.78       113\n",
      "         1.0       0.34      0.49      0.40        75\n",
      "         2.0       0.84      0.72      0.78       154\n",
      "         3.0       0.67      0.61      0.64       165\n",
      "         4.0       0.83      0.87      0.85       150\n",
      "         5.0       0.76      0.75      0.76       171\n",
      "         6.0       0.73      0.81      0.77       112\n",
      "         7.0       0.75      0.77      0.76       111\n",
      "\n",
      "    accuracy                           0.73      1051\n",
      "   macro avg       0.72      0.72      0.72      1051\n",
      "weighted avg       0.74      0.73      0.73      1051\n",
      "\n",
      "epoch.  117\n",
      "[TEST RESULT]\n",
      "epoch:117 IZY:-34.10 IZX:888.12 acc:0.7431 avg_acc:0.0000 err:0.2569 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.73      0.79       113\n",
      "         1.0       0.44      0.55      0.49        75\n",
      "         2.0       0.82      0.72      0.77       154\n",
      "         3.0       0.67      0.64      0.65       165\n",
      "         4.0       0.82      0.90      0.86       150\n",
      "         5.0       0.80      0.77      0.78       171\n",
      "         6.0       0.72      0.79      0.75       112\n",
      "         7.0       0.76      0.77      0.77       111\n",
      "\n",
      "    accuracy                           0.74      1051\n",
      "   macro avg       0.73      0.73      0.73      1051\n",
      "weighted avg       0.75      0.74      0.74      1051\n",
      "\n",
      "epoch.  118\n",
      "[TEST RESULT]\n",
      "epoch:118 IZY:-33.70 IZX:888.92 acc:0.7355 avg_acc:0.0000 err:0.2645 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.71      0.76       113\n",
      "         1.0       0.47      0.63      0.54        75\n",
      "         2.0       0.83      0.72      0.77       154\n",
      "         3.0       0.67      0.61      0.63       165\n",
      "         4.0       0.80      0.88      0.84       150\n",
      "         5.0       0.74      0.74      0.74       171\n",
      "         6.0       0.73      0.80      0.77       112\n",
      "         7.0       0.77      0.77      0.77       111\n",
      "\n",
      "    accuracy                           0.74      1051\n",
      "   macro avg       0.73      0.73      0.73      1051\n",
      "weighted avg       0.74      0.74      0.74      1051\n",
      "\n",
      "epoch.  119\n",
      "[TEST RESULT]\n",
      "epoch:119 IZY:-35.25 IZX:875.63 acc:0.7298 avg_acc:0.0000 err:0.2702 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.73      0.77       113\n",
      "         1.0       0.46      0.61      0.52        75\n",
      "         2.0       0.79      0.71      0.75       154\n",
      "         3.0       0.69      0.62      0.65       165\n",
      "         4.0       0.79      0.86      0.82       150\n",
      "         5.0       0.77      0.73      0.75       171\n",
      "         6.0       0.72      0.78      0.75       112\n",
      "         7.0       0.74      0.77      0.75       111\n",
      "\n",
      "    accuracy                           0.73      1051\n",
      "   macro avg       0.72      0.73      0.72      1051\n",
      "weighted avg       0.74      0.73      0.73      1051\n",
      "\n",
      "epoch.  120\n",
      "[TEST RESULT]\n",
      "epoch:120 IZY:-34.51 IZX:873.42 acc:0.7402 avg_acc:0.0000 err:0.2598 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.77      0.80       113\n",
      "         1.0       0.43      0.57      0.49        75\n",
      "         2.0       0.79      0.71      0.75       154\n",
      "         3.0       0.69      0.62      0.65       165\n",
      "         4.0       0.79      0.87      0.83       150\n",
      "         5.0       0.79      0.74      0.77       171\n",
      "         6.0       0.74      0.81      0.77       112\n",
      "         7.0       0.78      0.78      0.78       111\n",
      "\n",
      "    accuracy                           0.74      1051\n",
      "   macro avg       0.73      0.74      0.73      1051\n",
      "weighted avg       0.75      0.74      0.74      1051\n",
      "\n",
      "epoch.  121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST RESULT]\n",
      "epoch:121 IZY:-34.82 IZX:876.73 acc:0.7288 avg_acc:0.0000 err:0.2712 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.72      0.78       113\n",
      "         1.0       0.45      0.56      0.50        75\n",
      "         2.0       0.76      0.72      0.74       154\n",
      "         3.0       0.64      0.61      0.63       165\n",
      "         4.0       0.80      0.88      0.84       150\n",
      "         5.0       0.77      0.72      0.75       171\n",
      "         6.0       0.74      0.79      0.77       112\n",
      "         7.0       0.74      0.78      0.76       111\n",
      "\n",
      "    accuracy                           0.73      1051\n",
      "   macro avg       0.72      0.72      0.72      1051\n",
      "weighted avg       0.74      0.73      0.73      1051\n",
      "\n",
      "epoch.  122\n",
      "[TEST RESULT]\n",
      "epoch:122 IZY:-36.22 IZX:887.71 acc:0.7450 avg_acc:0.0000 err:0.2550 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.73      0.79       113\n",
      "         1.0       0.45      0.57      0.51        75\n",
      "         2.0       0.86      0.73      0.79       154\n",
      "         3.0       0.66      0.65      0.66       165\n",
      "         4.0       0.80      0.89      0.84       150\n",
      "         5.0       0.76      0.73      0.75       171\n",
      "         6.0       0.77      0.79      0.78       112\n",
      "         7.0       0.75      0.80      0.78       111\n",
      "\n",
      "    accuracy                           0.75      1051\n",
      "   macro avg       0.74      0.74      0.74      1051\n",
      "weighted avg       0.75      0.75      0.75      1051\n",
      "\n",
      "epoch.  123\n",
      "[TEST RESULT]\n",
      "epoch:123 IZY:-35.08 IZX:864.33 acc:0.7441 avg_acc:0.0000 err:0.2559 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.73      0.78       113\n",
      "         1.0       0.45      0.60      0.51        75\n",
      "         2.0       0.81      0.74      0.78       154\n",
      "         3.0       0.67      0.66      0.67       165\n",
      "         4.0       0.80      0.87      0.83       150\n",
      "         5.0       0.78      0.71      0.74       171\n",
      "         6.0       0.79      0.82      0.80       112\n",
      "         7.0       0.75      0.80      0.78       111\n",
      "\n",
      "    accuracy                           0.74      1051\n",
      "   macro avg       0.74      0.74      0.74      1051\n",
      "weighted avg       0.75      0.74      0.75      1051\n",
      "\n",
      "epoch.  124\n",
      "[TEST RESULT]\n",
      "epoch:124 IZY:-35.75 IZX:882.27 acc:0.7374 avg_acc:0.0000 err:0.2626 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.73      0.80       113\n",
      "         1.0       0.48      0.64      0.55        75\n",
      "         2.0       0.81      0.73      0.76       154\n",
      "         3.0       0.65      0.64      0.65       165\n",
      "         4.0       0.81      0.85      0.83       150\n",
      "         5.0       0.77      0.71      0.74       171\n",
      "         6.0       0.73      0.81      0.77       112\n",
      "         7.0       0.75      0.77      0.76       111\n",
      "\n",
      "    accuracy                           0.74      1051\n",
      "   macro avg       0.73      0.74      0.73      1051\n",
      "weighted avg       0.75      0.74      0.74      1051\n",
      "\n",
      "epoch.  125\n",
      "[TEST RESULT]\n",
      "epoch:125 IZY:-33.55 IZX:858.95 acc:0.7298 avg_acc:0.0000 err:0.2702 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.73      0.79       113\n",
      "         1.0       0.43      0.57      0.49        75\n",
      "         2.0       0.80      0.72      0.76       154\n",
      "         3.0       0.65      0.59      0.62       165\n",
      "         4.0       0.80      0.84      0.82       150\n",
      "         5.0       0.76      0.73      0.74       171\n",
      "         6.0       0.73      0.83      0.78       112\n",
      "         7.0       0.77      0.79      0.78       111\n",
      "\n",
      "    accuracy                           0.73      1051\n",
      "   macro avg       0.72      0.73      0.72      1051\n",
      "weighted avg       0.74      0.73      0.73      1051\n",
      "\n",
      "epoch.  126\n",
      "[TEST RESULT]\n",
      "epoch:126 IZY:-34.24 IZX:853.10 acc:0.7402 avg_acc:0.0000 err:0.2598 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.74      0.80       113\n",
      "         1.0       0.44      0.63      0.52        75\n",
      "         2.0       0.84      0.73      0.78       154\n",
      "         3.0       0.69      0.64      0.67       165\n",
      "         4.0       0.77      0.85      0.81       150\n",
      "         5.0       0.75      0.74      0.75       171\n",
      "         6.0       0.78      0.81      0.79       112\n",
      "         7.0       0.75      0.76      0.75       111\n",
      "\n",
      "    accuracy                           0.74      1051\n",
      "   macro avg       0.74      0.74      0.73      1051\n",
      "weighted avg       0.75      0.74      0.74      1051\n",
      "\n",
      "epoch.  127\n",
      "[TEST RESULT]\n",
      "epoch:127 IZY:-33.91 IZX:877.74 acc:0.7298 avg_acc:0.0000 err:0.2702 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.74      0.78       113\n",
      "         1.0       0.44      0.56      0.49        75\n",
      "         2.0       0.82      0.72      0.77       154\n",
      "         3.0       0.69      0.62      0.65       165\n",
      "         4.0       0.79      0.86      0.82       150\n",
      "         5.0       0.74      0.73      0.74       171\n",
      "         6.0       0.74      0.79      0.77       112\n",
      "         7.0       0.71      0.77      0.74       111\n",
      "\n",
      "    accuracy                           0.73      1051\n",
      "   macro avg       0.72      0.72      0.72      1051\n",
      "weighted avg       0.74      0.73      0.73      1051\n",
      "\n",
      "epoch.  128\n",
      "[TEST RESULT]\n",
      "epoch:128 IZY:-35.92 IZX:869.15 acc:0.7355 avg_acc:0.0000 err:0.2645 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.73      0.77       113\n",
      "         1.0       0.46      0.57      0.51        75\n",
      "         2.0       0.82      0.75      0.78       154\n",
      "         3.0       0.64      0.59      0.62       165\n",
      "         4.0       0.81      0.87      0.84       150\n",
      "         5.0       0.76      0.72      0.74       171\n",
      "         6.0       0.78      0.81      0.80       112\n",
      "         7.0       0.72      0.82      0.77       111\n",
      "\n",
      "    accuracy                           0.74      1051\n",
      "   macro avg       0.73      0.73      0.73      1051\n",
      "weighted avg       0.74      0.74      0.74      1051\n",
      "\n",
      "epoch.  129\n",
      "[TEST RESULT]\n",
      "epoch:129 IZY:-34.03 IZX:875.14 acc:0.7298 avg_acc:0.0000 err:0.2702 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.73      0.78       113\n",
      "         1.0       0.40      0.59      0.48        75\n",
      "         2.0       0.79      0.72      0.75       154\n",
      "         3.0       0.70      0.59      0.64       165\n",
      "         4.0       0.80      0.86      0.83       150\n",
      "         5.0       0.74      0.73      0.73       171\n",
      "         6.0       0.77      0.82      0.80       112\n",
      "         7.0       0.79      0.77      0.78       111\n",
      "\n",
      "    accuracy                           0.73      1051\n",
      "   macro avg       0.72      0.73      0.72      1051\n",
      "weighted avg       0.74      0.73      0.73      1051\n",
      "\n",
      "epoch.  130\n",
      "[TEST RESULT]\n",
      "epoch:130 IZY:-33.37 IZX:867.69 acc:0.7364 avg_acc:0.0000 err:0.2636 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.73      0.79       113\n",
      "         1.0       0.43      0.61      0.51        75\n",
      "         2.0       0.85      0.75      0.79       154\n",
      "         3.0       0.66      0.59      0.63       165\n",
      "         4.0       0.78      0.86      0.82       150\n",
      "         5.0       0.76      0.73      0.74       171\n",
      "         6.0       0.77      0.81      0.79       112\n",
      "         7.0       0.74      0.79      0.77       111\n",
      "\n",
      "    accuracy                           0.74      1051\n",
      "   macro avg       0.73      0.73      0.73      1051\n",
      "weighted avg       0.75      0.74      0.74      1051\n",
      "\n",
      "epoch.  131\n",
      "[TEST RESULT]\n",
      "epoch:131 IZY:-35.33 IZX:881.51 acc:0.7374 avg_acc:0.0000 err:0.2626 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.73      0.78       113\n",
      "         1.0       0.45      0.57      0.51        75\n",
      "         2.0       0.80      0.73      0.77       154\n",
      "         3.0       0.64      0.62      0.63       165\n",
      "         4.0       0.82      0.85      0.84       150\n",
      "         5.0       0.76      0.74      0.75       171\n",
      "         6.0       0.75      0.83      0.79       112\n",
      "         7.0       0.79      0.77      0.78       111\n",
      "\n",
      "    accuracy                           0.74      1051\n",
      "   macro avg       0.73      0.73      0.73      1051\n",
      "weighted avg       0.74      0.74      0.74      1051\n",
      "\n",
      "epoch.  132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST RESULT]\n",
      "epoch:132 IZY:-33.82 IZX:860.91 acc:0.7488 avg_acc:0.0000 err:0.2512 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.75      0.79       113\n",
      "         1.0       0.45      0.61      0.52        75\n",
      "         2.0       0.80      0.74      0.77       154\n",
      "         3.0       0.69      0.67      0.68       165\n",
      "         4.0       0.82      0.85      0.84       150\n",
      "         5.0       0.84      0.72      0.78       171\n",
      "         6.0       0.71      0.81      0.76       112\n",
      "         7.0       0.79      0.81      0.80       111\n",
      "\n",
      "    accuracy                           0.75      1051\n",
      "   macro avg       0.74      0.75      0.74      1051\n",
      "weighted avg       0.76      0.75      0.75      1051\n",
      "\n",
      "epoch.  133\n",
      "[TEST RESULT]\n",
      "epoch:133 IZY:-33.88 IZX:860.19 acc:0.7422 avg_acc:0.0000 err:0.2578 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.73      0.78       113\n",
      "         1.0       0.47      0.63      0.53        75\n",
      "         2.0       0.85      0.70      0.77       154\n",
      "         3.0       0.65      0.66      0.66       165\n",
      "         4.0       0.83      0.87      0.85       150\n",
      "         5.0       0.75      0.74      0.74       171\n",
      "         6.0       0.76      0.80      0.78       112\n",
      "         7.0       0.78      0.78      0.78       111\n",
      "\n",
      "    accuracy                           0.74      1051\n",
      "   macro avg       0.74      0.74      0.74      1051\n",
      "weighted avg       0.75      0.74      0.74      1051\n",
      "\n",
      "epoch.  134\n",
      "[TEST RESULT]\n",
      "epoch:134 IZY:-32.95 IZX:867.25 acc:0.7441 avg_acc:0.0000 err:0.2559 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.73      0.79       113\n",
      "         1.0       0.49      0.60      0.54        75\n",
      "         2.0       0.84      0.72      0.78       154\n",
      "         3.0       0.66      0.67      0.66       165\n",
      "         4.0       0.81      0.87      0.84       150\n",
      "         5.0       0.77      0.77      0.77       171\n",
      "         6.0       0.72      0.80      0.76       112\n",
      "         7.0       0.75      0.73      0.74       111\n",
      "\n",
      "    accuracy                           0.74      1051\n",
      "   macro avg       0.74      0.74      0.74      1051\n",
      "weighted avg       0.75      0.74      0.75      1051\n",
      "\n",
      "epoch.  135\n",
      "[TEST RESULT]\n",
      "epoch:135 IZY:-35.61 IZX:848.56 acc:0.7450 avg_acc:0.0000 err:0.2550 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.73      0.76       113\n",
      "         1.0       0.48      0.64      0.55        75\n",
      "         2.0       0.81      0.71      0.76       154\n",
      "         3.0       0.70      0.67      0.69       165\n",
      "         4.0       0.81      0.85      0.83       150\n",
      "         5.0       0.78      0.75      0.76       171\n",
      "         6.0       0.75      0.82      0.78       112\n",
      "         7.0       0.76      0.75      0.75       111\n",
      "\n",
      "    accuracy                           0.75      1051\n",
      "   macro avg       0.74      0.74      0.74      1051\n",
      "weighted avg       0.75      0.75      0.75      1051\n",
      "\n",
      "epoch.  136\n",
      "[TEST RESULT]\n",
      "epoch:136 IZY:-35.46 IZX:847.95 acc:0.7374 avg_acc:0.0000 err:0.2626 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.71      0.77       113\n",
      "         1.0       0.47      0.64      0.54        75\n",
      "         2.0       0.85      0.71      0.77       154\n",
      "         3.0       0.65      0.62      0.64       165\n",
      "         4.0       0.81      0.85      0.83       150\n",
      "         5.0       0.74      0.75      0.75       171\n",
      "         6.0       0.76      0.80      0.78       112\n",
      "         7.0       0.77      0.79      0.78       111\n",
      "\n",
      "    accuracy                           0.74      1051\n",
      "   macro avg       0.73      0.74      0.73      1051\n",
      "weighted avg       0.75      0.74      0.74      1051\n",
      "\n",
      "epoch.  137\n",
      "[TEST RESULT]\n",
      "epoch:137 IZY:-35.17 IZX:853.35 acc:0.7460 avg_acc:0.0000 err:0.2540 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.72      0.76       113\n",
      "         1.0       0.47      0.61      0.53        75\n",
      "         2.0       0.82      0.75      0.78       154\n",
      "         3.0       0.66      0.63      0.65       165\n",
      "         4.0       0.80      0.88      0.84       150\n",
      "         5.0       0.78      0.74      0.76       171\n",
      "         6.0       0.78      0.83      0.80       112\n",
      "         7.0       0.80      0.77      0.79       111\n",
      "\n",
      "    accuracy                           0.75      1051\n",
      "   macro avg       0.74      0.74      0.74      1051\n",
      "weighted avg       0.75      0.75      0.75      1051\n",
      "\n",
      "epoch.  138\n",
      "[TEST RESULT]\n",
      "epoch:138 IZY:-36.19 IZX:834.58 acc:0.7374 avg_acc:0.0000 err:0.2626 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.72      0.77       113\n",
      "         1.0       0.50      0.69      0.58        75\n",
      "         2.0       0.80      0.72      0.76       154\n",
      "         3.0       0.67      0.61      0.64       165\n",
      "         4.0       0.81      0.87      0.84       150\n",
      "         5.0       0.77      0.74      0.76       171\n",
      "         6.0       0.71      0.80      0.76       112\n",
      "         7.0       0.74      0.75      0.74       111\n",
      "\n",
      "    accuracy                           0.74      1051\n",
      "   macro avg       0.73      0.74      0.73      1051\n",
      "weighted avg       0.74      0.74      0.74      1051\n",
      "\n",
      "epoch.  139\n",
      "[TEST RESULT]\n",
      "epoch:139 IZY:-31.23 IZX:855.18 acc:0.7469 avg_acc:0.0000 err:0.2531 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.76      0.80       113\n",
      "         1.0       0.50      0.72      0.59        75\n",
      "         2.0       0.83      0.72      0.77       154\n",
      "         3.0       0.67      0.64      0.66       165\n",
      "         4.0       0.82      0.83      0.82       150\n",
      "         5.0       0.76      0.74      0.75       171\n",
      "         6.0       0.75      0.80      0.78       112\n",
      "         7.0       0.79      0.79      0.79       111\n",
      "\n",
      "    accuracy                           0.75      1051\n",
      "   macro avg       0.74      0.75      0.74      1051\n",
      "weighted avg       0.76      0.75      0.75      1051\n",
      "\n",
      "epoch.  140\n",
      "[TEST RESULT]\n",
      "epoch:140 IZY:-34.68 IZX:868.44 acc:0.7364 avg_acc:0.0000 err:0.2636 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.73      0.80       113\n",
      "         1.0       0.48      0.67      0.56        75\n",
      "         2.0       0.85      0.71      0.78       154\n",
      "         3.0       0.66      0.62      0.64       165\n",
      "         4.0       0.80      0.87      0.83       150\n",
      "         5.0       0.75      0.75      0.75       171\n",
      "         6.0       0.71      0.79      0.75       112\n",
      "         7.0       0.75      0.74      0.74       111\n",
      "\n",
      "    accuracy                           0.74      1051\n",
      "   macro avg       0.73      0.73      0.73      1051\n",
      "weighted avg       0.75      0.74      0.74      1051\n",
      "\n",
      "epoch.  141\n",
      "[TEST RESULT]\n",
      "epoch:141 IZY:-31.79 IZX:847.20 acc:0.7431 avg_acc:0.0000 err:0.2569 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.76      0.80       113\n",
      "         1.0       0.44      0.59      0.51        75\n",
      "         2.0       0.85      0.74      0.79       154\n",
      "         3.0       0.65      0.59      0.62       165\n",
      "         4.0       0.82      0.86      0.84       150\n",
      "         5.0       0.75      0.77      0.76       171\n",
      "         6.0       0.71      0.83      0.77       112\n",
      "         7.0       0.82      0.78      0.80       111\n",
      "\n",
      "    accuracy                           0.74      1051\n",
      "   macro avg       0.74      0.74      0.74      1051\n",
      "weighted avg       0.75      0.74      0.75      1051\n",
      "\n",
      "epoch.  142\n",
      "[TEST RESULT]\n",
      "epoch:142 IZY:-35.02 IZX:869.42 acc:0.7355 avg_acc:0.0000 err:0.2645 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.74      0.80       113\n",
      "         1.0       0.45      0.57      0.51        75\n",
      "         2.0       0.84      0.73      0.78       154\n",
      "         3.0       0.63      0.63      0.63       165\n",
      "         4.0       0.79      0.85      0.82       150\n",
      "         5.0       0.78      0.74      0.76       171\n",
      "         6.0       0.74      0.79      0.76       112\n",
      "         7.0       0.73      0.77      0.75       111\n",
      "\n",
      "    accuracy                           0.74      1051\n",
      "   macro avg       0.73      0.73      0.73      1051\n",
      "weighted avg       0.74      0.74      0.74      1051\n",
      "\n",
      "epoch.  143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST RESULT]\n",
      "epoch:143 IZY:-34.70 IZX:846.91 acc:0.7355 avg_acc:0.0000 err:0.2645 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.71      0.77       113\n",
      "         1.0       0.42      0.65      0.51        75\n",
      "         2.0       0.85      0.73      0.79       154\n",
      "         3.0       0.65      0.61      0.63       165\n",
      "         4.0       0.80      0.89      0.84       150\n",
      "         5.0       0.80      0.71      0.76       171\n",
      "         6.0       0.72      0.82      0.77       112\n",
      "         7.0       0.80      0.77      0.78       111\n",
      "\n",
      "    accuracy                           0.74      1051\n",
      "   macro avg       0.73      0.74      0.73      1051\n",
      "weighted avg       0.75      0.74      0.74      1051\n",
      "\n",
      "epoch.  144\n",
      "[TEST RESULT]\n",
      "epoch:144 IZY:-32.73 IZX:863.13 acc:0.7536 avg_acc:0.0000 err:0.2464 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.72      0.80       113\n",
      "         1.0       0.51      0.67      0.58        75\n",
      "         2.0       0.84      0.73      0.78       154\n",
      "         3.0       0.67      0.68      0.67       165\n",
      "         4.0       0.84      0.83      0.84       150\n",
      "         5.0       0.77      0.75      0.76       171\n",
      "         6.0       0.72      0.83      0.77       112\n",
      "         7.0       0.76      0.81      0.79       111\n",
      "\n",
      "    accuracy                           0.75      1051\n",
      "   macro avg       0.75      0.75      0.75      1051\n",
      "weighted avg       0.76      0.75      0.76      1051\n",
      "\n",
      "epoch.  145\n",
      "[TEST RESULT]\n",
      "epoch:145 IZY:-34.15 IZX:841.57 acc:0.7374 avg_acc:0.0000 err:0.2626 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.74      0.80       113\n",
      "         1.0       0.47      0.64      0.54        75\n",
      "         2.0       0.84      0.73      0.78       154\n",
      "         3.0       0.66      0.62      0.64       165\n",
      "         4.0       0.81      0.84      0.83       150\n",
      "         5.0       0.74      0.73      0.73       171\n",
      "         6.0       0.71      0.82      0.76       112\n",
      "         7.0       0.79      0.77      0.78       111\n",
      "\n",
      "    accuracy                           0.74      1051\n",
      "   macro avg       0.73      0.74      0.73      1051\n",
      "weighted avg       0.75      0.74      0.74      1051\n",
      "\n",
      "epoch.  146\n",
      "[TEST RESULT]\n",
      "epoch:146 IZY:-32.55 IZX:853.86 acc:0.7507 avg_acc:0.0000 err:0.2493 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.73      0.80       113\n",
      "         1.0       0.44      0.61      0.51        75\n",
      "         2.0       0.85      0.75      0.80       154\n",
      "         3.0       0.71      0.65      0.68       165\n",
      "         4.0       0.83      0.89      0.86       150\n",
      "         5.0       0.77      0.75      0.76       171\n",
      "         6.0       0.73      0.81      0.77       112\n",
      "         7.0       0.74      0.75      0.74       111\n",
      "\n",
      "    accuracy                           0.75      1051\n",
      "   macro avg       0.74      0.74      0.74      1051\n",
      "weighted avg       0.76      0.75      0.75      1051\n",
      "\n",
      "epoch.  147\n",
      "[TEST RESULT]\n",
      "epoch:147 IZY:-36.15 IZX:859.84 acc:0.7298 avg_acc:0.0000 err:0.2702 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.74      0.79       113\n",
      "         1.0       0.44      0.64      0.52        75\n",
      "         2.0       0.83      0.69      0.76       154\n",
      "         3.0       0.70      0.66      0.68       165\n",
      "         4.0       0.77      0.84      0.81       150\n",
      "         5.0       0.76      0.71      0.74       171\n",
      "         6.0       0.73      0.79      0.76       112\n",
      "         7.0       0.72      0.75      0.73       111\n",
      "\n",
      "    accuracy                           0.73      1051\n",
      "   macro avg       0.73      0.73      0.72      1051\n",
      "weighted avg       0.74      0.73      0.73      1051\n",
      "\n",
      "epoch.  148\n",
      "[TEST RESULT]\n",
      "epoch:148 IZY:-33.61 IZX:849.38 acc:0.7336 avg_acc:0.0000 err:0.2664 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.72      0.78       113\n",
      "         1.0       0.49      0.64      0.56        75\n",
      "         2.0       0.83      0.71      0.76       154\n",
      "         3.0       0.65      0.63      0.64       165\n",
      "         4.0       0.80      0.85      0.82       150\n",
      "         5.0       0.72      0.74      0.73       171\n",
      "         6.0       0.72      0.82      0.77       112\n",
      "         7.0       0.81      0.75      0.78       111\n",
      "\n",
      "    accuracy                           0.73      1051\n",
      "   macro avg       0.73      0.73      0.73      1051\n",
      "weighted avg       0.74      0.73      0.74      1051\n",
      "\n",
      "epoch.  149\n",
      "[TEST RESULT]\n",
      "epoch:149 IZY:-31.79 IZX:849.76 acc:0.7526 avg_acc:0.0000 err:0.2474 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.73      0.79       113\n",
      "         1.0       0.47      0.69      0.56        75\n",
      "         2.0       0.86      0.73      0.79       154\n",
      "         3.0       0.70      0.64      0.67       165\n",
      "         4.0       0.80      0.87      0.84       150\n",
      "         5.0       0.77      0.74      0.76       171\n",
      "         6.0       0.77      0.83      0.80       112\n",
      "         7.0       0.76      0.78      0.77       111\n",
      "\n",
      "    accuracy                           0.75      1051\n",
      "   macro avg       0.75      0.75      0.75      1051\n",
      "weighted avg       0.76      0.75      0.76      1051\n",
      "\n",
      "epoch.  150\n",
      "[TEST RESULT]\n",
      "epoch:150 IZY:-33.36 IZX:841.59 acc:0.7602 avg_acc:0.0000 err:0.2398 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.75      0.81       113\n",
      "         1.0       0.47      0.64      0.54        75\n",
      "         2.0       0.83      0.75      0.79       154\n",
      "         3.0       0.71      0.64      0.67       165\n",
      "         4.0       0.83      0.89      0.86       150\n",
      "         5.0       0.79      0.77      0.78       171\n",
      "         6.0       0.78      0.80      0.79       112\n",
      "         7.0       0.76      0.81      0.79       111\n",
      "\n",
      "    accuracy                           0.76      1051\n",
      "   macro avg       0.75      0.76      0.75      1051\n",
      "weighted avg       0.77      0.76      0.76      1051\n",
      "\n",
      "epoch.  151\n",
      "[TEST RESULT]\n",
      "epoch:151 IZY:-33.87 IZX:851.64 acc:0.7517 avg_acc:0.0000 err:0.2483 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.75      0.79       113\n",
      "         1.0       0.49      0.65      0.56        75\n",
      "         2.0       0.83      0.72      0.77       154\n",
      "         3.0       0.69      0.65      0.67       165\n",
      "         4.0       0.82      0.87      0.85       150\n",
      "         5.0       0.76      0.74      0.75       171\n",
      "         6.0       0.78      0.84      0.81       112\n",
      "         7.0       0.78      0.77      0.77       111\n",
      "\n",
      "    accuracy                           0.75      1051\n",
      "   macro avg       0.75      0.75      0.75      1051\n",
      "weighted avg       0.76      0.75      0.75      1051\n",
      "\n",
      "epoch.  152\n",
      "[TEST RESULT]\n",
      "epoch:152 IZY:-34.12 IZX:835.81 acc:0.7507 avg_acc:0.0000 err:0.2493 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.74      0.78       113\n",
      "         1.0       0.48      0.68      0.56        75\n",
      "         2.0       0.85      0.74      0.79       154\n",
      "         3.0       0.70      0.64      0.66       165\n",
      "         4.0       0.82      0.89      0.85       150\n",
      "         5.0       0.78      0.73      0.75       171\n",
      "         6.0       0.76      0.80      0.78       112\n",
      "         7.0       0.76      0.78      0.77       111\n",
      "\n",
      "    accuracy                           0.75      1051\n",
      "   macro avg       0.74      0.75      0.74      1051\n",
      "weighted avg       0.76      0.75      0.75      1051\n",
      "\n",
      "epoch.  153\n",
      "[TEST RESULT]\n",
      "epoch:153 IZY:-35.27 IZX:838.23 acc:0.7507 avg_acc:0.0000 err:0.2493 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.73      0.75       113\n",
      "         1.0       0.45      0.63      0.53        75\n",
      "         2.0       0.83      0.71      0.77       154\n",
      "         3.0       0.70      0.64      0.67       165\n",
      "         4.0       0.84      0.88      0.86       150\n",
      "         5.0       0.75      0.74      0.74       171\n",
      "         6.0       0.79      0.86      0.82       112\n",
      "         7.0       0.81      0.81      0.81       111\n",
      "\n",
      "    accuracy                           0.75      1051\n",
      "   macro avg       0.74      0.75      0.74      1051\n",
      "weighted avg       0.76      0.75      0.75      1051\n",
      "\n",
      "epoch.  154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST RESULT]\n",
      "epoch:154 IZY:-34.87 IZX:834.18 acc:0.7412 avg_acc:0.0000 err:0.2588 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.75      0.79       113\n",
      "         1.0       0.47      0.65      0.54        75\n",
      "         2.0       0.83      0.72      0.77       154\n",
      "         3.0       0.68      0.61      0.64       165\n",
      "         4.0       0.81      0.87      0.84       150\n",
      "         5.0       0.77      0.75      0.76       171\n",
      "         6.0       0.74      0.81      0.77       112\n",
      "         7.0       0.76      0.75      0.75       111\n",
      "\n",
      "    accuracy                           0.74      1051\n",
      "   macro avg       0.73      0.74      0.73      1051\n",
      "weighted avg       0.75      0.74      0.74      1051\n",
      "\n",
      "epoch.  155\n",
      "[TEST RESULT]\n",
      "epoch:155 IZY:-33.66 IZX:827.54 acc:0.7469 avg_acc:0.0000 err:0.2531 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.75      0.82       113\n",
      "         1.0       0.47      0.67      0.55        75\n",
      "         2.0       0.83      0.71      0.77       154\n",
      "         3.0       0.66      0.62      0.64       165\n",
      "         4.0       0.85      0.86      0.86       150\n",
      "         5.0       0.74      0.76      0.75       171\n",
      "         6.0       0.71      0.79      0.75       112\n",
      "         7.0       0.80      0.81      0.81       111\n",
      "\n",
      "    accuracy                           0.75      1051\n",
      "   macro avg       0.75      0.75      0.74      1051\n",
      "weighted avg       0.76      0.75      0.75      1051\n",
      "\n",
      "epoch.  156\n",
      "[TEST RESULT]\n",
      "epoch:156 IZY:-33.61 IZX:851.06 acc:0.7469 avg_acc:0.0000 err:0.2531 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.70      0.76       113\n",
      "         1.0       0.45      0.69      0.55        75\n",
      "         2.0       0.88      0.73      0.80       154\n",
      "         3.0       0.69      0.63      0.66       165\n",
      "         4.0       0.80      0.89      0.84       150\n",
      "         5.0       0.77      0.75      0.76       171\n",
      "         6.0       0.76      0.80      0.78       112\n",
      "         7.0       0.77      0.77      0.77       111\n",
      "\n",
      "    accuracy                           0.75      1051\n",
      "   macro avg       0.75      0.75      0.74      1051\n",
      "weighted avg       0.76      0.75      0.75      1051\n",
      "\n",
      "epoch.  157\n",
      "[TEST RESULT]\n",
      "epoch:157 IZY:-32.44 IZX:828.83 acc:0.7555 avg_acc:0.0000 err:0.2445 avg_erra:1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.76      0.82       113\n",
      "         1.0       0.51      0.69      0.59        75\n",
      "         2.0       0.83      0.73      0.78       154\n",
      "         3.0       0.71      0.65      0.68       165\n",
      "         4.0       0.79      0.86      0.82       150\n",
      "         5.0       0.79      0.76      0.77       171\n",
      "         6.0       0.70      0.83      0.76       112\n",
      "         7.0       0.80      0.76      0.78       111\n",
      "\n",
      "    accuracy                           0.76      1051\n",
      "   macro avg       0.75      0.76      0.75      1051\n",
      "weighted avg       0.76      0.76      0.76      1051\n",
      "\n",
      "epoch.  158\n"
     ]
    }
   ],
   "source": [
    "!python3 main.py --mode train --beta 1e-2 --epoch 200 --lr 1.e-3 --K=256 --batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 main.py --mode test --env_name [NAME] --load_ckpt best_acc.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
